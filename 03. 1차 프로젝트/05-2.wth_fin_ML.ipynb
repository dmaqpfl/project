{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6e5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import FinanceDataReader as fdr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89fa089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "mpl.rcParams['axes.unicode_minus']= False\n",
    "\n",
    "path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "font_name = fm.FontProperties(fname = path, size = 50).get_name()\n",
    "plt.rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358c0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79bc18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2162bd",
   "metadata": {},
   "source": [
    "# 날씨 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f7cf4b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tm</th>\n",
       "      <th>avgTa</th>\n",
       "      <th>minTa</th>\n",
       "      <th>maxTa</th>\n",
       "      <th>sumRnDur</th>\n",
       "      <th>mi10MaxRn</th>\n",
       "      <th>hr1MaxRn</th>\n",
       "      <th>sumRn</th>\n",
       "      <th>maxInsWs</th>\n",
       "      <th>maxWs</th>\n",
       "      <th>...</th>\n",
       "      <th>avgLmac</th>\n",
       "      <th>avgTs</th>\n",
       "      <th>avgCm10Te</th>\n",
       "      <th>avgCm30Te</th>\n",
       "      <th>avgM05Te</th>\n",
       "      <th>avgM15Te</th>\n",
       "      <th>avgM30Te</th>\n",
       "      <th>sumLrgEv</th>\n",
       "      <th>sumSmlEv</th>\n",
       "      <th>sumFogDur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>9.7</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>13.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tm  avgTa  minTa  maxTa  sumRnDur  mi10MaxRn  hr1MaxRn  sumRn  \\\n",
       "0  2000-01-01    5.5    1.8    9.9       NaN        NaN       NaN    NaN   \n",
       "1  2000-01-02    4.2   -0.9    6.9      6.83        NaN       NaN    6.0   \n",
       "2  2000-01-03   -2.2   -4.6    0.1       NaN        NaN       NaN    NaN   \n",
       "3  2000-01-04    0.3   -4.3    4.3       NaN        NaN       NaN    NaN   \n",
       "4  2000-01-05    2.8    0.1    4.6     13.90        NaN       NaN   18.4   \n",
       "\n",
       "   maxInsWs  maxWs  ...  avgLmac  avgTs  avgCm10Te  avgCm30Te  avgM05Te  \\\n",
       "0       7.4    4.0  ...      2.1    3.2        0.1        1.3       3.5   \n",
       "1      11.8    7.6  ...      3.9    4.3        0.3        1.4       3.6   \n",
       "2       8.1    5.9  ...      0.4   -1.9        0.2        1.3       3.3   \n",
       "3       4.5    3.0  ...      3.8   -1.3        0.1        1.3       3.3   \n",
       "4       9.1    5.2  ...      6.5    0.6        0.1        1.3       3.3   \n",
       "\n",
       "   avgM15Te  avgM30Te  sumLrgEv  sumSmlEv  sumFogDur  \n",
       "0      10.0      14.6       NaN       0.9        NaN  \n",
       "1       9.7      14.5       NaN       0.8        NaN  \n",
       "2       9.5      14.5       NaN       0.8        NaN  \n",
       "3       9.5      14.5       NaN       0.7        NaN  \n",
       "4       9.5      14.5       NaN       1.7        NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh = pd.read_csv('wth_data_20211025.csv', index_col = 0)\n",
    "wh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7feb6796",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7969 entries, 0 to 7968\n",
      "Data columns (total 36 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   tm           7969 non-null   object \n",
      " 1   avgTa        7969 non-null   float64\n",
      " 2   minTa        7969 non-null   float64\n",
      " 3   maxTa        7968 non-null   float64\n",
      " 4   sumRnDur     3098 non-null   float64\n",
      " 5   mi10MaxRn    1996 non-null   float64\n",
      " 6   hr1MaxRn     1996 non-null   float64\n",
      " 7   sumRn        3099 non-null   float64\n",
      " 8   maxInsWs     7967 non-null   float64\n",
      " 9   maxWs        7967 non-null   float64\n",
      " 10  avgWs        7966 non-null   float64\n",
      " 11  avgTd        7969 non-null   float64\n",
      " 12  minRhm       7968 non-null   float64\n",
      " 13  avgRhm       7969 non-null   float64\n",
      " 14  avgPa        7968 non-null   float64\n",
      " 15  maxPs        7968 non-null   float64\n",
      " 16  minPs        7967 non-null   float64\n",
      " 17  avgPs        7968 non-null   float64\n",
      " 18  ssDur        7969 non-null   float64\n",
      " 19  sumSsHr      7956 non-null   float64\n",
      " 20  hr1MaxIcsr   7945 non-null   float64\n",
      " 21  sumGsr       7942 non-null   float64\n",
      " 22  ddMefs       276 non-null    float64\n",
      " 23  ddMes        542 non-null    float64\n",
      " 24  sumDpthFhsc  276 non-null    float64\n",
      " 25  avgTca       7969 non-null   float64\n",
      " 26  avgLmac      7948 non-null   float64\n",
      " 27  avgTs        7968 non-null   float64\n",
      " 28  avgCm10Te    7960 non-null   float64\n",
      " 29  avgCm30Te    7943 non-null   float64\n",
      " 30  avgM05Te     7961 non-null   float64\n",
      " 31  avgM15Te     7960 non-null   float64\n",
      " 32  avgM30Te     7958 non-null   float64\n",
      " 33  sumLrgEv     5478 non-null   float64\n",
      " 34  sumSmlEv     7963 non-null   float64\n",
      " 35  sumFogDur    168 non-null    float64\n",
      "dtypes: float64(35), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "wh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78371532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tm', 'avgTa', 'minTa', 'maxTa', 'sumRnDur', 'mi10MaxRn', 'hr1MaxRn',\n",
       "       'sumRn', 'maxInsWs', 'maxWs', 'avgWs', 'avgTd', 'minRhm', 'avgRhm',\n",
       "       'avgPa', 'maxPs', 'minPs', 'avgPs', 'ssDur', 'sumSsHr', 'hr1MaxIcsr',\n",
       "       'sumGsr', 'ddMefs', 'ddMes', 'sumDpthFhsc', 'avgTca', 'avgLmac',\n",
       "       'avgTs', 'avgCm10Te', 'avgCm30Te', 'avgM05Te', 'avgM15Te', 'avgM30Te',\n",
       "       'sumLrgEv', 'sumSmlEv', 'sumFogDur'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84093cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = {'tm':'Date', 'avgTa':'평균기온', 'minTa':'최저기온', 'maxTa':'최고기온', 'sumRnDur':'강수계속시간', 'mi10MaxRn':'10분최다강수', 'hr1MaxRn':'1시간최다강수', 'sumRn':'일강수',\n",
    "       'maxInsWs':'최대순간풍속', 'maxWs':'최대풍속', 'avgWs':'평균풍속', 'avgTd':'평균이슬점온도', 'minRhm':'최소상대습도', 'avgRhm':'평균상대습도', 'avgPa':'평균현지기압',\n",
    "       'maxPs':'최고해면기압', 'minPs':'최저해면기압', 'avgPs':'평균해면기압', 'ssDur':'가조시간', 'sumSsHr':'합계일조시간', 'hr1MaxIcsr':'1시간최다일사량', 'sumGsr':'합계일사량',\n",
    "       'ddMefs':'최심신적설', 'ddMes':'최심적설', 'sumDpthFhsc':'3시간신적설', 'avgTca':'평균전운량', 'avgLmac':'평균중하층운량', 'avgTs':'평균지면온도',\n",
    "       'avgCm10Te':'평균10cm지중온도', 'avgCm30Te':'평균30cm지중온도', 'avgM05Te':'0.5m지중온도', 'avgM15Te':'1.5m지중온도', 'avgM30Te':'3m지중온도',\n",
    "       'sumLrgEv':'대형증발량', 'sumSmlEv':'소형증발량', 'sumFogDur':'안개계속시간'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adc24e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh = wh.rename(columns = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff1927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>평균기온</th>\n",
       "      <th>최저기온</th>\n",
       "      <th>최고기온</th>\n",
       "      <th>강수계속시간</th>\n",
       "      <th>10분최다강수</th>\n",
       "      <th>1시간최다강수</th>\n",
       "      <th>일강수</th>\n",
       "      <th>최대순간풍속</th>\n",
       "      <th>최대풍속</th>\n",
       "      <th>...</th>\n",
       "      <th>평균중하층운량</th>\n",
       "      <th>평균지면온도</th>\n",
       "      <th>평균10cm지중온도</th>\n",
       "      <th>평균30cm지중온도</th>\n",
       "      <th>0.5m지중온도</th>\n",
       "      <th>1.5m지중온도</th>\n",
       "      <th>3m지중온도</th>\n",
       "      <th>대형증발량</th>\n",
       "      <th>소형증발량</th>\n",
       "      <th>안개계속시간</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>9.7</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>13.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  평균기온  최저기온  최고기온  강수계속시간  10분최다강수  1시간최다강수   일강수  최대순간풍속  최대풍속  \\\n",
       "0  2000-01-01   5.5   1.8   9.9     NaN      NaN      NaN   NaN     7.4   4.0   \n",
       "1  2000-01-02   4.2  -0.9   6.9    6.83      NaN      NaN   6.0    11.8   7.6   \n",
       "2  2000-01-03  -2.2  -4.6   0.1     NaN      NaN      NaN   NaN     8.1   5.9   \n",
       "3  2000-01-04   0.3  -4.3   4.3     NaN      NaN      NaN   NaN     4.5   3.0   \n",
       "4  2000-01-05   2.8   0.1   4.6   13.90      NaN      NaN  18.4     9.1   5.2   \n",
       "\n",
       "   ...  평균중하층운량  평균지면온도  평균10cm지중온도  평균30cm지중온도  0.5m지중온도  1.5m지중온도  3m지중온도  \\\n",
       "0  ...      2.1     3.2         0.1         1.3       3.5      10.0    14.6   \n",
       "1  ...      3.9     4.3         0.3         1.4       3.6       9.7    14.5   \n",
       "2  ...      0.4    -1.9         0.2         1.3       3.3       9.5    14.5   \n",
       "3  ...      3.8    -1.3         0.1         1.3       3.3       9.5    14.5   \n",
       "4  ...      6.5     0.6         0.1         1.3       3.3       9.5    14.5   \n",
       "\n",
       "   대형증발량  소형증발량  안개계속시간  \n",
       "0    NaN    0.9     NaN  \n",
       "1    NaN    0.8     NaN  \n",
       "2    NaN    0.8     NaN  \n",
       "3    NaN    0.7     NaN  \n",
       "4    NaN    1.7     NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1dad2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh.index = wh['Date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da77e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh.drop('Date', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f2055d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh = wh.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a7ce67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "wh.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0d399",
   "metadata": {},
   "source": [
    "# 코스피 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d3fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = fdr.DataReader('KS11', '2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c787816c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kospi_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.0301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>-0.0687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>-0.0259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>-0.0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>0.0407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            kospi_change\n",
       "Date                    \n",
       "2000-01-04        0.0301\n",
       "2000-01-05       -0.0687\n",
       "2000-01-06       -0.0259\n",
       "2000-01-07       -0.0126\n",
       "2000-01-10        0.0407"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Change' : 'kospi_change'}\n",
    "kos = kos.rename(columns = d)\n",
    "kos = kos[['kospi_change']]\n",
    "kos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70c4473f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '02.finance_theme_code_crawling.ipynb',\n",
       " 'all_ver1_1.ipynb',\n",
       " 'all_ver1_2.ipynb',\n",
       " 'all_ver1_3-Copy4.ipynb',\n",
       " 'all_ver1_3.ipynb',\n",
       " 'cd_theme_data_20211021.csv',\n",
       " 'cd_theme_data_20211027.csv',\n",
       " 'wth_data_20211025.csv',\n",
       " '머신러닝_태양광에너지 관련주 테마.ipynb',\n",
       " '제비',\n",
       " '테마 전체의 변동률 예측 머신러닝.R1.ipynb',\n",
       " '테마 전체의 변동률 예측 머신러닝.R2 - 복사본.ipynb',\n",
       " '테마 전체의 변동률 예측 머신러닝.R2.ipynb',\n",
       " '테마별 주식데이터',\n",
       " '테마별 주식데이터.zip']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cb5ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './테마별 주식데이터'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b5edb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [path + '/'+ i for i in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a347ebb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cc25404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./테마별 주식데이터/겨울_list_20211027.csv\n",
      "./테마별 주식데이터/도시가스_list_20211027.csv\n",
      "./테마별 주식데이터/여행_list_20211027.csv\n",
      "./테마별 주식데이터/인터넷 대표주_list_20211027.csv\n",
      "./테마별 주식데이터/제습기_list_20211027.csv\n",
      "./테마별 주식데이터/태양광에너지_list_20211027.csv\n",
      "./테마별 주식데이터/태풍 및 장마_list_20211027.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.030136</td>\n",
       "      <td>-0.020502</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>-0.119001</td>\n",
       "      <td>0.054689</td>\n",
       "      <td>0.031705</td>\n",
       "      <td>-0.007652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.023748</td>\n",
       "      <td>-0.015360</td>\n",
       "      <td>-0.096321</td>\n",
       "      <td>-0.118948</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>-0.025857</td>\n",
       "      <td>-0.020016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>-0.019810</td>\n",
       "      <td>-0.024013</td>\n",
       "      <td>-0.055905</td>\n",
       "      <td>-0.120027</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>-0.026880</td>\n",
       "      <td>-0.045861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.010704</td>\n",
       "      <td>-0.030269</td>\n",
       "      <td>-0.119311</td>\n",
       "      <td>-0.119290</td>\n",
       "      <td>-0.005948</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.017759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.059410</td>\n",
       "      <td>-0.007423</td>\n",
       "      <td>0.010749</td>\n",
       "      <td>-0.031333</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.006444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            겨울_change  도시가스_change  여행_change  인터넷 대표주_change  제습기_change  \\\n",
       "Date                                                                        \n",
       "2000-01-04   0.030136    -0.020502   0.100968       -0.119001    0.054689   \n",
       "2000-01-05   0.023748    -0.015360  -0.096321       -0.118948    0.018182   \n",
       "2000-01-06  -0.019810    -0.024013  -0.055905       -0.120027    0.037346   \n",
       "2000-01-07   0.010704    -0.030269  -0.119311       -0.119290   -0.005948   \n",
       "2000-01-10   0.003991     0.059410  -0.007423        0.010749   -0.031333   \n",
       "\n",
       "            태양광에너지_change  태풍 및 장마_change  \n",
       "Date                                       \n",
       "2000-01-04       0.031705       -0.007652  \n",
       "2000-01-05      -0.025857       -0.020016  \n",
       "2000-01-06      -0.026880       -0.045861  \n",
       "2000-01-07       0.006642        0.017759  \n",
       "2000-01-10       0.002046        0.006444  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.DataFrame()\n",
    "\n",
    "for i in L :\n",
    "    print(i)\n",
    "    v = pd.read_csv(i, index_col = 0)\n",
    "    v = pd.DataFrame(v.groupby('Date')['Change'].mean())\n",
    "    v.columns = [i.split('/')[2].split('_')[0] + '_change']\n",
    "    v.index = v.index.astype('datetime64[ns]')\n",
    "    Y = pd.concat([Y, v], axis=1)\n",
    "# j += 1\n",
    "\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51436faa",
   "metadata": {},
   "source": [
    "# 코스피와 테마별 주식 데이터 concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5c464e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "      <th>kospi_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.030136</td>\n",
       "      <td>-0.020502</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>-0.119001</td>\n",
       "      <td>0.054689</td>\n",
       "      <td>0.031705</td>\n",
       "      <td>-0.007652</td>\n",
       "      <td>0.0301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.023748</td>\n",
       "      <td>-0.015360</td>\n",
       "      <td>-0.096321</td>\n",
       "      <td>-0.118948</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>-0.025857</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>-0.0687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            겨울_change  도시가스_change  여행_change  인터넷 대표주_change  제습기_change  \\\n",
       "Date                                                                        \n",
       "2000-01-04   0.030136    -0.020502   0.100968       -0.119001    0.054689   \n",
       "2000-01-05   0.023748    -0.015360  -0.096321       -0.118948    0.018182   \n",
       "\n",
       "            태양광에너지_change  태풍 및 장마_change  kospi_change  \n",
       "Date                                                     \n",
       "2000-01-04       0.031705       -0.007652        0.0301  \n",
       "2000-01-05      -0.025857       -0.020016       -0.0687  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.concat([Y,kos], axis =1)\n",
    "Y.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2ba182",
   "metadata": {},
   "source": [
    "# 코스피 변동률과 테마별 변동률의 상관관계\n",
    "- 코스피 변동률과 태양광 에너지의 변동률의 상관관계가 높은 것으로 나왔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fae91d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAFXCAYAAAAlJtBUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABEVElEQVR4nO3deZwdVZn/8c83ISyBQAIIKgqoMOzKpkQkEAiyZBBccGRTQTCAM6wyQxSVTZBNhUEFGRB/GBYRBcIiO4GAgBOEAZRN2ZHNhRAIAUJ/f3+cc5PKpbtvd6e7qvr2887rvrpuVd06T9+bW0+fU6fOkW1CCCGEdjCs6gBCCCGE/hJJLYQQQtuIpBZCCKFtRFILIYTQNiKphRBCaBuR1EIIIbSNRaoOIIQQQpD0LuBgoMP2twvrlwL+B1gJ+AfwJduvdHWcqKmFEEKog+8DbwAjmtYfAlxhe3PgemD/7g4SSS2EEELlbH8JuLWTTVsBv8rLvwY+3t1xovmxjSyxwX9UPjzMHt/Yr+oQAPjKhu+rOgTWXmnpqkMAYJOjr686BL6y7WpVh8Bayy9VdQgAvNHRUXUIAOz8kfdoYY/Rm3POnHt/vC8wqbDqLNtn9eCli9l+Ky//HRjT3c6R1EJoY3VIaCEA5ATWkyTWrEPSMNsdpIT2Unc7R/NjCCGEvtGwnj/67i5gp7z8OeCG7naOpBZCCKFvpJ4/en1onShpUeB7wCRJ04CNgHO7e100P4YQQuibYcP79XC2pwHT8vLhefXfgO17eoxIaiGEEPpm4ZoVB0QktRBCCH3Th2bFgRZJLYQQQt9ETS2EEELbiJpaCCGEttHPHUX6w5BJapL+BRhm+6H8/APA14C1AAGPAD+2/efqogwhhEEkmh8HnqTzgJXz0zHAxbaPAz5G+n0fytsuAQ4DvpOfj83r1i8t2BBCGMyi+XHg5UExAZB0ADBM0tbAOsDDhV2fJNXQhhd+PtmbsiStCpxge5eFDDuEEAafGtbU6hdR/9oK+D2wKvCupm27AaOBA4H/AJYBvlBibCGEMLiVM0xWr7RdTa1B0kTgCdt3AHdImgMsIumTwBGdvGRb4ACl6vQJtq/p5JgTmN9cOZU0DcIoSVOAtYHptg+StAxwHilRDgN2sv1PSTOAGaQmzsdt75qPexKwGfACsCRwoO2HJB0FbEmqSR5i++5OYppEHvl6kfeNZ5Hl1+nlOxVCCH00LJofSyHpw8ABwOckbQeMJzU//tr29cD1klYgJZzPkd6HX5JmXH2xi2OOAo4HtrE9U9Iw0rW7tYD1gNnAPZJGA3OAPWzPknQkMBE4H1gNmGj7RUlTJa0HvBsYY3vTPM7ZXbm8rYHRtreQtCwpSe7QHFdx5Os6TD0TQhhCovfjwFKqZn0J2AX4iu3Zkv4X+DPzR3lu2AVYtPB8D+DLpATVmTWAu2zPBLDdkWt1M2y/lst/mNSkOQI4WNIsYE1SDQzg4ULSfBBYFtgAuDof801J9+ftGwIT8iCekK75hRBCfdTwmlpbJTVgJLACsGNjUjnbfwf+LukFFvx9tweWaHr9st0c+0lgrKQlbL8uqTHleHHGv0ZN6UBgiu07JJ3eyfbGsoCngHHApZJGknphQrrF4GLbxwLkbSGEUB/R+3Fg5RrTyT3cXbbH9+LYL0k6FbhF0quk5spru9h9KnCOpEeBZ1sc+hJgR0l3kBLcY6Tmy8uB7STdBswiTbdwcU/jDSGEARc1tVpZr9C0V7Sv7Yc7WY/tC4ALmlbvUtjeWH6C1HGk+fVjC8uTASQNB3a37dzB5GbgadsG9uvxbxNCCGWLmlp1bE9per5Sd/t3kvC+3lnvw36wAjAldzwZAUy2/fYAlBNCCP0ramqDR2+aJheynOeACWWUFUII/Sp6P4YQQmgb0fwYQgihbUTzYwghhLYRSS2EEELbiObHEEIIbaMfO4pIOhbYnJSXJtn+Y14/GjibNCj9LOCLtv/Z1XEiqbWRPb5R/W1tU753ZtUhAHDQlSdUHQKLjai+aebe727LrNfnVh0G1z7yfNUhsMxiI1rvVIKZb7xVdQj9p5+aHyWNA1bMY92uSxpEY2LePBm4wPZvJO0DHML8geXfofpvXQhhwNQhoYU2JvX80b1tgAsBbD/AgkMWrkcalALgCuCj3R0okloIIYQ+kdSbxyRJMwqPSYVDrQC8VHg+Nw9IAXAf8Nm8PIEWLYzR/BhCCKFP1IuOIsVpsjoxExhTeN5huzFY/PHA6ZJ2AaaRhiHsUtTUQggh9I168ejedGBnAElrA880NtieZXtP258ElgZ+0d2BIqmFEELok2HDhvX40cJVwKKSpgOnAIdLOlHSopK2kvS7PJPJ32zf2t2BovkxhBBCn/Sm+bE7ualx/6bVh+efNwGb9vRYkdRCCCH0SX8ltf4USS2EEELf1C+nRVILIYTQN3WsqQ3qjiKSVpK0cQ/226mMeEIIYSjpzX1qZalFTU3SI8Bfm1a/ZPvzTftdY3u7wqrVgc2AGXn7qcD6edtI4C7bBwAHAJd3Ufb+ALbPWLjfIoQQhpYe9GosXS2SGvCU7a17sN+i3W20fXBjWdJngJW62z/fsb4tYEk/Ldzs1yOSVgVOsL1Lb14XQghtoX6tj4On+VGp/rqxpG4TW8FE0r0PXR1vJPAj4BzSCNBnSBq10IGGEMIQUcfmx0GT1IBPku4y/0yrHSVtCCxh+/G8apikyyT9V97+HeBnwP/YvsL2VaQEd5ako7s57gRJt+TH1/PqUZKmSPqDpNPyfstIulzSNEm3ShqT18+QdKakOyVdWDjuSfnmwkslXSdpzbz+qFzWrZI26iKmeeOpPXTDr1q9NSGE0G/qmNTq0vz4T0nTgBVJFdrGPBXb235d0iLAgaSmwnMl/db2K50dSNIqwAlAsUmww/anC8+/b/u14uts3w/smmtwnR13FGkMsm1sz8xNlysDa5FGkZ4N3JPn/pkD7GF7lqQjSbXG84HVgIm2X5Q0VdJ6wLuBMbY3zbXQu3J5WwOj81QMywLnATs0x1UcT+2rFz/gzmIPIYSBUMfej7VIao0OIZL2ABax/fPGtpzQzgDOtv20pG8Cl0jarfk4kj4L7Af8u+1/dFPea91sm93FpjVIHU9m5v068gc6o3E8SQ8Do4ERwMGSZgFrAi/kYzxs+8W8/CBpeoUNgKvzMd+UdH/eviEwISd7gP6bjS+EEPqBhkVS64v3AjfavgzA9u8lfQtYoFYiaQSpN+Snu0lMSJoAfKNFmSfZvq5p3ZPAWElL5NpjY8bBYueSRkwHAlNs3yHp9E62N5YFPAWMAy7NtcSxefsjwMW2j81xd1qDDCGEqkRNrYmkTwJHdLJ+z8LTE2xfVNxu+/d5v+K6t4ATW5Vp+0bgxt7GavulfMvALZJeBX4JXNvF7lOBcyQ9Cjzb4tCXADsqDdb5FPAYqfnycmA7SbeRpjA/F7i4t3GHEMJAiaTWxPb1wPVVxtAbti8ALmhavUthe2P5CWDtTl4/trA8GUDScGB325a0DGmG16dtm9SUGkIItRRJrZ/ZnkaaNK7Vfj25B24BhWtZDV+3fXdvj9MDKwBTcseTEcBk228PQDkhhNC/6pfTBndSG0i2x5dUznOkKcpDCGFQiZpaCCGEthHDZIUQQmgf9auoRVILIYTQN9H8GEIIoW1EUgshhNA2IqmFAfWVDd9XdQgcdOUJVYcAwEd3mFx1CPz2omOqDgGAdy+9eNUh8IdnX606BMZ8sKcTfAysl+a8UXUI/SaGyQohlKoOCS20r/6sqUk6FticlJcm2f5jXr8o8FNgFdJoS7s2xuDtTP36Y4YQQhgU+mvqGUnjgBVtbwHsC5xc2Lwd8KztrYDfAPt0d6yoqYUQQuiTfqyobQNcCGD7gTzdVsMsYExeXh74a3cHiqQWQgihT3rT/ChpEjCpsOqsPB8kpOECXypsmytpmO0O4Dbg25L+BLwNbNpdOZHUQggh9ElvamrFCY07MZP5tTFIEzs3pvU6HjjF9tWS1s/H2LWrcuKaWgghhD4ZNkw9frQwHdgZQNLawDOFbasAz+flF4H3d3egqKmFEELokx4kq566CpgoaTrpGtq+kk4Evp0fPynMZPKf3R0okloIIYQ+6a+OIrmpcf+m1Yfnnw/Ti5lMIqmFEELokzqOKDJkrqlJWl3SmoXnIySN6Wy/ciMLIYTBSer5oyxtl9RysjpL0jRJN0p6b960ETBW0uKSVgW2BE6UtKqk5SRdk/c7vYq4QwhhsOmvm6/7Uzs2P+4F/Mn2JEmbAFdLuhf4AHAusBywA/AeYC6wI3BfXwrKyfEE27v0Q9whhDCo9GNHkX7TdjU1YCvgHADbdwEvAPsBZ+d1z5J+7znAHcAm+eeKkm6oIuAQQhiM6lhTa8ekNtL2rMLzDttzgLcK67a2faztXwCPAusAL9jeursDS5og6Zb8+HpePUrSFEl/kHRa3m8ZSZfnJtBbG9fuJM2QdKakOyVdWDjuSZJ+J+lSSdc1rv1JOiqXdaukjbqIaVI+7ozLLvp5796pEEJYCHW8ptaOzY/PSFrN9p/zfQ0rSdoH+CipRgZwvaRLgCeAdYHvtTqopFGkO9u3sT0zH3tlYC1gPWA2cI+k0aRa4B62Z0k6EpgInA+sBky0/aKkqZLWA94NjLG9aR6N+q5c3tbAaNtb5HHQziM1my6geJf+HX9+2b1+t0IIoY/q2PuxHZPa2aQOIJOBLwHXkpLXqo0dbJ8u6WJgb9Id6r8BVpe0L3BUF8ddA7irMeWB7Y78gc6w/RqApIeB0aQbBA+WNAtYk9QECvCw7Rfz8oPAssAGwNX5mG9Kuj9v3xCYIGlafj68929FCCEMnBrmtPZLarb/kO9E3wt4yPZ5AJKWB4qTS00k1ZImkxLb0sAXgF2AOzs59JOk3pNL2H5d0oi8vqOwT6OmdCAwxfYdkk7vZHtjWcBTwDjgUkkjgbF5+yPAxbaPzfGP7Ol7EEIIZahjR5G2S2oAtn8P/L7Fbu8H7rXdmMbgH5JuBzq9rmb7JUmnArdIehX4JakW2JmpwDmSHgWebRHHJcCOku4gJbjHSM2XlwPbSbqNNGzMucDFLY4VQgiliebHevkB8ANJX2J+besfwKFdvcD2BcAFTat3KWxvLD8BrN3J68cWlicDSBoO7G7bkpYBbgaetm1Sr80QQqilGua0oZPUbF/U9PxVFpzbZwGFa1kNX7d99wCEtgIwpTBY52Tbbw9AOSGE0K+ipjaI2B5fUjnP0YvBOkMIoS5qmNMiqYUQQuibqKmFEEJoG9H7MYQQQtuImloIIYS2UcOcFkkthBBC30RNLYQQQtuoYU6LpNZO1l5p6apDYLER9Zj44bcXHVN1CGy/y3eqDgGAv99V/by3n1rjXVWHwAeWW7LqEACY+1xH650GiaiphRBKVYeEFtrX8Oj9GEIIoV30Z0VN0rHA5qS8NMn2H/P6s0nTdkEaeP4J25/t6jiR1EIIIfRJfzU/ShoHrJjnj1wXOJk0kwq29yns99/AL7o7ViS1EEIIfdKPrY/bABcC2H4gT4y8AEmrACvY/t9uY+q3kEIIIQwpknrzmCRpRuFRHFB+BeClwvO5eZD3okOB01rFFDW1EEIIfTKsF82Pts8Czupi80xgTOF5h+153UQlLQ6sb/ugljH1OKIQQgihYJh6/mhhOrAzgKS1gWeatm8P3NCjmHr5O4QQQghA75ofW7gKWFTSdOAU4HBJJ0paNG8fD9zek5j63Pwo6aPAONs/aLHf6sBw2w+12G8MqfdLt/t18rotgRm2Z/XmdSGEEBZOf3Xpz02N+zetPrywvWWzY0PLpCZpOHAqsBZpZuazbf8CWIx0z0Bjv6OAnUhtow0TgI2AxYGHCvtdY/vOwmuvAY4Ctss/m2MYC1wAPJZXnQpsDFwD7A48DszK+14GLNXJr/K67U8Vjnkh0BjmYHPg1rz8D9v/1umbEUIIYZ7eXFMrS09qal8BHrN9QE5wv5J0Wxf7HmB7gW1dVTslLQLskp/2ZPya82wfVXj9xp3tZPvTknYAptueKWkUsKXtqU377ZqP8x+5/IvzhcxekfRz4ITe1jBDCGGwq2FO69E1tY+Q2jux/TbpYt06Xez7bkmr5vsJWjEwJz/cg/1745PAio2YSPdAzCPpvZL2lnQu8IrtjwNvSfp/kvaVtHI/xxNCCG1n2DD1+FFaTD3Y525yUlCqdm0O3NfFvp8G9gMmSfqgpIuAAzvZbwlgFPB74Hpgdu/CnudEYOtO1r/G/CbIUfl50evAA8A+ts8DsH0usDfwp67ikbSEpLMl3Szpd5Iaza+7Srpe0n35bngk7SXpRkl3N+7HkHSUpJMl/VbSHyVtltevJ+lWSddKOjW/b0haQ9J1ubyf9O0tCiGEgTFM6vGjLD1pfvx/wAmSfk26pnae7ae6qM2cWWx+lLQH8G/AooV97gW+mNe/QoshT1r4Jql5tFHe4sCVwIeArSW9QkpqK0raCNjJ9mvAj4CV8ms6O+7zzG8aLfpP4G7b+2jBF75g+5OSPktKjIcAV9o+V9KSwG3Mvz9jru3tJW0IHJG3nQrsZfsvkj4PfC7vexqwt+2nJZ0kaZzt6cWAcsKcBHDq6Wew597F+xlDCGHg1LD1sXVSs90h6URSR4tWNaqlJI0GhpNqY3OABeZZsH0ZcFnjuaSjgTN7EOuyklYjdVBpvJdvU2i6tD2HlMy+S0oqd+ZrbzvbnlzYb/figSXdYLuzGl+zjwFfysdwfi3AtLz9QWDHvPxlSSsAc0kdZRpuLezbGApmpO2/5OW7mZ/UNgB+kctYKm9bQPGGxpmvd/R3M24IIXSpv8Z+7E897dK/P6lGMa2xItfIip1CZpCaH3ciJbLXgKu7O2gexPLLwM25N+SdXez6HCmBTSI1HT7Yw7j72yOkHpoXNA3h0kjcjUS3HPBJ29tKei+wW2FfF342/keMkPRe238Ftirsez8pIb8saTFSggwhhFqo4cwz/TdMlu0rSU1/C5D0jma8nBD2InXo+DDwU0nvA85v1ICajv0kqUmveIyjOjnu+eRmRWCz4l8RkqYBz9vurFmxp74L/EzSfqTk+rku9vsHMFvS7aQbBl9scdzDgask/Q34X1INF+BbwJWS3iCNi7ZXLjeEECo3mGtqAKdKerlp3b22D+5Ngfka0/mkBLhbbt7cA/gqcLGk3Wy/1ZtjNjQ3K/bCn3p4/H+QaqNFexa2P1R4/plOXn9UYXkO6S55gFttbwAg6RByEsy11816ElsIIZStzF6NPdWjpGb7u6RaSq/Zvqjp+Ws0JYZ8q8CZ9OzaWuM1R+XFrpose8z2O3poStqTQsIC7rd9wMKW1YWDJf0rqTnycVIP0hBCqLUa5rQYpb8rtn8O/Lyksk4mTYoXQgiDxmBvfgwhhBDmqV9Ki6QWQgihjwbr2I8hhBDCOwzajiIhhBBCsxpW1CKphRBC6JtofgwhhNA2apjTIqm1k02Ovr7qEJh+xISqQwDg3Usv3nqnAfb3u06vOgQAlttkoG6v7LlLfvGdqkPg9bferjoEAEaNGFF1CP0muvSHEEpVh4QW2ldP5i4rWyS1EEIIfTI8ej+GEEJoFzXMabWsPYYQQhgEJPX40YNjHSvpFkm3S1qnadteku7M27q9cB81tRBCCH3SXzW1PLfmira3kLQuaSzciXnbOsA4YFPbHd0cJsXUPyGFEEIYaqSeP1rYBrgQwPYDwLKFbXsDTwI3SbpY0vLdHSiSWgghhD5ZROrxQ9IkSTMKj0mFQ61Amgi5YW6eTBpgdeBvtscDvwKO7Dam/vwFQwghDB29uU3N9lnAWV1sngmMKTzvKDQ1zgWuzstX0mK+yUFfU5M0StKW/XSs1SWt2R/HCiGEdjdM6vGjhenAzgCS1gaeKWy7g3x9DRgP3NdtTH36TSog6QZJd0t6NC9/RNI1wHLA7p3s/x+SDu7iWEdImpYf0yVdmzdtBIwdsF8ihBDaSD9eU7sKWFTSdOAU4HBJJ0paFPgJMF7SNFIt7bvdHWjQND/a3lrSeGCs7ROg6yFaJG0BbEFql93C9i1NxzoOOC7v+zHgi32JSdKqwAm2d+nL60MIYTDrr96Pualx/6bVh+efbwKf7+mxBk1Sy5YDRucun+sDSxc3StoX2By4B9gNMHBIXv872z/q5Jg7AFMHMugQQmhHMUr/wtsAWBfoIF08dNP2823/tGndyQCSlm5aj6T3A5+gRW+awv4TgMbIrFOBXwOjJE0B1gam2z5I0jLAecAypCbenWz/U9IMYAYpIT9ue9d83JOAzYAXgCWBA20/JOkoYEvSrOmH2L67J3GGEEIZhtfwAtagSWqSFiEltSeBV21fJGnPwvZPAkd0d+e6pBNsX5OXxwA/Bfa23ZwcO3vtKOB4YBvbM3N305WBtYD1gNnAPZJGA3OAPWzPknQk6SLn+cBqwETbL0qaKmk94N3AGNub5vbju3J5WwOj882Iy5KS5A6dxDUJmASw4rYHMnr9ic27hBDCgBBRU1sYBwFTgP8jJZc9ihttXw9cL+lg26cWtzWvk7QZqXb2LdtP9LD8NYC7bM/M5XXkBDrD9mv5uA8Do4ERwMGSZgFrkmpgAA/bfjEvP0i6wXADcndV229Kuj9v3xCYkC+OAgzvLKhiN9k1J1/bMjmHEEJ/qePYj4MiqUlaBdi40Fw3PddyOnOgpOYazQeBUwvPNwV2s/0SPfckMFbSErZfl9SYFKk4bEsjqRwITLF9h6TTO9neWBbwFGkImEsljWR+78tHgIttHwuQt4UQQm1EUusj209K2q3w/KfQZe/HR2xvV1yRu/4Xj3dSH2J4SdKpwC2SXgV+CVzbxe5TgXMkPQo82+LQlwA7SrqDlOAeIzVfXg5sJ+k2YBZwLnBxb+MOIYSBEpOELoSeXPfK/kXSDU3rPthPMVwAXNC0epfC9sbyE6SOI82vH1tYngwgaTiwu23nDiY3A0/n37fbO+dDCKFKUVPrZ4Ua2T6FdX1OYLYvaiwXrmU1fH2Aeh+uAEzJHU9GAJNt12Pe+RBC6EZMEjqI5MEzyyjnOaDb+YFCCKGOapjTIqmFEELomxpeUoukFkIIoW+GxX1qIYQQ2kXU1EIIIbSNRWp4US2SWgghhD6JmloIIYS2EaP0hwH1lW1XqzoErn3k+apDAOAPz75adQh8ao13VR0CV190NLPfqv62x52/eEzVIbDZ3nu03qkETzz5ctUhAPDoydu13qmFGua0SGohtLM6JLTQvmo480wktRBCCH0TYz+GEEJoG8MjqYUQQmgX9UtpkdRCCCH0UQ0rarW8zhdCCGEQkNTjRw+OdaykWyTdLmmdwvr3S/qrpGn58Y5pvYqiphZCCKFP+qtWJGkcsKLtLSStC5wMTMybRwO/tH1IT44VSS2EEEKf9GPvx22ACwFsPyBp2cK20cA/e3qgfm1+lLRTi+0b9fA4EyQt2YP9lpTUci4ySatLWrO/9gshhJBGFOnpQ9IkSTMKj0mFQ60AvFR4PjdPnAwwEvhcbpY8VdKIbmPq7S8h6RpJN+THFY11efMB+fnHJd0s6XpJl0laIW8/rulYhxaOdYOkF/OmLwJjCvutK2m6pN9J2jSvuyHv88XCfmdKWrWTsDcCxhb2m5LL+3uh7KWb9wshhNC1Yb142D7L9saFx1mFQ82kcM4HOmx3kF53re2PAOOAWcBXu4upT82PtrduscspwI62/57bSo8B9oN5yeh025fb/oGk04Albb+St3XmKOALwGzgl8C2fYm7EP8eOZZbi79Lb6vSOYGeYHuXhYknhBAGo35sfpwO7AxMzx1BnimUsYjtubY7JP291YH61Pwoaan8WKyLXV6z3Sj8XmD5xgbbW9u+vLDv+4Ef5OW3CusvlLR3Xl7U9l9tvwy8LqllMpa0maSzJZ0NTOpit9UlVT9AXwghDELqxaOFq4BFJU0nVYoOl3SipEWBz0u6TdItwAbAOd0dqK8dRc7MP+8AfgysK+mywvarJR0N3AX8G/OT1ryaGnAnsDKwErCipC2A/5a0Yd51V9vP8E6vAb8B1ulkW9HvgQfy8mebN+bre28AnwHOat7emXz97jv56VTg18AoSVOAtYHptg+StAxwHrAM6Q+HnWz/U9IMYAawPvC47V3zcU8CNgNeAJYEDrT9kKSjgC1J/ycOsX13T+IMIYQy9FdFLTc17t+0+vD888L86JG+Nj82D3f9R1LV8Zq8/dTcNPcB4FDb/8j7vWD7ywCSPgx8FHgbuBR4H/B6ft6s+NYtA+wIXNcixjeBN3NZs4HFm3Y5HNgJOE3SRbZf6e54kkYBxwPb2J6ZL2KuDKwFrEdqGr1H0mhgDrCH7VmSjiR1TT0fWA2YaPtFSVMlrQe8Gxhje9P8V8ldubytgdG5i+uypCS5QydxTSLXRD976HfZZIdoCQ0hlKNthsmStHh+7UjSBT7bntvUvroYcCgwUmmDgJMaG23fB9wnafW83wfzpidJ1cvnCsd6ISeAV4E3cttqV+F9VdLLwAhSrefPpGRZjP8bwAzb/yfpMOCcQlNnV9YA7rI9M8ffiGGG7dfycR8mdT8dARwsaRawJqkGBvCw7UZnmAeBZUnV6avzMd+UdH/eviEwQdK0/Hx4Z0Hli61nAZx081/c4ncIIYR+oxoOlNWXpDaNlHTeJPVEOa2L/c4A9rP9CKTrcMBNkm6xPTuvWwS4ANg7JznyjXc/BzZlfq1tMqkJc3GguxvwTgRWBDqAuaQk+AypZkc+/jKkJHwSaWGGpO8Do1r83k8CYyUtYfv1QrfSjsI+jaRyIDDF9h2STu9ke2NZwFOkXj2XShrJ/N6XjwAX2z42xz2yRXwhhFCqGlbUep/UbJ/QvK6LWpNZ8ITfmUXzz78U1v2F1GFkUXLzoe2/AV/qQWyPA493F1+uaS3wO9i+s3m/To79kqRTgVskvUrqhXltF7tPJdX+HgWebRH2JcCOku4gJbjHSM2XlwPbSbqN9MfDucDFLY4VQgilGdYmNbWe+hrwQ82/iVrAkY1aGoDt2fma02WSGglwGHCc7eqnLm5i+wJSzbJol8L2xvITpI4jza8fW1ieDCBpOLC7beda5M3A07ZNvg0ihBDqqC1qap2xvV3+uXVh3cPAp3rw2qvJ15R6WWajrD17sO9FPTzmvP0K17Iavj5AvQ9XAKbkjicjgMm2Y7riEELttW1Sa0e2x5dUznNAy6G+Qgihbtqm92MIIYTQLr0fQwghhGh+DCGE0D6iphZCCKFtDKtfToukFkIIoW+iphZCCKFtRE0tDKi1ll+q6hBYZrFuJ6UtzZgPLtp6pwH2geVaTt5eitffqv62x832bh4DvXy3nTOl6hAAOOx7B1UdQr8ZVsOeIpHUQmhjdUhooX3VL6VFUgshhNBXNcxqkdRCCCH0SXQUCSGE0Daio0gIIYT2EUkthBBCu4jmxxBCCG2jhj36GVZ1ACGEEAYn9eLR8ljSsZJukXS7pHU62b6ipNmSFu/uOJHUQggh9E0/ZTVJ44AVbW8B7Auc3Mluk4G/tQppwJKapJ0G8Njj+/CalrNw5/0GLO4QQmgnw6QeP1rYBrgQwPYDwLLFjZI2BAw81jKmvv0q8wq6RtIN+XFFY13efEBhv01yldKF/S3pDkmbdnP8P0malh//J+mwvOlb3bymsf/f88/z86Z/b9rvpkIsN3QWdwghhK71pqImaZKkGYXHpMKhVgBeKjyfK2kY6XUjgROAo3sS00J3FLG9dQ/2uUvSNsB5tj8HIOkS4Cu2X+nmpU/Z3i7vvzWwfg/KGi9pCeBB2+O72bWjGHshqfWKpFWBE2zv0pfXhxDCoNWLjiK2zwLO6mLzTGBM4XmH7Y68/EPgRNsz1YOeKQvd/ChpqfxYrJt9dgAuB7Zo1IyA8cClA9TcdyBwo6SvNsUxTdJnBqC8EEIYctSLfy1MB3YGkLQ28ExeXgHYCPiqpIuAtYGfd3eg/ujSf2b+eQfwY2BdSZc1Nkp6F/AycFRXB5C0gu0Xu9h2Q15cDPhZd4Hk6uoBwHDbe0s6UtLRwDGQanGtfx2G5VrkDbbPbN4oaQLwnfx0KvBrYJSkKaQ3fLrtgyQtA5wHLEP642En2/+UNAOYQap1Pm5713zck4DNgBeAJYEDbT8k6ShgS9LfRIfYvrspnknAJICvfedkttv5iz34FUMIYeH1Y5f+q4CJkqYDs4B9JZ0IfNv2xvPL0zRgz+4O1B/Nj81zSvyRlHEbzXmjgNUK2z8ODAduK6x7HnhHUms0PQJI2gxozCdyexfhjAb+avtX+fVHS1rX9tuSnujJ70Oq9u7c2QZJo4DjgW1yVXgYsDKwFrAeMBu4R9JoYA6wh+1Zko4EJgLnk96LibZflDRV0nrAu4ExtjeVtChwVy5va2C07S0kLUtKkjs0vUfzqvRX3P+Ce/g7hhDCQuuvnJabGvdvWn14J/uNb3WshU5q+Z6BRYCRpHZR257baPu0/RjwmKQPAYcAnyC9F3OAH9r+SzfH/hDw0/x0RVIt6rm8bWPbM4r72/4H8CtJqwDfJV18lKTXgRObDj9M0im9/HXXAO6yPTOX15F/zxm2X8txPUxKriOAgyXNAtYk1cAAHi7USh8k9fLZALg6H/NNSffn7RsCE/JfJ5D+GAghhFroyTWusi1sUpsGnAO8SaoyntbNvlOA/wIOIyW1DUk1l7FdvSAnvK1zjejSHO9Otue2iOtnwMG274d5TaBXSNrK9uy8z25A8Sa+11scE+BJYKykJWy/LqkxI2ZHYZ9GbelAYIrtOySd3sn2xrKAp4BxpGuMI5n/njwCXGz72Px7jOxBjCGEUIoa5rSFS2q2T2he11nm1vyVd9uek9fdA1iSbHfZbCZpY9JNd+cCb5FqYseTakddvW4xUpJtaCSyeb+v7ee7KrMrtl+SdCpwi6RXgV8C13ax+1TgHEmPAs+2OPQlwI6S7iAluMdINdnLge0k3Ub6fc4FLu5t3CGEMBBqmNPKGfvRtiV9i1QTaSQikS4CdpfQdiD1fNnf9kt53e9Jd5yvRbrG1Jn9gB/nrv2N2tDRLW4f6OnvcgFwQdPqXQrbG8tPkDqONL9+bGF5MoCk4cDu+X1aBrgZeDq/N/stbMwhhDAgapjV+j2pNTp3NN+/ZvtG4MZeHutK4MqmdS+Rrpd197oHgH/tTVmF1xbvXZvWtPnrzb0P+8kKwJTczDoCmGz77QEoJ4QQ+k2M0j/I9PAWgP4o5zlgQhllhRBCf4lJQkMIIbSPSGohhBDaRTQ/hhBCaBtt16U/hBDC0FXDnBZJLYQQQh/VMKtFUmsjb3R0tN5pgM18462qQwDgpTlvVB0Cc5+r/vMAGDViROudBtgTT75cdQgc9r2Dqg4BgFO+0d3AS+U5drsfLfQxejD5Z+kiqYXQxuqQ0EL7ql9Ki6QWQgihr2qY1SKphRBC6JPo0h9CCKFt1PCSWiS1EEIIfRPDZIUQQmgj9ctqkdRCCCH0STQ/hhBCaBs1zGmR1EIIIfRNHWtqw6oOIIQQwuCkXvxreSzpWEm3SLpd0jqF9etJuj6vnyKp28rYoE9qklaVdFE/H/OUXuy7p6T9+rP8EEIYDKSeP7o/jsYBK9reAtgXOLmw+XFgG9ufAOYAH+vuWNH82Anbh1UdQwgh1F0/Nj9uA1wIYPsBScs2Nth+NZWlxYFlgce6O9Cgr6k1KDlL0r6SfiRpmqQ7Jf1X3j5W0m2Spkv697zuTknH5X2nS/pAY3035Rycj3ObpPF59YclXSHpQUm75v02zlXm2yT9LK8bn6vPv5F0v6SD8vrRki6VdLOkMyTNyOuXknSBpJskXVn8oEMIoWq9aX6UNEnSjMJjUuFQKwAvFZ7PlTQvP0m6AHgCuB94obuY2iapAacAdwMdwIu2xwObAptJ+jDwBeBI2+OAM/JrVgB+lff9NvCd7gqQtDmp6ru57c2AW/Om5Wx/CtgCODSvexzYFhgHrCJppbx+FeDzwMZAo9nyP4FLbG8JHA8sn9dPBi62vRXwE+DfO4lp3n+U6y+Z0v07FEII/Uk9f9g+y/bGhcdZhSPNBMYUnnfYnjfNhe3dgPcCI4AvdxdSuyS1scBHbP8UWB+4EiC/KTcDawDfBbaSdCLwnvy6l2zfm5fvAlZuUc7HSMmno3B8gFvy8xdJSRVgE+A0UpJaFhiV1//O9tu23wBeyes2AK7Ox3gaeDGv3xD4uqRpwDfzcRZQ/I/yyZ33aBF+CCH0n17ktFamAzsDSFobeGZeGdIyMO98+1dgqe4O1C5J7U7gJkmnAn8EtgPI1ddxwH3AbNtHAD8D/ju/bjlJH8zL/wrc26KcR0i1L/LxG/N6FCfOcv55JHAIqQboTrYXl5/KcSJpTdJfJI3yvml7fK4ZfrNFfCGEUJr+6igCXAUsKmk6qdXtcEknSloU+ELu+Xgz6Q/9/+nuQG3TUcT28ZKOBtZh/pvTAZxn+2FJ35a0LTAXODW/7B/AQZLWA14F9mxRxlRJ4/I1t1eBb3Wz+6XAH0gJ9dkW4R8HnC/pMFKN8em8/njg55KOyeV9A3igxbFCCKEU/TVJaK6F7d+0+vD886z86JFBn9RsPwHskpeP7Ga/Y4Fjm1Z32H7HdLi2x3ZznP9sWnVn0/ax+ecJwAlN+z4ETOuknOdtbw4gaSNgtbz9RWBiV7GEEEJY0KBPagNF0vrMr9E1TLD99gAUt6Wkb5KaI98AvjYAZYQQQr+q44giQzqptaiR3QuMLymO64DryigrhBD6S0wSGkIIoW1ETS2EEELbiKQWQgihbUTzYwghhLYRNbUQQghto4Y5LZJaCCGEPqphVmuXYbJCCJ2Y9dZbVYcQ2lh/ThLabzHZbr1XGDIkTWoaPXtIxlCXOOoQQ13iqEMMdYmjDjHUVdTUQrNJrXcZcHWIAeoRRx1igHrEUYcYoB5x1CGGWoqkFkIIoW1EUgshhNA2IqmFZnVop69DDFCPOOoQA9QjjjrEAPWIow4x1FJ0FAkhhNA2oqYWQgihbURSCyGE0DYiqYVQU5I+IenzSharOp4QBoNIaiHUkKQfATsC/wmMAM6tNqKhTdIGkq6QNE3S4pJ2riiO0ZK+Jen7khaTtHYVcdRZJLUA1ONLW4cYamQt24cDr9l+E1ihiiDiM5nnh8CXANueA+xVURznAXcDH7X9BvC9iuKorUhqoaEOX9o6xFCXE/lcSSsBlrQ0UFXzY3wmme1/Ao3u4kuXXX420vZvgbn5+aiK4qitSGphnjp8aesQA/U4kR8AnA2sDVwCHFZBDEB8JtnNkn4ILC/pCOCBkstveEHSjsBwSZ8AXq8ojtqKqWdCQx2+tHWIAUgnckmVnchtPwJsX3a5nYjPJJV9tKQJwF+BR2wfV2b5BZOAycCrwOeAPSuKo7bi5uswT/7Sbkj60l4+hGM4EhgNTAB+CbzP9v4lx3Ah82tHAHOAe4Ez8zW2MmMZ8p+JpH9pWjUHeNpxAq2dSGoBqMeXtg4xFGKp9ESea0e3kzoFbAV8EHgJ+LDtr5QYR3wmqexrgeVJNdWxwF9InXcm276hxDj+F1gOeBF4L/A08DzwddtPlBVHnUVSC0A9vrR1iCHHUfmJXNJvbW9feH6t7W0lTbM9vsQ44jNJ5f8G+ILttySNBM4B9gWutL15GTHkOH4CHG/7GUlrAl8BLgK+a3tiWXHUWVxTCw2vATs0fWl3Aa4Eyjp51SEGgNPp5EQuqcwT+UhJq9p+QtJ7gHfl9WX/FRqfSbKC7bcAbM+WtLLtVyTNbfXCfraG7WdyHA9J+pjt/5K0eMlx1FYktdBQhy9tHWKAepzI/x04O5e/CHCYpEWAq0oqvyE+k+R2ST8FrgY2Bx7P6ztKKLtopqRdC3Eor1fXLxlaIqmFhjp8aesQA9TgRG77AWDrTjadUlYMWXwmqczDJW0NbAD8HrhE0jBgjzLKL9iLNMrMHsCTwO75j53jS46jtuKaWpin8KV9inRvlEknk+eHWAwnknraNU7kK9reQ9INtjtLNAMRw6bAIcCy5L/CbW9VRtmdxBKfSYphHRb8PG4to9zQO5HUwjx1+NLWIYYcR6Unckn3k242fjCXTR4WqXTxmYCk84ElSZ8HpJvAvznQ5XYSx4HAfsDMQhyblh1HnUXzYwA6/9ICpZ686hBDwXPAG6QT+Sfyiby0mgmpZ989JZbXqfhM5vmg7Y+XVFZ39gbWL/texcEkklpoqMOXtg4x1OVE/oCk43K5jZradSXHAPGZNNwjaTnbfy+xzM78ORJa9yKphYY6fGnrEAPU40T+Wv45Nv80UEVSi88k+SjwqKSH8/Oqmv1mS7oF+B3z/9gpvRm0ziKphYY6fGnrEAPU4ERu++iqym4Snwlg+6NVlNuJs6sOoO6io0gITfJQRB8CKjuRS9oH+BppypklgBdtj+3+Ve2r6s9E0jLARApTvdg+q6zym2J5T1Mcj1QRR11FTS0A9fjS1iGGXGYd/irfF9gMOAL4EXBwFUHEZzLP5cBNpN6XT1PRtF2SzgZWBcbkVc8AO1URS11FUgsNdfjS1iGGupzIZ+abjIfbfi7ft1aF+EySDtvHSDre9jclXVpi2UX/YntzSccD3wZ+XlEctRWThIaGDtvHAA/aPhBYaYjGAOlEvjppPrN1gQ9XEMMUScsDL0m6hjRCfxXiM0lekbQksLSkTYDmAZbLMif/XJLUUaSK/5u1FkktNNThS1uHGKAGJ3LbP7f9N9vfB3az/dmyY8jiM0m+BMwFTgV2Bw4qufyGb0haFriG1APygoriqK1ofgwNxS/tgVTzpa1DDFCDE7mktUk32o7Jz3GJ86gVxGcC5HEmlwbepPzxN4tx3J0Xf5sfoUn0fgzz5C/t6MZz208N4RjeAN5POpFPLXPusBzDvcBRwEPMvx/p4W5eMpCxDPnPRNKpwBakzwNS78vdyiq/EMcXgK8DbzP//0UMk1UQSS0A9fjS1iGGQiyVnsglXWd7mzLL7CKOU4nPBEl3296orPK6ieOPwHjbVV1jrb1ofgwN42xvEDF0fiIHSjmRF2Z4/p2k/YBp5GleKrofach/JtmfJC1ue07rXQfUXyKhdS+SWmiow5e2DjFAtSfybxSWVwE2ycsGqrimNqQ/E0kXkt77pUnjcc7Iz0utsUqalBefzjHdwvw/diq5CbyuIqkNcXX40tYhhiaVncht7wUgaSnbr+ZlASPLjCM+k3kml1xeVxrTDv2+0igGgbimNsRJWqWrbbafHCox5DiKJ/I1gcpO5JJus71ZXhZwte3tSyw/PpMF4zjE9g/z8iLAXrb/p6zyC3FsnqfcacSxoe1IdAWR1AJQjy9t1THU5USeY7nJhZmuJd1ie4syY8jlxmeS4rjZ9paF56XNuN0Ux622Ny88r0WHojqJm69Dw46NBdtzgS8MtRhsP5lPlJ8tLD8LVHHS+IukfSWNlrQr8I8KYoD4TBokaam8sDiF4brKjqPpeVVx1FYktdBQhy9tHWKAeiT4A4AVgF8AG1FNJxGIz6ThWOCG3AtzGvDDkstvuETSFEmflnQmML2iOGorOoqEhsaX9k7SxJRVfGnrEAPkE7ntV6s6kecOEcd2Ethptssc1SM+E8D2jZLuAtYAvmv7bzmoDWzfU2Icp0kaB3wMuMr2FTkOOa4lAXFNLRTkv8jXAJ6s6ktbkxgmAMcBjRP5qbYvKqv87jRfayupzPhMulDF51HnOOogklroVh2+LEP1RN5FXJV/HlXFUcfPpLkDyVCPow7imlpopfnCdBVKj8H2q7bvbpw8s++XHUcn6vB5QHwmDXWpFdQljspFUgut1OHLUocYoB4J5edVB5DFZ1KP8hvqEkflIqmFVurwZalDDFDSiVzS+yQtJ+kdc2XZ/n9lxNADQ+0zmdTZ+ho1+R1cdQB1EUktACCp0/t+qvrSSpp3Y2uNThwDeiKX1Oj4sD2wFvDugSxvYQyVz6Sg9ButiySdlH/eIel3+ecdkn4HYPv/qoyvTqKjSAA6v/AvaXXbj5YYw5HAibbnDMWREhq/s6RzgX2AG8pOHpLWYP4gyl2yfV4J4VRG0o6kewUbhpEHECbVDkUaqmtI/R8dDOI+tSFK0oeAS4AngF3SKi0P3ASMtr0y8FOglB5ujZ5thQFrS2vekrQacDrzm7KUl48CdgXeBxxq++mBD0X7ALfYfjsN+Vi6t5k/eG5lqk6utqcCUwfi2AsjDxt2JGmy1HuB42y/XGVMdRNJbej6GnAIMBz4V9JJfBhwHjAx71PKWTUP2HsycHxhdWlNCLb/TGryW2AsPUlfBR4GfkbqZfdvAxzK5sBI259orJB0XWH7n2wfPJAB5PfizwNZRg9VnlwlXd3Fpi+7ujnNzgO+TRqtfwdSx6FPVxRLLUVSG7r+BbgDGAH8R173BUru1aY0EeYngbNtP1Bm2U1x/Jb0uy+fT2YCVgM+avtlScuVEMatwGWS9rA9BaCK5q38XjwCTLV9Y9nlQ0qukp5vTL9TiG0pYJTt50oIY4TtTzaVfzKwRAlld6WjMUo/acis/SuMpZaio0hoXB8AmFtRDMOo/v/i7sCJpNEqjgB2ItXSXsnby0j2tv1jYEtJVb4fSwJTgM0lXS9p5Yri+E3xSU5o55Ca3spQxw4Ht0taD0DSqsB91YZTP1WfSEJ1HiSdwD8KPJTX/bppnwH/Uts+E/gsMFHSRwa6vG4sBXyYdNLcEbgM+BtpUGFIzbQDrXFT8e3AxlR3Up1r+39tH0kaSPkMSRtXFAv59oZ9SNe4Tqp4/rCqE90EUm3+DuB6YNNiL8gQzY9D2U+Y31Fkd1JPrw7gTWBOboJavYxAbFvSYaSEUvqsypJGk2pnbwHX2D4/NzP9A5gs6V5Sc9yAKkx6+VvgdeCvA11mF+ZdS7X9tKQ9gIsk7Wb77yXGsaGkaaSm8jnATrbvL7H84fmaZqPjkPKj9BnRG2x/vKqyB4tIakOU7SdItQFg3ijffyP1Ajy9gnhel/SgpCVsv065N/e+SkrwWwCr5nWrAieROtG8Hzi0rGAK14v2KKvMJtcXn9j+p6RjgL2AU0qM457GNS1JGwHfkvS/tkuJwfaEMsrpDUn72z5D0nuB04DzGiP1hyTuUwtAutnZ9g1Vx9EgaSvbN5VY3iqk3mTDSDfaXm/7R2WV30VMjQSPpAsKNbkhQdIvbH+xad1kUmeJk0qMYyfbl5dVXneUZ0CX9D3gXODMOgxwXSeR1Iaoqu8D6oykw8r6K7yTshcFlrddVZMfki63vVPhefH2gspGYZe0je3rWu9ZDklL236l9Z79Vt4CAxPk+dwWae6ZWVIs04HvABNsf0vSdNvjyo6jzqL5cejqIN0LtA6wPHALqUv/zcCLFcW0aRWFFhN8dzc8l5DgR0raAdgGmA2sLul45l/TKZWkr5Fm3p4M1CaplZHQ8ufw76T3/Y18jflx0n1iPwQs6Wjb1w50LE0OI31Pj83Jtezyay+S2hCVh796NE++uGruHLEucLntx8qIoTAUUeOE3bgwP28XyhmKqHGj736kzipvAVuSkvsfB7jsIpP+qHiINLPzeNK1vmH0oFY9ADa1/RMlB5E+q0eB1W2vNpAFV92SYPtK4MpCPMNsd0i6lNRMPQe4nJKTiu27JM0mjfRzn+3vlln+YBBJbQiT9A1SJ4lGF+lpwD/LKr8uQxE1RtGQtC1wse038z1Rj5d5XS/H8hp5RA9Jr9j+Q14uMwwkjSMNw5TD8mmSdrC9vaTru3lpfymOKPJV0n1zr5dQ7jxN1/S+LekSYIlGD9AqhjHLvYQ3I31Xd5N0he2flx5IjUVSG9q+AJwNHC7pceCIwtiLpZB0Gukm56tsP1lm2U1xvAfYALhckoGVgGtIY2GWGccoYEVSTW1pSR+j5Glecq3sY8AXmzaVPXRZI7lvDfzG9iuSvgz8sqT/pyvl8vdJIfmPFY3HWfRZ4BP5Npj/Bm6kPnPs1ULcfD20/dP2j2x/FrgB+LWkFUuOYSzpfqwjJJ2X7xmrwnnAvra3tz0RWJ90LaXMbvUCxpGGLdsZeBepqWuHEmOANLLMItRnzrSi1UkDTJfhw5IeAzaxfUxe96KktfMoK1Xcr/aGc+8+2x2UMyjAoBJJbWib95e37d8C3wB+JqnML8ps25fZngScSrrJ94Mllt+wSHGkinziOI80r1lZXrV9te2DbR8BPGb7O7a/XWIM5KG6fgwc1NUuJYYDqSYyOy+/Rhr9pQz3AWuTrj1Pzuu+Bfw3qTn0v0qKo+gBSd+StH6+fPBgBTHUWiS1oW2BqVRs3wf8kopm0c3Xj/YFfpJ7dpXpEUkHSloS5k3N8z3g0rICsP2ZplXFGlqptxrkQXM3yE8bHUU+lHsBlvpHh+3bbTfGJX2L8i6byPacfE/cbEmfs/2U7a1tb277TyXFUXQ/8Dxpvr2XSSMAhYK4Ty28g6SRtme33rNfyvqh7UOa1n0GWM32yWXEkMtchDRixlakUdifAc6xfU9ZMdSNpEnA+cCVVdwj18VAyl8Frih7/Eeli2mjbZfWkaqLOH4KzLD9P5J+CMy0fVSVMdVNJLVQS5IWKfx13vZyDbHl9Da2nyohnAVUNdqMpDO62HRClZ2KqibpFNLg2zfZPqHqeOomkloINSBpPGlg6cbAuRNIPdsorHO+9lhWHPNWF56XEkdYkKQLWfAzGAvcSfoshtTwaa1El/5QmTxI7bat9rN9fKt9Bjvb0yS9zvwEtjppxu2O4m4lhDKDNHJG/LVbL5Nb7xIgamqhQnmk8ZbT29i+pYRwKifpSBactBXeWUM65h0v7P84GrOAL51/zoIFpl9xvu1hIGPYinSfXPP7QVMcXxnIOMLgE0kt1I6kZUknrEovypdN0kTbVzetWwdYx/bFJcbxYdv3SdqdNGHoL/P6dW0/UFIMI4ExtKgxlj0AtaQNC6O87GF7Spnlh9ai+THUSh6e6gLS/UAzKg6nbAcDVzetM+XeKwdpzrRtgHuADknvI93ecCtQSlKzPVvS5cyvla1NGodzgRpjjrPfSdqC9H+wWNbvSINub6M0E/gqA1F2WDiR1EIt5C71nyF12T7C9lBLaF15g3SLQZlWlfRfpJrSOsBTwHG2HyozCM+fIHQ4aZisnVq8pD/LvoU0c8UCJF0naRjwTdL/1VAzkdRCpfL1m0VJs3A/DWxr+9lqo6rMhyR9p2ndcqRhq8r0Cqln3fK57A2Aj5BmDyiNpLHAUaTRRGZJmkpK8ofYfqaE8ouznf+dlNzfSxqd/yeNgY1DvURSC5WyvX1jWdI2wBmSzs4j+A81XXXNfq7UKNKYoLfm5d/kmtJBks63vXuJcZwC/KvtmY0Vkj6Q1+9SQvlfAg4lNT9+h1Q7a8xDOKKE8kMfRFILtWH7Okk3khLb4mV2jqgD23dVHQPMb/YrPH8b+EEXI3wMpA5gcWBmYd2SzJ+SZqD9szH1kKTDbd8u6XlSM/nFkm6P2lr9RFILtWL7bUn7A++VtI3t2sy4PNRVMJrJ/sCPJDVqRcNI4x4e2vVL+lVnPS+Vp305AfgacGxJsYQeii79oVYkLWb7jbx8k+2tqo4pDE2S/gg8SeHePEkfdJ4ZXtK/2r6q0iDDO8Qo/aFSkn7ZtOq3xc1lxhLqSdJeVZRrex3bEwtz7NFIaHk5EloNRVILVVuh6Xlno2kE5nVtHxIkLSHpvZJWAvbMy+9Vski+OTuEd4hraqFqzYnr3ZK+xBCrpUlag9Sj7x2JvDA01gXAF8qMq0IfJw2TBfAYcBzpvTmHNJnsm5KOax6BJYRIaqFuTLo3akglNeAFFmx6bRCApN2Am0qNqEK51+G831fSBqSu9F8D9iQlust45wgsYYiLpBbq5gXbFwBI2rvqYMpi+2VJRwMjSYm9MWL/mZI2J82CXeY9YpXL3efvI812/d+k92YV23/M26N5OrxDJLVQtZUkNbrtC3ixymCqZHv7PIjwHOB64P3A50k3AX/YQ6+r8v22twGQNI53TqJa2vshaXlg6WJHkVBPkdRCpWyv0c3modYE2WBgGWAP29/IN6SfRdcjjrQr5wGuf0jqUHQp8HieueAxYEA7zkgaa/tOSZ8iDZO1Wi431Fj0fgx1dlzVAVTgItK1oldI85lhezpwg6ShNneYgNeA75ImTB0B/AA4F5iWlwfS93NSPXBeQNIHJN0h6fY851uomaiphdqyfUPVMZRJ0scKT0cCixWenwv8hnRyHyquzk2uT0p6F/Ae23+W9HFgUduvD3D5Hye93x/JzwUcAnwduBf4NUOo885gEUkthPrYvun5FY2FPDTTkOooYvuHhadPkcd8zGNRDnRCA7jR9r9Juj4/3wwYC/yn7Tekodo6Xm+R1EKoCdtHt9g+u6xY6kLSp2xfAWySf5bJTT/fzsvN60ONxDW1EEKdHdD0E0mLS1q8hLK3lvQrYP38/A7SxKEb5/Lj/FlDMaBxCDWQRxTZpNV+ts8rIZzKSdqQd3YUep7UkeYYUi3pSNvXDmAMtwHbkCYFPZLU+/E2YEou/1u2bx6o8kPfRPNjCPXwNgvOE3YA8COGaBOX7T/wzmuM5NsbtiTVki4HBiypAYfani3pVPLtJfk+tU0HsMywkCKphVADuVffXxo3WEv6NHAxMAZYpzAT9ZCRb3g+lnTT9fcbk6g2ri0OdEcN27/PP6/Ksfx1QAsM/SLahEOojxsLy9+03Zj5eWJF8VTtLFJT31eAfSWNJs2G3VBaLdb232w/XlZ5oe+iphZCfTQGL16ZdCL/Nqnr+pJVBlWhJW3fDlDosPG6pA+REtqA9QaVtCOFzim5vOaqoRvDeIX6iKQWQn00ah5i/hBQbzN0W1RGSBpt+2XgY6Qb0A8j1eA6SCP2DwjbU4GpjeeSfgPsnGvPocYiqYVQH6MlbQq8B3hfXh7F0B0D8wjgSkmvkkYXeSqvn1BG4ZJ+y/w/NNYDrmqeGaAxI3aoj+jSH0JNSDqyi00zbF9VajChU5IWBd4Xo/XXVyS1EELtFK5pFU9QpV7TknS57Z1yItvb9hl5DMojbB88UOWGhRPNjyGE2qnJNa2R+ecI0uDGZ5A6p4wqMYbQS5HUQqgBSYfQxcnS9jF5nx/YPrTUwCpUg2tanTVjzQUWHcAyw0KKpBZCPUxnwalmOrN+CXHUhu3ORhQp85rW25KuZv6tFo0kO62EskMfRVILoQZszwCQtAqwDnCf7WeqjapanV3TIs0IfiBw8ECX31lSDfU3VO9/CaF28nxp3wdWAU6W9NmKQ6pa8zUtiGtaoYWoqYVQH/sAE2x3SDoTuJQ02/VQFde0Qq9FUguhPuY2evflma7n5nm7Pka6rjO6yuAqENe0Qq9FUguhPh6UdBBwFbAt8BdgCWBc3v7rqgKrQlzTCn0RN1+HUBOShpEGMv4IMAM4z/EFDaFXIqmFEEJoG9H7MYQQQtuIpBZCCKFtRFILIYTQNiKphRBCaBuR1EIIIbSNSGohhBDaxv8H5csdRxxcRegAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(Y.corr(), cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144aa24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "947980a7",
   "metadata": {},
   "source": [
    "# 날씨데이터와 주가 데이터 concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c82fcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df = pd.concat([wh, Y], axis = 1)\n",
    "total_df = total_df.dropna()\n",
    "total_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f58bb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>평균기온</th>\n",
       "      <th>최저기온</th>\n",
       "      <th>최고기온</th>\n",
       "      <th>강수계속시간</th>\n",
       "      <th>10분최다강수</th>\n",
       "      <th>1시간최다강수</th>\n",
       "      <th>일강수</th>\n",
       "      <th>최대순간풍속</th>\n",
       "      <th>최대풍속</th>\n",
       "      <th>평균풍속</th>\n",
       "      <th>...</th>\n",
       "      <th>소형증발량</th>\n",
       "      <th>안개계속시간</th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "      <th>kospi_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.3</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030136</td>\n",
       "      <td>-0.020502</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>-0.119001</td>\n",
       "      <td>0.054689</td>\n",
       "      <td>0.031705</td>\n",
       "      <td>-0.007652</td>\n",
       "      <td>0.0301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>2.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>13.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023748</td>\n",
       "      <td>-0.015360</td>\n",
       "      <td>-0.096321</td>\n",
       "      <td>-0.118948</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>-0.025857</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>-0.0687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>1.7</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.019810</td>\n",
       "      <td>-0.024013</td>\n",
       "      <td>-0.055905</td>\n",
       "      <td>-0.120027</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>-0.026880</td>\n",
       "      <td>-0.045861</td>\n",
       "      <td>-0.0259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>-8.2</td>\n",
       "      <td>-12.1</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010704</td>\n",
       "      <td>-0.030269</td>\n",
       "      <td>-0.119311</td>\n",
       "      <td>-0.119290</td>\n",
       "      <td>-0.005948</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>-0.0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>-0.8</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.059410</td>\n",
       "      <td>-0.007423</td>\n",
       "      <td>0.010749</td>\n",
       "      <td>-0.031333</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>0.0407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            평균기온  최저기온  최고기온  강수계속시간  10분최다강수  1시간최다강수   일강수  최대순간풍속  최대풍속  \\\n",
       "Date                                                                         \n",
       "2000-01-04   0.3  -4.3   4.3    0.00      0.0      0.0   0.0     4.5   3.0   \n",
       "2000-01-05   2.8   0.1   4.6   13.90      0.0      0.0  18.4     9.1   5.2   \n",
       "2000-01-06   1.7  -4.2   5.7    6.08      0.0      0.0   9.8    11.1   6.9   \n",
       "2000-01-07  -8.2 -12.1  -4.2    1.50      0.0      0.0   0.0    12.3   7.2   \n",
       "2000-01-10  -0.8  -4.8   2.3    1.83      0.0      0.0   0.1     8.8   5.5   \n",
       "\n",
       "            평균풍속  ...  소형증발량  안개계속시간  겨울_change  도시가스_change  여행_change  \\\n",
       "Date              ...                                                     \n",
       "2000-01-04   1.7  ...    0.7     0.0   0.030136    -0.020502   0.100968   \n",
       "2000-01-05   3.2  ...    1.7     0.0   0.023748    -0.015360  -0.096321   \n",
       "2000-01-06   3.5  ...    1.0     0.0  -0.019810    -0.024013  -0.055905   \n",
       "2000-01-07   2.5  ...    0.8     0.0   0.010704    -0.030269  -0.119311   \n",
       "2000-01-10   2.8  ...    1.0     0.0   0.003991     0.059410  -0.007423   \n",
       "\n",
       "            인터넷 대표주_change  제습기_change  태양광에너지_change  태풍 및 장마_change  \\\n",
       "Date                                                                    \n",
       "2000-01-04       -0.119001    0.054689       0.031705       -0.007652   \n",
       "2000-01-05       -0.118948    0.018182      -0.025857       -0.020016   \n",
       "2000-01-06       -0.120027    0.037346      -0.026880       -0.045861   \n",
       "2000-01-07       -0.119290   -0.005948       0.006642        0.017759   \n",
       "2000-01-10        0.010749   -0.031333       0.002046        0.006444   \n",
       "\n",
       "            kospi_change  \n",
       "Date                      \n",
       "2000-01-04        0.0301  \n",
       "2000-01-05       -0.0687  \n",
       "2000-01-06       -0.0259  \n",
       "2000-01-07       -0.0126  \n",
       "2000-01-10        0.0407  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c7a0d",
   "metadata": {},
   "source": [
    "# 총 데이터의 기술통계량 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "609832e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>평균기온</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>13.076417</td>\n",
       "      <td>10.501693</td>\n",
       "      <td>-15.500000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>33.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>최저기온</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>9.188887</td>\n",
       "      <td>10.606737</td>\n",
       "      <td>-18.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>30.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>최고기온</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>17.607582</td>\n",
       "      <td>10.702111</td>\n",
       "      <td>-12.400000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>39.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>강수계속시간</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>2.229913</td>\n",
       "      <td>4.402864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10분최다강수</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.561085</td>\n",
       "      <td>1.995413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1시간최다강수</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>1.342055</td>\n",
       "      <td>5.106588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>일강수</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>3.758316</td>\n",
       "      <td>14.478471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>301.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>최대순간풍속</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>8.539231</td>\n",
       "      <td>2.704584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>최대풍속</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>4.995837</td>\n",
       "      <td>1.487491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균풍속</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>2.359803</td>\n",
       "      <td>0.845299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균이슬점온도</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>4.973890</td>\n",
       "      <td>11.991616</td>\n",
       "      <td>-27.600000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>25.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>최소상대습도</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>39.288422</td>\n",
       "      <td>16.350712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균상대습도</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>60.817190</td>\n",
       "      <td>14.910302</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>60.900000</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>99.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균현지기압</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>1005.800409</td>\n",
       "      <td>7.889377</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>999.700000</td>\n",
       "      <td>1006.000000</td>\n",
       "      <td>1011.900000</td>\n",
       "      <td>1027.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>최고해면기압</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>1018.639212</td>\n",
       "      <td>8.303036</td>\n",
       "      <td>996.100000</td>\n",
       "      <td>1011.900000</td>\n",
       "      <td>1019.000000</td>\n",
       "      <td>1025.200000</td>\n",
       "      <td>1040.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>최저해면기압</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>1013.397101</td>\n",
       "      <td>16.159494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1007.400000</td>\n",
       "      <td>1013.500000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>1037.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균해면기압</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>1016.083739</td>\n",
       "      <td>8.293288</td>\n",
       "      <td>990.800000</td>\n",
       "      <td>1009.600000</td>\n",
       "      <td>1016.300000</td>\n",
       "      <td>1022.500000</td>\n",
       "      <td>1039.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>가조시간</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>12.235217</td>\n",
       "      <td>1.784063</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>합계일조시간</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>5.810946</td>\n",
       "      <td>3.932295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>13.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1시간최다일사량</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>1.975042</td>\n",
       "      <td>0.829928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.630000</td>\n",
       "      <td>3.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>합계일사량</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>12.472503</td>\n",
       "      <td>6.682528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.440000</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>17.340000</td>\n",
       "      <td>31.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>최심신적설</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.069244</td>\n",
       "      <td>0.721783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>최심적설</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.261290</td>\n",
       "      <td>1.526284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3시간신적설</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.071511</td>\n",
       "      <td>0.742635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균전운량</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>4.843858</td>\n",
       "      <td>3.159536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균중하층운량</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>3.038432</td>\n",
       "      <td>2.464343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>9.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균지면온도</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>14.356811</td>\n",
       "      <td>11.195690</td>\n",
       "      <td>-12.600000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>40.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균10cm지중온도</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>14.083423</td>\n",
       "      <td>10.289435</td>\n",
       "      <td>-5.500000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>33.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균30cm지중온도</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>14.173983</td>\n",
       "      <td>9.426475</td>\n",
       "      <td>-2.200000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5m지중온도</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>14.555399</td>\n",
       "      <td>8.836704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>29.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5m지중온도</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>15.471529</td>\n",
       "      <td>6.399206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>26.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3m지중온도</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>15.690336</td>\n",
       "      <td>3.810007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>24.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>대형증발량</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>1.899833</td>\n",
       "      <td>1.794305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>8.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>소형증발량</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>3.284148</td>\n",
       "      <td>2.062768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>안개계속시간</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.061818</td>\n",
       "      <td>0.572537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>겨울_change</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>-0.104303</td>\n",
       "      <td>-0.004905</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.586323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>도시가스_change</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.011820</td>\n",
       "      <td>-0.087226</td>\n",
       "      <td>-0.004982</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>0.097878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>여행_change</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.024870</td>\n",
       "      <td>-0.160828</td>\n",
       "      <td>-0.009882</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>0.135356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>-0.120027</td>\n",
       "      <td>-0.013167</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>0.135984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>제습기_change</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.025276</td>\n",
       "      <td>-0.132446</td>\n",
       "      <td>-0.008139</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.010229</td>\n",
       "      <td>1.266279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.018176</td>\n",
       "      <td>-0.143741</td>\n",
       "      <td>-0.006956</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.134660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.019116</td>\n",
       "      <td>-0.146420</td>\n",
       "      <td>-0.007632</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.010023</td>\n",
       "      <td>0.139025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kospi_change</th>\n",
       "      <td>5381.0</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.014736</td>\n",
       "      <td>-0.120200</td>\n",
       "      <td>-0.006000</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.119500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count         mean        std         min          25%  \\\n",
       "평균기온            5381.0    13.076417  10.501693  -15.500000     4.200000   \n",
       "최저기온            5381.0     9.188887  10.606737  -18.600000     0.400000   \n",
       "최고기온            5381.0    17.607582  10.702111  -12.400000     8.400000   \n",
       "강수계속시간          5381.0     2.229913   4.402864    0.000000     0.000000   \n",
       "10분최다강수         5381.0     0.561085   1.995413    0.000000     0.000000   \n",
       "1시간최다강수         5381.0     1.342055   5.106588    0.000000     0.000000   \n",
       "일강수             5381.0     3.758316  14.478471    0.000000     0.000000   \n",
       "최대순간풍속          5381.0     8.539231   2.704584    0.000000     6.600000   \n",
       "최대풍속            5381.0     4.995837   1.487491    0.000000     4.000000   \n",
       "평균풍속            5381.0     2.359803   0.845299    0.000000     1.800000   \n",
       "평균이슬점온도         5381.0     4.973890  11.991616  -27.600000    -4.500000   \n",
       "최소상대습도          5381.0    39.288422  16.350712    0.000000    27.000000   \n",
       "평균상대습도          5381.0    60.817190  14.910302   19.900000    49.600000   \n",
       "평균현지기압          5381.0  1005.800409   7.889377  981.000000   999.700000   \n",
       "최고해면기압          5381.0  1018.639212   8.303036  996.100000  1011.900000   \n",
       "최저해면기압          5381.0  1013.397101  16.159494    0.000000  1007.400000   \n",
       "평균해면기압          5381.0  1016.083739   8.293288  990.800000  1009.600000   \n",
       "가조시간            5381.0    12.235217   1.784063    9.600000    10.500000   \n",
       "합계일조시간          5381.0     5.810946   3.932295    0.000000     1.900000   \n",
       "1시간최다일사량        5381.0     1.975042   0.829928    0.000000     1.430000   \n",
       "합계일사량           5381.0    12.472503   6.682528    0.000000     7.440000   \n",
       "최심신적설           5381.0     0.069244   0.721783    0.000000     0.000000   \n",
       "최심적설            5381.0     0.261290   1.526284    0.000000     0.000000   \n",
       "3시간신적설          5381.0     0.071511   0.742635    0.000000     0.000000   \n",
       "평균전운량           5381.0     4.843858   3.159536    0.000000     2.100000   \n",
       "평균중하층운량         5381.0     3.038432   2.464343    0.000000     0.600000   \n",
       "평균지면온도          5381.0    14.356811  11.195690  -12.600000     3.700000   \n",
       "평균10cm지중온도      5381.0    14.083423  10.289435   -5.500000     4.300000   \n",
       "평균30cm지중온도      5381.0    14.173983   9.426475   -2.200000     5.300000   \n",
       "0.5m지중온도        5381.0    14.555399   8.836704    0.000000     6.000000   \n",
       "1.5m지중온도        5381.0    15.471529   6.399206    0.000000     9.100000   \n",
       "3m지중온도          5381.0    15.690336   3.810007    0.000000    12.100000   \n",
       "대형증발량           5381.0     1.899833   1.794305    0.000000     0.000000   \n",
       "소형증발량           5381.0     3.284148   2.062768    0.000000     1.600000   \n",
       "안개계속시간          5381.0     0.061818   0.572537    0.000000     0.000000   \n",
       "겨울_change       5381.0     0.000806   0.014480   -0.104303    -0.004905   \n",
       "도시가스_change     5381.0     0.000476   0.011820   -0.087226    -0.004982   \n",
       "여행_change       5381.0     0.000885   0.024870   -0.160828    -0.009882   \n",
       "인터넷 대표주_change  5381.0     0.000993   0.030612   -0.120027    -0.013167   \n",
       "제습기_change      5381.0     0.001050   0.025276   -0.132446    -0.008139   \n",
       "태양광에너지_change   5381.0     0.000740   0.018176   -0.143741    -0.006956   \n",
       "태풍 및 장마_change  5381.0     0.000737   0.019116   -0.146420    -0.007632   \n",
       "kospi_change    5381.0     0.000309   0.014736   -0.120200    -0.006000   \n",
       "\n",
       "                        50%          75%          max  \n",
       "평균기온              14.400000    22.500000    33.700000  \n",
       "최저기온               9.800000    18.800000    30.300000  \n",
       "최고기온              19.400000    26.900000    39.600000  \n",
       "강수계속시간             0.000000     2.250000    24.000000  \n",
       "10분최다강수            0.000000     0.000000    26.600000  \n",
       "1시간최다강수            0.000000     0.000000    68.000000  \n",
       "일강수                0.000000     0.500000   301.500000  \n",
       "최대순간풍속             8.000000     9.900000    24.000000  \n",
       "최대풍속               4.800000     5.800000    14.000000  \n",
       "평균풍속               2.200000     2.800000     7.500000  \n",
       "평균이슬점온도            5.600000    15.600000    25.300000  \n",
       "최소상대습도            37.000000    50.000000    94.000000  \n",
       "평균상대습도            60.900000    71.400000    99.800000  \n",
       "평균현지기압          1006.000000  1011.900000  1027.700000  \n",
       "최고해면기압          1019.000000  1025.200000  1040.400000  \n",
       "최저해면기압          1013.500000  1020.000000  1037.100000  \n",
       "평균해면기압          1016.300000  1022.500000  1039.200000  \n",
       "가조시간              12.300000    14.000000    15.000000  \n",
       "합계일조시간             6.400000     9.100000    13.600000  \n",
       "1시간최다일사량           2.000000     2.630000     3.850000  \n",
       "합계일사량             11.600000    17.340000    31.110000  \n",
       "최심신적설              0.000000     0.000000    25.800000  \n",
       "최심적설               0.000000     0.000000    28.500000  \n",
       "3시간신적설             0.000000     0.000000    25.800000  \n",
       "평균전운량              4.800000     7.600000    10.000000  \n",
       "평균중하층운량            2.800000     5.100000     9.800000  \n",
       "평균지면온도            15.300000    24.400000    40.100000  \n",
       "평균10cm지중온도        14.900000    23.900000    33.400000  \n",
       "평균30cm지중온도        15.100000    23.200000    32.000000  \n",
       "0.5m지중온도          15.400000    23.200000    29.700000  \n",
       "1.5m지중온도          15.800000    21.600000    26.700000  \n",
       "3m지중온도            15.400000    19.400000    24.500000  \n",
       "대형증발량              1.600000     3.200000     8.800000  \n",
       "소형증발량              2.900000     4.600000    13.000000  \n",
       "안개계속시간             0.000000     0.000000    12.170000  \n",
       "겨울_change          0.001013     0.006752     0.586323  \n",
       "도시가스_change        0.000285     0.005734     0.097878  \n",
       "여행_change          0.000646     0.011722     0.135356  \n",
       "인터넷 대표주_change     0.000022     0.013008     0.135984  \n",
       "제습기_change         0.000934     0.010229     1.266279  \n",
       "태양광에너지_change      0.001866     0.010172     0.134660  \n",
       "태풍 및 장마_change     0.001056     0.010023     0.139025  \n",
       "kospi_change       0.000700     0.007400     0.119500  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d38037",
   "metadata": {},
   "source": [
    "# 날씨 데이터와 주가의 상관관계 확인\n",
    "- 눈에 띄게 상관관계가 높은 부분은 보이지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a946f945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4gAAAOtCAYAAADD0UtLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdeZxcVZnw8d/TnT0B2fdF2VQUATcUEUF2RAVEJgPoi+IEcEGGgMjiDoII6qgzYmQEFDXjBjoKEchMFFRUcHTUGQc3RBAQZAtZe3neP+o2FkVVd1WdhDTVv28+/em65z7nnHurq6rz9Dn33MhMJEmSJEnqW9MHIEmSJEkaH0wQJUmSJEmACaIkSZIkqWKCKEmSJEkCTBAlSZIkSRUTREmSJEkSYIIoSZIkSeNSRGwYEedGxAcaymdFxJci4nsRcVVErF2VHxoRN0TEjyLi77rp0wRRkiRJksani4AVwOSG8n8E/j0z9wSuA06MiJnAqcC+wMuBd0bEtE47NEGUJEmSpHEoM18PfK/JrpcDX6kefw14MfAiYGFmrsjMJcCPgGd02qcJoiRJkiQ9uUzNzIHq8V+BdYGNgHvrYkbKOzKp/Ng0Xkzf9a3ZdeVYc38reN0ZxxfVv/uBpV3XnTyp7LxnTC17C71023W6rhtR1DWzpnR/7G884WNFfe9y+Cu7rrty5VBR3wtP3bOo/pSC18x///Ghor6ftcXaXdfd6PBPFPX9/nd0/zO7/n/uHTtoFEuXDYwdNIo37LlV13U3mzG9qO8/L13Wdd3Lb/xTUd9Tp/R3XfeGz36pqO/i3yn9BZ+tfd2fNwAbPa3rqs/dY8eirv/vV3d2XXfm2jOL+v5/r+h4kGGVWTnU/X9fANab3v3PfPlgWd/TJnX/y3hwuKhrhrLs2Aur8+79tiv8n8gTo+j/x0+A5T/75+OBOXVF8zJzXhtVhyOiLzOHqSWB9wIPAdvVxYyUd8QRREmSJElaAzJzXmY+v+6rneQQatNHX109fg1wPfBj4MCImBwRM4BnA7/u9JhMECVJkiTpSSAiPhQRU4DzgDkRsQh4HnBpZt4HXAbcCFwNvCczBzvtwymmkiRJknrTGryMalXJzEXAourx6VXxfcBBTWI/A3ympL8n/zP2BIqIrSNij1XU1vYRseYm/EuSJElSA0cQm4iIi4CdG4rPqb7vQW3Yloj4MrBeQ9wOmfnoiggRcRawX7XZDyzNzAOoDQVPo25ecEQcSO3eJUNAVPEXZuY1q+C0JEmSJGlUJohNZObciLgmMw+KiGOBxcCbgW2BK+vijmysGxFXN7R1LnBute+FwOtG6focYO/MXFzFr0VtONkEUZIkSepU6bLvE5AJYmsja+lPBf6SmUdGxF7URhBHM9pSuocA3xxl/38Cx0fETdRGEHeryiRJkiRptTNBbG3k7jTTgOXVdNJtgSsjYj/grBb1dqpWEzo/MxeMFEbElsBLgPe06jAzT4uIrYETqU0v/WRm/rH4TCRJkiSpDSaITUTEmcDiiDgb2BzYDPg6cDewR2ZeB1xXxR4BrJOZl0TEgsxcv0l76wKfBo7LfPxtSZsknBtTG0F8QfxtWPwxCWdd3TlUN9ectMVeTNrgWV2etSRJkqSJzgSxicz8IEBEHAo8HdgG2Bq4FrhwJC4iNh6rrWrV0/cAZ2fmbS36ezTh7OJY5wHzAKbv+tbRprdKkiRJE0sP3ObiieYz1kJEHA68FngXtWsH/xF4JrXpnyMuB/7A31YifdwIH7A7cFRm/qiNPi8oOWZJkiRJKuEIYmubATfXjfrdFRE3AHvWB2XmLXWPP9bYSGZ2kvQ9t/PDlCRJkqRVwwSxtXnA+RGxkNqKpn3AbcApdTE7VgvSNDo6M+/sos+nr+L2JEmSpInL21x0zASxhcxcyWOTwWYxWxW0P79J2ZbdtidJkiRJpbwGUZIkSZIEOIIoSZIkqVe5imnHfMYkSZIkSYAjiL2l5C8kOVzW9+RpXVddsnygqOuBoe6PfbjwzpGT+suet8GCA+grvOa65HljeKio7yVLVnZdd3Cw7DnvK7xYvah+4c8sivou63z9md3/ulh7xuSivif1lx37UMH7bCjLPiRKqi9dWvbZWPRe6esv6vtJreD34VDJ5yowZdqUrutOm959XSh7rQL0P0mHHIZLT7z0g10ah0wQJUmSJPUmVzHt2JP07z2SJEmSpFXNBFGSJEmSBDjFVJIkSVKvchXTjvmMdSgiZkbEPmPE7BARz2ijre3biZMkSZKkJ4IjiGOIiNnAOpl5cVW0LvA6YGFEfBbYCtgV+C+AzNwXeCG15/bXVRtnAftV9fuBpZl5APA8YNpIXBV7IHAqMERtaax+4MLMvGY1nqYkSZIkmSC2EhFvAHYDdgQmR8QuwA+BhSMxmfnGKvZ7VWLYVGaeC5xbxb6QWoLZyjnA3pm5uIpfC1gEmCBKkiRJWq1MEFvIzEsj4nPA14BZwNzMXBIRWzQJ3zkiplNLJncCXkwtmWzmEOCbo3T9n8DxEXETtRHE3aoySZIkSZ3wNhcdM0FsISKeA5wNfAq4D5gfEfOB7zbE7QE8SC3x+0UVu7hFm1sCLwHe06rfzDwtIrYGTqQ2vfSTmfnH0vORJEmSpLGYILa2DXASsB216w4Pq8oanQK8GvgIcFBm/joi1qHhuY2IdYFPA8dlZjY2EhH7AWfVFW1MbQTxBfG3v3ycn5kLGurNAeYATNpybyZt8OzOzlKSJEmSKiaILWTmVQARsRcwKzMHgVvrp5hGxBnADzLzZxHxUeDSiHhjY1vVKON7gLMz87YW/V0HXNfFcc4D5gFMf+5Jj0s8JUmSpAnL21x0zASxiYjYFDiW2hTPnYEZEbEDtRVHv1PFrAWQmRdW3/89IgarmEa7A0dl5r1t9H1BZr5jVZyHJEmSJHXCBLG5B6klgkPAVcAgsAxYCswEXlutMnpefaWRW1FEw8WwmXlBB30/t8tjliRJkqQiJohNZOYy4KfN9kXE1NXc/dMjYlGT8qMz887V3LckSZLUO1zFtGMmiB3KzDuoTT8dLeaKNtua36Rsy+6OTJIkSZLKeNWmJEmSJAlwBFGSJElSr3IV0475jEmSJEmSAEcQNWJys7tzdGBgeddVN1lnelHXK4eGu647qa/sbySzppW9hSb3r7kLp6dN6u++8tSZRX1vuslaXdddtnywqO+BgtcLlF3rXvJahfJjL/G/9yzruu6df3mkqO/lhT/zyX2bdF13Ul/Ze7TkLb7xBmXvs+lTu3+P/3R4qKhv+ieX1e8r+Hwq7Dsmd78W3dSpZb8Tljy8pOu6w4WfD/2FQwbDa/BOzCV99z2JFzBJ736t1cQEUZIkSVJvehL/EWBNcYqpJEmSJAkwQZQkSZIkVZxiKkmSJKk3uYppx3zGOhQRMyNin1XU1vYR8YxV0ZYkSZIklXIEcQwRMRtYJzMvrorWBV4HLIyI9YCvN6m2Q2ZuVtfGWcB+1WY/sDQzDwCeB0wDfl0XeyBwKjAERBV/YWZes0pPTJIkSZIamCC2EBFvAHYDdgQmR8QuwA+BhSMxmXk/sFeTutfXb2fmucC51b4XUkswWzkH2DszF1fxawGLABNESZIkSauVCWILmXlpRHwO+BowC5ibmUsiYos2qo92M6JDgG+Osv8/geMj4iZqI4i7VWWSJEmSOuE1iB3zGWshIp4DfAn4FHA6MD8ijh4l/uK6zaYJYkRsCbwEuL7ZfoDMPA34CrVE8lXAVzLz1I5PQJIkSZI65Ahia9sAJwHbUbvu8LCqrJWn1j1+XIIYEesCnwaOy8xssn8/4Ky6oo2pjSC+IP52g8/zM3NBQ705wByASVvuzaQNnj3qSUmSJElSKyaILWTmVQARsRcwKzMHgVvbnGL6mJHGiNgDeA9wdmbe1qK/64DrujjOecA8gOnPPelxiackSZI0YfXF2DF6DBPEJiJiU+BYaiuI7gzMiIgdqK04+p0qpnHE7zkRsaiuDfjbiN/uwFGZeW8bfV+Qme9YNWciSZIkSe0zQWzuQWqJ4BBwFTAILAOWAjOB13Yy4peZF3TQ93M7OVBJkiRJWlVMEJvIzGXAT5vti4ipq7n7p9ePRNY5OjPvXM19S5IkSb3DVUw7ZoLYocy8g9r001XR1vwmZVuuirYlSZIkqVOm1JIkSZIkwBFESZIkSb0qXMW0U44gSpIkSZIARxB7yuvOOL7rukuWDxT1vck607uu+y/v/kRR30876FVd1x0YGC7q+6H7Hy6qv3jP7buuO31q2du3v+AvansdfUhR37/4xV1d1x0eLvuZ/eKOsp/ZIwPdv1ceWlH2Phv6U/e3Oj3iqJcV9X38C7fquu6bnl92afXgUNktXj964x+6rrvuzGVFfT+wpPuf+c9+XrYuWWb3z9ubzj6hqO/lA0NF9QeHuz/2oYK6AFMndf+387WnTy7q++R9tu267kbTy9bQ+/qv/1JUf62p3T9vU/rLRnhWFnxGDBR+vpQMThW8RYv7XhX9q3eZIEqSJEnqTa5i2jGfMUmSJEkSYIIoSZIkSaqYIEqSJEmSgAmQIEZE9yu3PL6ttSJi71XY3uYR8fw24j6/qvqUJEmSJoyI8f01DvVMghgR50XE9dXX/0XEm6pdh7WInxMRb26x76K6tr5flS0A1geOblFnbkScPsYxLmgo2h44sOEcFlVft9YltxuO1q4kSZIkrQo9s4ppZp4x8jgi5gPfaRUbEdsBr6g9jGsz87cNbc2t4jYHro6ItwLrtGhrJvAPwCbV9knAZzKz2droUzo4h88B3x0tXpIkSZJWpZ5JEEdExOHA7Zn5p7qyG4GPAFOBPYEHgWOojaC+OyLWBb6fmf/a0NxLgWuA3wKPu5lVNcL3VGA+MFS1Nwv4cETcnpkX1MUG8PyImJKZK8c4h+cBszLz13Vls4FbMvM37TwPkiRJ0oTnbS461jMJYkT0AW8HtgROq9+XmXtUMdsCV2bm8rrdcyNiBrBFk2bnAIdn5oMRcXJDf5sAv6u+NgT2AfqBa4GrqphNM3PkjuD7AXdQm/L6b6OcxzOBi4C/H/OkJUmSJGkV6okEMSLWAb4AXJqZH23Y/bsqZh/gjOpxq3YuyMxrq8f/ACwEjouIpwEbN4RP4bHTTm+pvq/TEENETAJOAg4ALo2IazLz4Ya+pwEnAK8CjqpLLAHIzPktjnkOtUSWPea8h2fu+9qm5yZJkiRJY+mJBDEzHwReERG7RMS3+Nu1fn3URuPIzIXUEj4AIuIYYFJmXtbYXkQcALyS2mjfpsA04JkNfd4eESuoJaaNHsnMQ6u2JgGfAi7JzD9FxJnAVyPiqCb17gP2y8yhNk+dzJwHzAOY85VfZbv1JEmSpJ43TlcKHc96IkGsczHwmsy8EyAiZgHXRsSPMvP+dhqIiA2Bo4DZVaJ2R1X+uGsQM/MeYN8mbVxft7kZsDAzr6rq/DgizgYek8xV016viIgraVh5NTMPRJIkSZJWs15LEJPHJl7Z8H3sBjLvBf7fKjugzNuB2xvKfgwtp7pOX1V9S5IkSVInei1BPBH4TERMrrb7gXMz84EmsfdU+1eHq0sqR8SiJsVzM/OWJuWSJEmSmnEV0471VIKYmT+jdn/DdmKv67DtkWmeb2oj9iNttrkIWNSiH0mSJEl6QplSS5IkSZKAHhtBlCRJkqRHuYppxxxBlCRJkiQBjiD2lLsfWNp13YGh4aK+VxbUf9pBryrq+w/XfLP7ytNmFfXNptsXVZ82pft1kib1lf1FbMNZU8YOauF3dz9c1Pemm6/Tdd2+wvMeGC57rU/u6/7vaoNZdqvSweHu6z+0ZGVR37+775Gu6z688nF3CepIixWf2/a0DaZ1XXdy4ettnendv8e322Gjor6HCj6X/1zw+wRgxUDZ+2y44L2She+zyf0F7/GC9yjA/9zb/fvsnhnLi/qeNqnstV7434giA0PdP+8lr7Va393XLfx4ofDXGYWnrh5mgihJkiSpN7mKacd8xiRJkiRJgAmiJEmSJKligihJkiRJAkwQ2xYRMyNinzbiXtlme8eXH5UkSZKkliLG99c4NKESxIi4vknZghaxsyPihLqidYHX1bfV8PXOatdbGto5ry7m/yLiTdWuw0Y5zjkR8eZ2z0uSJEmSVoUn/SqmEbEhcDIwnJnvioinA/8CTAN+kJmn1YU/LSIWNTSxRUN7bwB2A3YEJkfELsAPgYWNfWfmvmMdX2aeUdf2fOA7Y5zPdsArag/j2sz87Vh9SJIkSdKq8KRPEIGLgN8CM6rtjwHHZeZtEfGViNgtM39U7bsPuLCh/pn1G5l5aUR8DvgaMAuYm5lLImILCkTE4cDtmfmnurIbgY9k5tcj4u+BPYEHgWOoje6+OyLWBb6fmf9a0r8kSZI04Xibi4496RPEzHx9ROwFHBgRk4BpmXlbtftrwIuBkQTxVGBqQxOn129ExHOAs4FPUUso51cjf99t85A2ioirgK9l5ucjog94O7AlUD+aSWbuUbf5Y+DKzKy/0+3ciJhBwyinJEmSJK0OT/oEscGGwF/rtv8KPDMi9gPOalUpaheInp+ZC4BtgJOA7ahdd3hYVdauv2TmoVW76wBfAC7NzI82xP2urv99gDPqjqXZMV6Qmdc2KZ8DzAF4ztFnsPWeLS9tlCRJkqRR9VqC+CCwTt32usC9mXkdcN1IYUQcAWyQmRc3NpCZV1UxewGzMnMQuLXZFNOIOJXaVNBJ1Ka4zmto60HgFRGxS0R8C5hS7eqjNjV2JG4hddc4RsQxwKTMvGysE87MeSP9vmreT3KseEmSJGnCcIppx3oqQczMZRExNSI2z8w7gcOB943sj4iPZ+ZJrepHxKbAsUA/sDMwIyJ2oLbgTePiMm8DngIkMAg8DNzdoumLgddUx0REzAKujYgfZeb9nZ+pJEmSJK16PZUgVk4BvhoRK4BvZub/1u3bsfp+DbUksNGD1BLBIeAqaonfMmApMBN47UhgQ7uPajFFNKuv+m0ayiRJkiRpjeqJBDEzFwGLqsc/obYwTTM7198LsS6Ze0Nm/ikzlwE/bVYxIhoXt+nEicBnImJytd0PnJuZD7SIv4fmCawkSZKkdo3Tm9GPZz2RILYrMzcsqHsHtemnY8Ud2KTsZ9TubdhuX9eNHSVJkiRJq5ZXbUqSJEmSgAk2gihJkiRpAnEV0475jEmSJEmSAEcQe8rkSd3n+8OF66lO6uu+74GB4bLOp83qvu7yR8r6XnxfUfUWq96u9rqlJvWX/W2p5NBLT3uo8MU+XLD4cGZZ3yXH3te35l4v/S4Q0JXSp63kZ176Hi98qTM41P3vheEse+JKnrfSV/rkgr771+B7vNRw4Qum70n6GVP6f6/S95nUiiOIkiRJkiTAEURJkiRJvepJOsK8JjmCKEmSJEkCTBAlSZIkSZWeThAj4tVtxOwaEae02d7eEbHWGDHbR8Qz2mhr64g4sJ1+JUmSJHUh+sb31zg0Po+qCxExOyKObSh+W93+p0fEorqvP1a7pgJrt2hzUUPR0cD61b49IuL3EXF93ddmwPOAF9W18cyGmD9Uuzatj2vS93+NedKSJEmStAo96RapiYgNgZOB4cx8V92u/uqrqcz8P2Cvqo1tgXNHaf8D1eauEXFx9fisJuGfy8z3NtRv7Pd/gX2rfc8C3t7qGKuYPuBs4HcR8W7gnMwsvA+EJEmSJI3tyTiCeBGwApjcUL4lsHWbbXwQ+Gjd9rMj4jCAzLw3M08AvgQ8BHwvM0/IzL+WHHRETAM+DJxTV/zGiPhWtX+biHgXcDnwg8w8Avgx8G8RcU5EPL2kf0mSJGnCiRjfX+PQky5BzMzXA99rsmtPYPfR6kbNh4CfZeaPWsTMiIi3AG8AngXsHBH/HBHtJp8AJ0XEVRExuWpzO+ALwLsy8/a6uM9m5iHV47uBz2fm6zLzeoDMXJCZr6WWNN7ZQf+SJEmS1LEn3RTTZiLilcCPgL9ExFsz85NNYnYB3g9cl5mfaNj9y8y8snr8FOBPmfnPEfG+zDw9Ip4K3NvBIX08My+r+n0zsDNwYmb+pS5mCbWkcMSngM0bp6jWuRs4psl5zQHmAOz6+jN52ssO7+AwJUmSJOlvnvQJYkS8ADgeOBwYAD4fEYsz8/KG0PWBuZn5m9Hay8y7gG9Wmy+pym6r+moM3z0iTqV27eNUaqN8Sxra+5eoVXx3ROwNrKT2vN8KzK2L+38N53V9Zu472rFW9eYB8wBe89lbcqx4SZIkaaIYZfBFLTzpE0Rqo3Ovz8yVABHxBuBljUGZuTAiXhARZ2bmB+vKbwJuGtmOiCOB7alNv90mIs6jlvzd19Dkz4F3A1l9LQPuAV7e5BiPAaZk5l51/cwG3gec2ukJS5IkSdLq8KRPEDPzkobtAeD6FuH9wJQxmrwF+A0wBHyd2oI4S4HF1C1sk5mLqUssR7T4K0Wzkb1sUS5JkiRJa8STMkHMzEXAoi6rHxsRezWU/SIz31a1/btWFQuGqL8AvKe6r+IAtUT1d8A/jlLn5912JkmSJKk3pphGxAeoLcg5CZiTmb+qyi8BtqvC1gZuy8zDI+JfgWdSu7Ttx5n5jk76e1ImiO1qvIavmk761IL23tRGzPwmZQm8t8O+5o4dJUmSJKlXRcRLgY0z82UR8Wxqt807GB6bm0TEx4HPV5vrAAdl5kPd9Pmku82FJEmSJE0Q+1O7PzuZ+UtgvcaA6nZ8G2XmT6qitYCHu+3QBFGSJEmS1oCImBMRN9d9zWkI2YjH3m5vMCIac7hTgH+q205gUURcW41AdqSnp5hKkiRJmsDG+SWI9besa+EhYN267eHMHB7ZiIhpwC6Z+fa6Ng+o9m0JfBt4TifHZILYQ2ZM7f7HOal/eOygUcya1n3fD93f9Qh4zabbd193cePdSzp035+Kqg8Odf+89xdedP3Iyu77njq5v6jvoaHuF/DNwrV/B7Pstb6y4GdW1nPZsc8s+HwAmNzX/YSTtaZMLup7uPCHvrTgtT5tctlEm+UD3fdd8j4BGB5ec6+XlYW/U4aGuz/30tdLX8Fn66T+stfLrKndf7bOmlL2MxvKFUX1+8b5f8LHo9LfZ6Vrr5T2ryfMDcARwA0RsSNwR8P+g2i4g0NETMrMQeABagtkdsQEUZIkSZLGp28DB0fEDdRuu3d8RHwIeFd1H/i9gG801FkQEZOo3TnhzE47NEGUJEmS1JOe7Le5qKaTnthQfHrd/rc37HvcnRw65SI1kiRJkiTABFGSJEmSVDFBXA0iYreIOGmMmOOfqOORJEmSJqKIGNdf45EJYoGIWDcivh4R10XE9yLi9dWu6VQ3sYyI8yLi+urr/yLiTVXMYaO0Oyci3ryaD1+SJEmSHsNFasqcDHw2M79V3bByUUR8vT4gM88YeRwR84HvjNZgRGwHvKL2MK7NzN+u+sOWJEmSpMczQSxzDzCtetwPPAwsbxYYEYcDt2fmn+rKbgQ+kplfj4i/B/YEHgSOoTa6++6IWBf4fmb+62o7C0mSJKkHjddpnOOZCWKZi4G3RcQHqCWIp2XmYP0LsRpZfDuwJXBafeXM3KNu88fAlZlZn2DOjYgZwBar6fglSZIk6VEmiAUyczgirgYOqIr2iYh9qsdXR8Q6wBeASzPzow3VfzfyoKpzRvW4aV8RcUFmXtukfA4wB2C3N57N9i8/ovsTkiRJkjShmSCWWww0Xif4LODgzPwx8IqI2CUivgVMqfb3AReNBGfmQmDhyHZEHANMyszLxuo8M+cB8wBe94WfZ8F5SJIkST3FKaadM0Es9wzg1IaypwDfrtu+GHhNZt4JEBGzgGsj4keZef8Tc5iSJEmSNDoTxHKbAFeMMdqX1Vf9Ng1lkiRJkrRGmSCuGqdV00Lr/Twz51aPTwQ+ExGTq+1+4NzMfKBFe/dUMZIkSZK65QzTjpkgFsrM+cD8MWJ+Ru3ehu22eV3hYUmSJElSx/rW9AFIkiRJksYHE0RJkiRJEuAUU0mSJEk9yttcdM4EsYe8dNt1uq47OFy2oOrk/u7ffIv33L6o72lTul/Pp/RDY3BouKj+Vy/8TPeVZ65b1Dfrbtp11Y+eeXBR139d2v2x9xf+zJYMDBbVf2hFWf0SD68c6LruhmtPK+r7P2/r/o48Q4WfL6W/25cPdt9/X5Qde0nfezxjw6K+H1jW/Wv1mRtPL+q78EdOX8HPvPQz4inTuv+v0YxJZevL/fIvS7que/uDK4v6Xmda2bEvHej+92HpzywLXm/9JS82YFJB/eGSAwf6Cp+3fucRqgVfGpIkSZIkwBFESZIkST3KKaadcwRRkiRJkgSYIEqSJEmSKj2fIEbEzIjYpzSmwz4/v6rakiRJktSdiBjXX+NRzyWIETE7Ik6oK1oXeF21b0FEXF99fXmkrD6mSXtviYi3tdh3XkQsqr5ujYjjq10bNsTtFhHfj4is6z8j4ocRsXuLtudGxOkdnbwkSZIkFeiZRWoi4g3AbsCOwOSI2AX4IbCwPi4z9+2gzRcB+wBDEXFLZv6goa0z6mI/B3y3WTuZ+aOI2B/4XGa+por/KvDGzHy4oc+ZwD8Am1TbJwGfycxl7R63JEmSJHWjZxLEzLy0StK+BswC5mbmkojYotO2qmRzL+DXwOyq+B0R8VZgUWbOa4h/HjArM39dVzYbuCUzfxMRhwAnA7tExPVVyC7AlRHx8cz8RlXneOCpwHxgiNoI7yzgwxFxe2Ze0Om5SJIkSRPVeJ3GOZ71TIIYEc8BzgY+BdwHzI+I+bQY1auzK3AJcHdd2ZXAZZmPuYPpORHRB2zQ0O8zgYuAv29xXBsCDwLvHeXYN6KWDP6u+tqQ2shlP3AtcFUVt2lm3jXG+UiSJElSV3omQQS2AU4CtqN2TeFhVdlYfgYcD7wPICL2A86qHgNMreJWjFSIiPOBRcAJwKuAoxoTt8ycX8VuUx3TiBdTS/xurCu7G1gJrFNXdkv1vb5sSuPBR8QcYA7A0ad/kD0PPWqUU5UkSZKk1nomQczMqwAiYi9q0z0HgVsbp5hGxHbUErSZwO+BpDadc6Sd64Dr6uKPASZl5mUN7UyjNlK5X2YO0UJm/h74fURsC/wj8BIggOXARzPzd3VtrgC+0KSZRzLz0BbtzwPmAcy76Y/ZLEaSJEmakJxh2rGeSBAjYlPgWGqJ387AjIjYAZgGfKcu9ErgRGqjgYtpnoyNtPnVzDyi1f7MXA5cERFXUhutrN93YJMqVwDvAE6l9lJ9btX/i+rq3QM8bhGduusWJUmSJGm16YkEkdo1ft+hNhJ4FTAILAOWUhspfC1AZn66seIoF67Oqr7/O6P/7WH6WAcXf+vkliqxJCL+C8iIiIZrHSVJkiRpjeiJBLG6BcRPm+2LiKnNytvw9IhYVNfOyMOjM/POhj4W8XhzM/OW6vgyIs6mtmrpSDIYwLvaTA6v7vDYJUmSJKljPZEgjiYz76A2/bTV/pHpoMc2lD+tzfabTSdtFreQhnsytiszP9JNPUmSJGki8zYXnetb0wcgSZIkSRofTBAlSZIkScAEmGIqSZIkaWJyimnnTBB7SMnrv28NvnemTy17GU4qOPjSD43+0g+dmet2X3fJA2V9z+q+7741/bwVGCpcNHh4DS46XNL1cOFhrxga7rpu6euFwmNfk59vJX33Fx54yWdjqf7C+UklnxGl5z214OCn9vcX9V36vJUo/Wwsqb4m//9e+jZZk78TSvuONHFSc04xlSRJkiQBjiBKkiRJ6lFOMe2cI4iSJEmSJMAEUZIkSZJUMUHsUETMjIh9SmMkSZIkrWYxzr/GIRPEMUTE7Ig4oa5oXeB11b4FEXF99fXlkbL6mKpst4j4fkRkXXxGxA8jYvcW/c6NiNNX35lJkiRJ0mO5SE0LEfEGYDdgR2ByROwC/BBYWB+XmfuO1VZm/igi9gc+l5mvqdr/KvDGzHy4od+ZwD8Am1TbJwGfycxlxSclSZIkSaMwQWwhMy+NiM8BXwNmAXMzc0lEbNFpWxFxCHAysEtEXF8V7wJcGREfz8xvVHHHA08F5gND1EZ4ZwEfjojbM/OCsrOSJEmSJg5XMe2cCWILEfEc4GzgU8B9wPyImA98d4yquwKXAHdX7WwIPAi8d5S+NqKWDP6u+toQ2AfoB64FrqriNs3Mu7o8JUmSJEkaldcgtrYNcBKwhNo1hYcBP2mj3s+A4+u21wK2q/t6HXBsQ9nawBRgnbqvW4AfN5RNaewsIuZExM0RcfP3rvpi2ycnSZIkSY0cQWwhM68CiIi9gFmZOQjc2jjFNCK2ozbSNxP4PZDUpoeOtPN74PcRsS3wj8BLqK1ZtBz4aGb+rq6tFcAXmhzOI5l5aIvjnAfMA/jMj/6YnZ+pJEmS1JucYto5E8QmImJTaqN8/cDOwIyI2AGYBnynLvRK4ERgBbCY5sndiCuAdwCnUksQn1vFv2gkIDPvAR636E3ddYuSJEmStNqYIDb3ILVEcIja9X+DwDJgKbWRwtcCZOanGys2+ytF/K3wlsxcXpX9F5AREZnpyJ8kSZKkNc4EsYnqlhI/bbYvIqZ20V5GxNnUVi0dSQYDeFebyeHVnfYpSZIkSZ0yQexQZt5Bbfppq/0HVg+PbShfSMM9FDvo8yPd1JMkSZImMq9B7JyrmEqSJEmSABNESZIkSVLFKaaSJEmSepJTTDtngthDZk3p/sc5MDRc1Pe0Sf1d1+0vfONuOGtKUf0Sj6wse95Yd9Pu685at6zve37ffddTuv95A9y7ZKDrujML+14yMDR20CgWr+j+Zz65v/SX1GDXNdeZXva8LR/s/rxLT7uv8DNiuGCh6BWFn41r8v8lJf8pmjW17PWyJpX+Til53lYOl71epk/ufmLXwNCaXRD9yfp/8OE1+LT1reHPRqkVp5hKkiRJkgBHECVJkiT1KgdaO+YIoiRJkiQJMEGUJEmSJFWcYtqBiNga2DIzb1zTxyJJkiRpdK5i2jkTxCYi4iJg54bic6rvewA3VnFfBtZriNshM7eqa2s34CPA7sDCqngf4CZgbmb+oEn/c4FJmfmhwlORJEmSpLaZIDaRmXMj4prMPCgijgUWA28GtgWurIs7srFuRFzd0NaPImJ/4HOZ+Zoq5qvAGzPz4Ya6M4F/ADaptk8CPpOZy1bl+UmSJElSMyaIrY3cLG0q8JfMPDIi9qI2gjiax9xRJyIOAU4GdomI66viXYArI+LjmfmNKu544KnA/KrvPmAW8OGIuD0zLyg8H0mSJGlCcYpp50wQWxu52+00YHk1nXRbaondfsBZLertFBGLgPOBW4AHgfe26iQiNqKWDP6u+tqQ2hTUfuBa4KoqbtPMvKvkhCRJkiRpNCaITUTEmcDiiDgb2BzYDPg6cDewR2ZeB1xXxR4BrJOZl0TEgsxcv66dbYDt6pp+MbXEr36Rm7uBlcA6dWW3VN/ry6a0ONY5wByA4846n31ec0xH5ypJkiRJI0wQm8jMDwJExKHA04FtgK2pjehdOBIXERuP0c7vgd9HxLbAPwIvoXa7zuXARzPzd3VtrQC+0KSZRzLz0FH6mAfMA/jSf92ZreIkSZIkaSwmiC1ExOHAa6hNJb0T2AA4BTgR+GgVdnm1f3q1vaBFc1cA7wBOpZYgPpdaMviikYDMvAfYt8lxXN9YJkmSJGlsXoPYORPE1jYDbs7M26rtuyLiBmDP+qDMvKXu8ccaG4m/vSpvyczlVdl/ARkRkZmO+kmSJEkaF0wQW5sHnB8RC/nbqqK3URtFHLFjtSBNo6Mz806AzMzqWsYrI2IkGQzgXW0mh1ePHSJJkiRJ5UwQW8jMlTw2GWwWs1WbbS0EFnZ5HB/ppp4kSZI04TnDtGN9a/oAJEmSJEnjgwmiJEmSJAlwiqkkSZKkHuUqpp0zQewhbzzhY91XHh4q63zqzK6r7nX0IUVd/+7uh7uuO6m/bBB96uT+ovofPfPgruv2FX7gzZrS/bEfd9z5RX2v96J9uq67YtmKor7/cPGRRfVLXjP/fftDRX0/a4u1u6674d9/tqjv+e97Rdd1v/Ob+4v6Xray7PPp+Vuu1XXdTWdNLer7rke6f73+87dvLeq7v7/7z4jPXPi9or7J4bL6fWWfrUXW27zrqs9+4dOLun7ooeVd191ggxlFfe/xrFFv7TymGZO7/2xcOVi2oPs607t/vSwv7Ht6wXkPDJX1nZTVH3YdfbXgFFNJkiRJEuAIoiRJkqQe5RTTzjmCKEmSJEkCTBAlSZIkSZUn5RTTiNga2DIzb1wFbW0ObJqZN5cfGUTEM4DhzCxbXUCSJElSEaeYdm5cJ4gRcRGwc0PxOdX3PYAbq7gvA+s1xO2QmVvVtTUDmAdsBdwPvCkz7wO2r9p6XIIYEe8C+jLzfU32XQtMAZ4D/Ddwd2bOBl4EDAK31sUeCJwKDAEB9AMXZuY1DW3eCvy5oat7M/O1jf1LkiRJ0qo2rhPEzJwbEddk5kERcSywGHgzsC1wZV3c49atj4irG4reDvxHZn42Il5OLdE8oUm9SdSSvtcBdwODEfFh4HLgfzNzqOpz/4iYBvwB2Ac4KyIWAZvwtyR2xDnA3pm5uOpjLWARcE1D3O2Zue+oT4okSZIkrSbjOkGsjNwAayrwl8w8MiL2ojbqN5rGu7vsDhwKkJn/ERGnt6j399X392XmgwARsTEwGzgAuKgu9mTgXcAZmfl+4P1VItvoP4HjI+ImaiOIu1VlkiRJkjRuPBkSxJG77U4DllfTSbcFroyI/YCzWtTbqRrROz8zFwA5MvpXedydl6v2jqs2j2s2ZzkifkUtuTsDuCszL4mIIyLis8DxzQ4kM0+rrps8kdr00k9m5h9HO2lJkiRJZbwGsXPjOkGMiDOBxRFxNrA5sBnwdWpTP/fIzOuA66rYI4B1qoRtQWau39DcIxGxXmbeHxGTabKC60h7EfE0aolcvaHM/EPV1zTghsxcWNX7akRcl5kD1XWEw1VcYwK7MbURxBfUvVhHEliAB6qkdiTu7qr8oMxc1uI5mgPMAZj01P2YtFHjJZuSJEmS1J5xnSBm5gcBIuJQ4OnANsDWwLXAhSNx1RTQscwDLoyI91MbyfvSKLGvpjZiWe8oatcmkpnLgYURcQK1qaeD1XFAbSrseVXcowlsO0YWo4mIY4BJmXlZG3XmUTs3pu92WuO0WkmSJElq27hOEAEi4nDgNdRG4u4ENgBOoZbkfbQKu7zaP73aXtDQDJm5qErgTgR+mJlXjdLtXsCshrKnNInbBHhnZt5Ud7zH0LCiakRckJnvGKU/SZIkSauaM0w7Nu4TRGrTSm/OzNuq7bsi4gZgz/qgzLyl7vHHmjWUmYuorR46lmmreDXR5462s9W1lA0L3tRPRZUkSZKkVe7JkCDOA86PiIXUFpbpA26jNoo4Ysfq2r1GR2fmnV302aq9N2XmbxvKPh4RD9dtbwKc3xDz9NGOr9OpqJIkSZK0Ooz7BDEzV/LYZLBZzFYF7S+iYVSx3fYy873Ae9uI27LzI5MkSZJUwlVMO/e4lTwlSZIkSROTCaIkSZIkCXgSTDGVJEmSpG44xbRzJog9ZJfDX9l13SVLVhb1vekma3Vd9xe/uKus783X6bpu6WfG0FDZrSf/unTdruv2Fx78vUsGuq673ov2Ker7/psWdl95rQ2K+v7tPUuK6ifd/8xve/iRor6n3tP9pI99DnhOUd+7bbV+13W3W6/7zweAzLL32Rf/+89d173zobLPxhL33PnXovqDKwe7rrv73x1c1Pfy5d33DTA0NFxQt+z1Mjzcff1Zs6YU9X3i/tt0XXfrtWYU9f3lX95TVP8p06YW1S8xUPAzGyyoCzBUUL/k94m0OjnFVJIkSZIEOIIoSZIkqUc5w7RzjiBKkiRJkoAJkCBGxMyIKLtg6m9tvfSJ7lOSJEmSnig9N8U0ImYD62TmxVXRusDrgIUNcccDZOanR2nrW5l5SF3Re4B96/Yv4G/P4f2ZeWRV9qZmfVZ13gpMysyPtejzVqBxRYV7M/O1rY5TkiRJ0uO5imnneiZBjIg3ALsBOwKTI2IX4Ic0SdIq+1AbQW2aIEbEFsBWY/WbmfuOFVPX5suAlwGDEfGyzPxuk7DbO2lTkiRJklaVnplimpmXAm8B7geWAHMz8/JmsRFxNLABsG5EvL5FkycD/x0R9SN3/RGxKCJe1cmxRcTxEfEF4AXAUdRGF18YEV+sRhQlSZIkaY3rpRHE5wBnA58C7gPmR8R84Lt1MU+llvg9HTgMSOCLEfEC4KLMvC0iJgFnAH/OzFMj4sKI2Bb4EDDUxujersAlwN11ZV9oMpX1w9Uxrd3N+UqSJEnSqtYzCSKwDXASsB216w4Pq8rqHQt8NzNPjojNgcjMQyLiFdRG9T4AbAj8IjOvAqiSxGdnZkbEH9o4jp8BxwPvA4iI/YCzRpv/HBHnZ+aCavOBiFgEbAwEf0s0D8rMZW30L0mSJAlvc9GNnkkQRxK6iNgLmJWZg8Ct1bWEIzHvrauyN7Xzvywzvw18u4q5C7gqInagluStV2s2lgDnNfYbEdsB/cBM4PfURiWH6vq8DrguIk5uXJimWdnIYjQRcQy1xWwuG+28I2IOMAfgaYfNZePdOpr9KkmSJEmP6okEMSI2pTY62A/sDMyoErxpwHe6bPZS4I2Z+X9VH5sA36gWl1lexVwJnAisABYDXxilvZMi4pCGsm2Aj3V5fABk5jxgHsCLP/S9LGlLkiRJ0vgSER8A9qSWu83JzF9V5VsCPwJurULfnJn/ExGHAnOBKcBHMvPfOumvJxJE4EFqieAQcBUwCCwDllIb2XvtyFTPxooRcWzdZv1UzynAw3X7llCb8tk/UtDsFhmjTCW9NTMPbIhdUPe40+OTJEmSNIon+20uqvuwb5yZL4uIZ1Nbx+Tgavc6wL9l5j/Wxc8ETqV2x4ZJwI0R8Y26Aa4x9USCWF2b99Nm+yJiahVzHXBdB82eAHw2IqZQSwwTeFdmLunyMHeIiOsbyh69RrKL45MkSZLU2/YHvgSQmb+MiPXq9q0DPNAQ/yJgYWauAFZExI+AZ1BbJ6UtPZEgjiYz76A2/bTTercAB3VRb2SU8NiG8sYFcyRJkiRNYPXriVTmVZeQjdgIuLduezAi+jJzGJgBvCYiDgB+ApzWJP6v1BbwbFvPJ4iSJEmSJqbxPsO0fj2RFh7isQnecJUckpnfAb4TEX3UFtf8B+A2and1GLEuj00Yx9TXSbAkSZIk6QlzA3AEQETsCNwxsqO6fztVwvjXqvjHwIERMTkiZgDPBn7dSYeOIEqSJEnS+PRt4OCIuIHaXROOj4gPAe+iNr30LdQW6ryN2gqnKyLiMuBGaot2vqe6/V/bTBAlSZIk9aS+vnE+x3QM1ejgiQ3Fp1ffv1R9Ndb5DPCZbvs0QewhK1cOdV13cHC4qO9lyzv6w8RjDA+X9V3yxi+dl56Fd57sX4MT42dO6R87qIUVy1aUdb7WBt3XXXxfUdeTJ5U955nd1585uewjd3J/91cFrBzs/vMBYOVQ9+/TFQNlfZfe4HXpQPfHPmNy2ZUYJX3393f/HgUYjO4/l0t+n0D575Th4e5/6kMFr1UoWxJ/UsF7FGDZyoL3WeF5Dw2VvdMKfmTFSn6X9sWaO+9gTScu3j5bzXkNoiRJkiQJcARRkiRJUo8a76uYjkeOIEqSJEmSgB5PECNi64jYYxW19dI242ZGxD6rok9JkiRJeiL1xBTTiLgI2Lmh+Jzq+x7UlnklIr4MrNcQt0NmbtWkzW9l5iF1Re8B9q3bv4C/PX/3Z+aRVdmbgNcBC5u0+VZgUmZ+rMV53Ar8uaH43sx8bbN4SZIkSVqVeiJBzMy5EXFNZh4UEcdSu0fIm4FtgSvr4o5srBsRVzcp2wJ4XNLYpN99x4qpa/NlwMuAwYh4WWZ+t0nY7Z20KUmSJKm1kpWJJ6pemmI6sib3VGBZlQzObaNeszV+Twb+OyLqR+76I2JRRLyqk4OKiOMj4gvAC4CjqI0uvjAivliNKEqSJEnSuNATI4iVkRsATQOWV9NJtwWujIj9gLNa1NspIhYB5wPXA2cAf87MUyPiwojYFvgQMNTG6N6uwCXA3XVlX8jMTzfEfRggItZu79QkSZIkafXriQQxIs4EFkfE2cDmwGbA16klantk5nXAdVXsEcA6mXlJRCzIzPXr2tkU+EVmXgVQJYnPzsyMiD+0cSg/A44H3le1tx9w1mhD2xFxfmYuqDYfqJLVjYHgb4nmQZm5rI3+JUmSJFWcYdq5nkgQM/ODABFxKPB0YBtga+Ba4MKRuIjYeIx27gKuiogdqCV569WqxRLgvMb4iNgO6AdmAr+nNl11qK6964DrIuLkxoVpmpWNLEYTEcdQW8zmsrHOPSLmAHMAtnrVKWzw/EPGqCFJkiRJzfVEgggQEYcDr6E2lfROYAPgFOBE4KNV2OXV/unV9gKauxR4Y2b+X9X2JsA3qsVlllcxV1Ztr6C2KM4XRjm8kyKiMXPbBvhYWyc3isycB8wDeN4H/rPZ9ZSSJEmS1JaeSRCpTSu9OTNvq7bviogbgD3rgzLzlrrHH2vR1hTg4brtJdSmfPbX1W28rnC0VZJuzcwDG2IX1D1ueo1ktSLriPqpqJIkSZLG4CqmneulBHEecH5ELKQ2zbMPuI3aKOKIHatr/BodnZl31m2fAHw2IqZQSwwTeFdmLuny2HaIiOsbyrYZeVB/jaQkSZIkrSk9kyBm5koemww2ixnz3oZV3C3AQV0cw8go4bEN5ds8PlqSJEmSxpeeSRAlSZIkqZ5TTDvXt6YPQJIkSZI0PpggSpIkSZIAp5hKkiRJ6lHOMO2cCWIPWXjqnmMHtdBX+O4ZGBruuu4v7nh47KDR+h7uvu+h4bJbRw5m930DLBkY7LruUJYd+5KBoa7r/uHiI4v6/u093S4IDJMnlb1WX3DIO4vq09c/dkwLW+17cFHXt1/7713Xve9Hnyjq+41f+lnXdfd/5vpFfc+Y3P1zDjCl4DXz54eWjx00io3Wntp13Wvf2/FaaY9R8hHxtI1mFPVdquBjvfhz/S8Pr+i67sI//KWo75dutUHXdZet7P4zHeBpG0wrqr9isPvnfVJf2ef6/cu6/106Y3LZZLq/Lu2+76n9azZzMXFSK04xlSRJkiQBjiBKkiRJ6lGuYto5RxAlSZIkSYAJoiRJkiSp0tMJYkRsHRF7dFn33xq294qIs9uot31EPGMVxn18rBhJkiRJWhV64hrEiLgI2Lmh+Jzq+x7AjVXcl4H1GuJ2yMytqv3bAidW5S+MiAurx59u0ucVwCbArsB/VcWHA88DpgG/ruLOAvar9vcDSzPzgCZxBwBnAAPAIHBiZt4G7NDOcyBJkiTpsbwEsXM9kSBm5tyIuCYzD4qIY4HFwJuBbYEr6+IetzZ/RFxdt3kPcAWwMXA78Bvgrupr84Y+j6nqfy8z961rr/HYzgXOrfa9EHhdi9N4P7B3Zi6NiJ2A84C/r+rNAlZk5sCoT4QkSZIkFeilKaYjNwCaCiyrksG5bdR79MY9mfkIsA3wFmqjfW8CdgQ+BFzQov72EbFhm8d4CPDNFvvuBUbu/DQE3Fe372QeP0IqSZIkSatUT4wgVkaSq2nA8mo66bbAlRGxH3BWi3o7RcQi4PzMXAAcBxyRmcuq6/+uycz9I2IvatNVHxURzwNWAIcB80Y7uIjYEngJ8J4WIacA74uIldW5nDmyIzPPaVFHkiRJUgve5qJzPZEgRsSZwOJqEZnNgc2ArwN3A3tk5nXAdVXsEcA6mXlJRCzIzPUbmvsP4AMRcRWwP/D9iDgXeCHw3YbY04FXA/8UEfMz8+EWx7cutesYj8vMbBaTmbdW7TWWHzjGuc8B5gB89BOf4tjj/mG0cEmSJElqqScSxMz8IEBEHAo8ndo00a2Ba4GRhWaIiI3baOuiasTxhcAPM/OaiFgLeBmwS11bZwA3Z+bPI+JU4F8j4rjG9qpVVN8DnF0tOtNSRFyZmYeNVdZwvPOoRi8fXDbUNPmUJEmSpHb0RIIIEBGHA6+hNpX0TmADatM2TwQ+WoVdXu2fXm0vaNHcRsDXRxK6zFwcEQv42yjkU2rFeUG1/+ZqJdW1mrS1O3BUZt7bxmlMj4jrG8p2aaOeJEmSpAbOMO1czySI1KaV3lw3SndXRNwA7FkflJm31D3+WIu2dgJ+1VBvkNrtJ8jMh4DzG/bfBE1XMW21uE1T9SuiVu21SmIlSZIkaZXqpQRxHnB+RCyktgpoH3AbtVHEETtWC9I0Ojoz72wouzgiHmko+2lmvmMVHW9TjiBKkiRJWlN6JkHMzJU8NhlsFrNVm229s+A45ncbN9aCNJIkSZLa5yqmneul+yBKkiRJkgqYIEqSJEmSgB6aYipJkiRJ9Zxh2jkTxB4yZVL3A8J9he+ekuqPDAwU9T25r/vzHqbs1pErh4aL6j+0YrDrusNZduyLV3R/7JP6yyYfZMHznln4Sd/XX1Z/eKjrqv39a+7Y+/vK+p46ufu+ZxTUBZgxqaz+ysHuX2+DhbeXLel7oPDzpeTjbWrhc15qaLj7gy+pCzB1cvefbzOnlD1vJb/HS897TSr9D3zp/2HK+l5jXZv4aLVxiqkkSZIkCTBBlCRJkiRVnGIqSZIkqSd5m4vOOYIoSZIkSQImQIIYETMjYp9V2N6r24h5cUSc1Ebc9hHxjDbiPt7u8UmSJElSt3puimlEzAbWycyLq6J1gdcBCyNiPeDrTartkJmbNbSzL7BjZn682l6QmQcCbwO+UZWdDRwBPFhV2yAznw1MBdaua+ssYL9qsx9YmpkHAM8DpgG/ruIOAM4ABoBB4MTMvA3YoasnQ5IkSZrAnGHauZ5JECPiDcBuwI7A5IjYBfghsHAkJjPvB/ZqUvf6usfPAV4FbA9sFBFrA98fpeuTM3NRVfcXETEf2Aj4j7p+zwXOrWJeSC1hbeb9wN6ZuTQidgLOA/6+qjcLWJGZZfeEkCRJkqQWeiZBzMxLI+JzwNeAWcDczFwSEVu0Ub3+ZlO3A1dVbUwH7q2+2nFPZs6OiL2APVrEHAJ8s8W+e+uOZQi4r27fycAC4OY2j0WSJEmSOtIzCWI18nc28ClqidX8ajTvuy3iL87ME6rNRxPEzHwwIg6lNiX0QWBJZr6jzRWQNm42gljX55bAS4D3tKh/CvC+iFhZHdOZdcd1TovzmAPMAfjEv1zMG980p53jlCRJknqeq5h2rmcSRGAb4CRgO2rXHR5WlbXy1LrHww37ZlfXGxIRn4qIrYDNquSv3oPAGRHx1mr7rlYjiBGxLvBp4LjMzGYHlJm3Aqc3KT+w1Ulk5jxgHsDSgebtSpIkSVI7emYV08y8KjPvBrYAnpqZg1XC1Y6jG7b7ImLkuZkJrAT+nJmzG/r8JLUpo0dl5hGZuX+zxiNiD+DLwPuqRWdaiogr2ymTJEmSpFWtJ0YQI2JT4FhqK4TuDMyIiB2orRD6nSpmP+CsumrPiYhFdW0AnJ+ZC4ALga9FxADwvcy8e5Th6b+j9jxeNlJQLVqzqC5md2pJZDvXMk6vXzSnsksb9SRJkiTVcYZp53oiQaQ21fM71BZ2uYraLSKWAUupjQC+NjOvA65rp7HMvBa4dlUdXGZe0GH8vvXbEbFgVR2LJEmSJLXSEwliZi4DftpsX0RMfQIO4Z0RcWxD2S8y823dNOYIoiRJkqQ1oScSxNFk5h3Upp+WtnNg9X3fhvIrgCu6bLNx0ZtRF6SRJEmS1D5XMe1czyxSI0mSJEkqY4IoSZIkSQImwBTTieS///hQ95ULR99XDjXeSrJ9D60YKOp7sPD2jy1uS9mW7s96zZvc3/0P/b9vL3itAbc9/EhR/ZmTu//o2mrfg4v67i943v5wzTeL+t5q/1d2XffnJZ8PwNRJ3f898T9+8wBPW3961/WnTS77gJo5pftjH55Vdhl7Sd9/fmRZUd8l/vzrZWw8fVrX9YcKP5eHC6r3Ff4+e2DFyq7r3r90sKjv/7334aL6ywa777/g1zhQ9ryX3sW5ZLSjv/AFM7mw/pqc/Vh67updJoia0EqSQ60ZJcmh1oyS5FBrRklyqDWjJDnUmuGlcU8Mn+fOOcVUkiRJkgSYIEqSJEmSKs7VkiRJktSTvM1F5xxBlCRJkiQBEyBBjIiZEbHPGDE7RMQz2mzv1W3EvDgiTmojbvt2+o2Ij7dzbJIkSZJUouemmEbEbGCdzLy4KloXeB2wMCI+C2wF7Ar8F0Bm7gu8kNpz8eu6dvYFdszMj1fbCzLzQOBtwDeqsrOBI4AHq2obZOazganA2nVtnQXsV232A0sz8wDgecC0kX4j4gDgDGAAGAROzMzbgB1WwVMjSZIkTShOMe1czySIEfEGYDdgR2ByROwC/BBYOBKTmW+sYr9XJYbN2nkO8Cpge2CjiFgb+P4oXZ+cmYuqur+IiPnARsB/1PV7LnBuFfNCaglrM+8H9s7MpRGxE3Ae8PdVvVnAiswsu2mgJEmSJLXQMwliZl4aEZ8DvgbMAuZm5pKI2KJJ+M4RMZ1aMrkT8GJqySTA7cBVVRvTgXurr3bck5mzI2IvYI8WMYcAre6WfS9/u/f6EHBf3b6TgQXAzW0eiyRJkiR1pGeuQaxG/r4EfAo4HZgfEUc3iduD2pTQQ4Al1JKwxSP7M/NB4PnUppIeAbw+M+9p8zA2rkYQ393iGLcEXgJc36L+KcD7IuIDwN8BZ9Yd1zmZ+bjkMCLmRMTNEXHzVfMva/MwJUmSpN4XMb6/xqOeGUEEtgFOArajdt3hYVVZo1OAVwMfAQ7KzF9HxDo89rmYXV1vSER8KiK2Ajarkr96DwJnRMRbq+27Wo0gRsS6wKeB4zIzm51AZt5KLbltLD+wxTmTmfOAeQA3/fbBpu1KkiRJUjt6ZgQxM6/KzLuBLYCnZuZglXA9KiLOAH6QmT8DPgpcGhHTmjTXFxEjz81MYCXw58yc3dDnJ6mNRB6VmUdk5v7Njq0atfwy8L5q0ZmWIuLKdsokSZIkaVXriRHEiNgUOJbaCqE7AzMiYgdqK4R+p4pZCyAzL6y+/3tEDFYxjS4EvhYRA8D3MvPuUVZA+jtqz+NlIwXVojWL6mJ2p5ZEtnMt4/SIaJyCuksb9SRJkiTVcRXTzvVEgkhtqud3qC3schW1W0QsA5ZSGwF8bWYuprYq6KMy8xp4/AsnM68Frl1VB5eZF3QY/5gVViNiwao6FkmSJElqpScSxMxcBvy02b6ImPoEHMI7I+LYhrJfZObbumnMEURJkiRJa0JPJIijycw7qE0/HS3mijbaObD6vm9D+RXAmPVbtNm46M2oC9JIkiRJap8zTDvXM4vUSJIkSZLKmCBKkiRJkoAJMMV0InnWFmt3Xbd0haeBoeGu6w79qez2jYPD3dcfKqgLMJjdnzfAwysHuq7b/G6anRjsumbJaw1g6j3d/21qcn/Z37Vuv/bfi+rT19911a32f2VR1yXHvtMHmt6Fp20P39j9a/Xndwxw0I7rd11/+qTun3OAux7u/tgfXLqyqO+pk7q/DH7rp8ws6rv0M2K7jcv6L1HyuT5ceOJ/eXhF13X/+NCyor63X39WUf1lK4a6rvuHB5YX9T3Y/a8UCj/WGSz4mZf+P2DFUFn9qf1rbv5j6bmrd5kgSpJWq5LkUGvGmkwO1Z2S5FBrxppMDicSb3PROaeYSpIkSZIAE0RJkiRJUsUpppIkSZJ6kjNMO+cIoiRJkiQJ6PEEMSK2jog9VmF7r24j5sURcVIbcdtHxDPaiPt4u8cnSZIkSSV6YoppRFwE7NxQfE71fQ/gxiruy8B6DXE7ZOZWDe3tC+yYmR+vthdk5oHA24BvVGVnA0cAD1bVNsjMZwNTgbXr2joL2K/a7AeWZuYBwPOAacCvq7gDgDOAAWr3HzgxM28DdujgqZAkSZJU6XOOacd6IkHMzLkRcU1mHhQRxwKLgTcD2wJX1sUd2Vg3Iq6ue/wc4FXA9sBGEbE28P1Ruj45MxdVdX8REfOBjYD/qOvzXODcKuaFwOtatPV+YO/MXBoROwHnAX9f1ZsFrMjM7m/mJUmSJElj6IkEsTJyA6CpwF8y88iI2IvaCOJo6u8SejtwFTALmA7cW321457MnD1Gn4cA32yx715g5K7rQ8B9dftOBhYAN7d5LJIkSZLUsV5KEEeSq2nA8mo66bbAlRGxH3BWi3o7RcQi4PzMXBARh1KbEvogsCQz39HmDTY3bjaCOCIitgReArynRf1TgPdFxMrqXM4c2ZGZ57SoQ0TMAeYA/NMnP8UbjpvTzrFKkiRJPc8Zpp3riQQxIs4EFlfXBW4ObAZ8Hbgb2CMzrwOuq2KPANbJzEuqawvXb2hudnW9IRHxqYjYCtisSv7qPQicERFvrbbvajWCGBHrAp8GjsvM+hHLR2XmrcDpTcoPHO3cM3MeMA9g8fLhpm1LkiRJUjt6YhXTzPxgZh4N/JLa9NBdgEOBbYALR+IiYuM2muuLiJHnZSawEvhzZs5u6POT1KaMHpWZR2Tm/s0aq1ZR/TLwvmrRmZYi4sp2yiRJkiRpdeiJEUSAiDgceA21qaR3AhtQm7Z5IvDRKuzyav/0antBk6YuBL4WEQPA9zLz7lGmmP4dtefwspGCatGaRXUxu1NLItu5lnF6RFzfULZLG/UkSZIkNWjzUjHV6ZkEkdq00pvrRunuiogbgD3rgzLzlrrHH2tsJDOvBa5dVQeVmRd0GL9v/XZENEtiJUmSJGmV66UEcR5wfkQspLYKaB9wG7VRxBE7VgvSNDo6M+/sst93VrfWqPeLzHxbN405gihJkiRpTemZBDEzV/LYZLBZzFZdtn1g9X3fhvIrgCu6bLNx0ZsxF6SRJEmSpNWpZxJESZIkSarX5yWIHeuJVUwlSZIkSeUcQewhGx3+ie4rr8EVno446mVF9R9asrLrun2Ff1aaObXsLbTh2tO6rlt618t1pvd3XXfDv/9sUd/7HPCcruuuHBwq6vu+HxW8T4D+gtfMz//4UFHfO32g6d102rL+bl1dFv2o085/e9d1L174h6K+lxS8xwFOPGj7rus+f/NZRX3/ddlA13VP++avivqePqX79/h1X/mPor7pn1xWf+rMrqv2TZlS1PV2O3Z1NQoAc/bftqjvl7/r6q7rTp5a9pz/w2HPLqo/VPBLaeVQ2S+0p0zr/rW+fKCs7/VndP//gKHmt8ZuW2F1qSUTREmSJEk9ydtcdM4pppIkSZIkwARRkiRJklRxiqkkSZKknuQM0845gtihiHj1Kmxr84h4fhtxn19VfUqSJElSKyaILUTExyJiUfX144gYWfrwbXUxB0XE9dXX/1RfI9uHNGlzQUPR9sCBdfvPq+vz1og4vtq14ao+P0mSJElq5BTTFjLz5JHHEXEYsHmTmGuAa6qY84BJmXnaKM2OuvZ2Zp5R1+fngO92dtSSJEmSRgTOMe2UI4jtORj4dqudEfE04LnArtXjZjEBPD8ixrxBU0Q8D5iVmb+uK5sdEd3fzEuSJEmSxmCCOIaIeC4wPTNH7vTcFxFXRcQ7qv3PBy4BjgPeCHw2Il7cpKn9gDuAw8bo75nARcBbVtEpSJIkSXqSiogPRMR3I+L7EfGsuvLnRMS1EXFDRHx5ZCAqIv41In5QXbZ2Qaf9OcV0FBGxNXA+MLuueDgzD632fwpIaknfBtQS7lcD50XEGzJzThU3CTgJOAC4NCKuycyHG/qaBpwAvAo4KjPvqt+fmfNbHOMcYA7ApGcdyaStdi86Z0mSJKlX9D3JZ5hGxEuBjTPzZRHxbODD1GY3Qi0PeWVmroiID1PLQ74CrAMclJkPddOnCWILEXE4tYTtLZl5f4uwt2TmcBX/KmrXIF4GvKWaUjqSHH4KuCQz/xQRZwJfjYijmrR3H7BfZg61e5yZOQ+YBzD94H/KdutJkiRJGvf2B74EkJm/jIj1RnZk5i/q4h4AllSP1wIeMxjVCaeYNhERk6mtMHpoZv6mVdxIcthi30iythmwMDOvqsp/DJxNLeOvj1+emVcAX23S1oGNZZIkSZJ63kbAvXXbgxHxmBwuIl4CPAv4TlWUwKJq+ulLO+3QEcQmMnMA+NBoMRGxD3BGk/Jj6jYvyMxrgdsb2v9xFdus6emdHq8kSZKkx2vx/+1xo/5yscq8aobgiIeAdeu2h+tmMAZwOjAZeP3ILMTMPKDavyW1hTaf08kxmSB2KTMXAgtXR9sRsahJ8dzMvGV19CdJkiTpiVd/uVgLNwBHADdExI7UFr0ccQJwV2ZeXl8hIiZl5iC1aacDnR6TCWKHMnPfVdjWImBRQ5nTSSVJkiRBbQTw4Ii4AVgMHB8RHwLeBbwSWCci3lDFfjMzPwIsqNZB6QfO7LRDE0RJkiRJGoeq6aQnNhSfXn0/mCZKB7RMECVJkiT1pHF+CeK45CqmkiRJkiTAEcSe8v53vLLruuvPLHsp/O89y7que/wLtyrq+3f3PVJUv8TkvrK/sfznba1usTm2FUMt77LSluWD3def/75XFPW921brd113ZeF5v/FLPyuqP3Vyf/d1J5W9Xh6+sePrzB912vlvL+r7w+/8p67r9m37vKK+hwdWFtVfuf92Xdf93f3Li/qeMaX7n/k3jt+tqO+Bwe5vjXvu5msX9b3W1O7fJwBT+7v/k39/4V2xp0wq6buoazYr+Gz8671lvwtL/x/wl8WDXdctvZH58oHuX+ulP7OS36WlhobLbn/d59CaWjBBlCRJktSTTIQ75xRTSZIkSRJggihJkiRJqjjFVJIkSVJPcoZp53puBDEiNljTxyBJkiRJT0Y9lyACV9RvRMSxY1WIiLUiYu824naLiJMKjq2xvc0j4vltxH1+VfUpSZIkSa30RIIYEbtHxPURcT0waeRxROwMHFMXd1Hdvu9XZQuA9YGj6+LWjYivR8R1EfG9iHh9tWs6sF5d3EF17f1P9TWyfUiT41zQULQ9cGDd/vMiYlH1dWtEHF/t2rDoCZIkSZImoIgY11/jUU9cg5iZP4iI2cCZwJbAH4FzM/OB6smfBSzLzLlQG7kDro6ItwLrNGnyZOCzmfmtiOgDFkXE15v0ew1wTdXmecCkzDxtlEOdMsZ5nDHyOCI+B3x3tHhJkiRJWpV6YgSx8gng85n5WuDfgI9X5X3AJcBz6mJfSi2x+y3Q7M7T9wDTqsf9wMNAy7slR8TTgOcCu1aPm8UE8PyIGDVJrGKfB8zKzF/Xlc2OiO3HqitJkiRJ3eqlBHEWcGf1+HZg7erxcGbOzsz/qoudA5yfmQuAJU3auhjYPCI+ALwPOC0zB5t1Wl1DeAlwHPBG4LMR8eImofsBdwCHjXYSEfFM4CLgLaPF1cXPiYibI+Lmm/79S+1UkSRJkiaEiPH9NR71xBTTyunAxdVc3mHgHc2CIuIfgIXAcdVo38aNMZk5HBFXAwdURftExD7V46vr2voUkNSSvg2oJdyvBs6LiDdk5pwqbhJwUtXepRFxTWY+3HBc04ATgFcBR2XmXQ3HNL/Z+WTmPGAewIcX/T6bxUiSJElSO3omQczM/4mIT2fmdxp2fXjkQUQcALySWkK3KbVppM9s0eRialNQ6z0LOBj4cbX9lswcrtp+FbVrEC8D3lJNKR1JDj8FXJKZf4qIM4GvRsRRTfq8D9gvM4faOWdJkiRJWpV6JkGsvD8iGheJ2QnYOCI2BI4CZlcJ2B0AEdHsGkSAZwCnNpQ9Bfj2yMZIcthMZo6M5m0GLMzMq6ryH0fE2dRGHuvjlwNXRMSVNExDzcwDkSRJkqTVrNcSxAcak6mRW0tk5r3A/+ugrU2AK6oRwcepppye0aT8mLrNCzLzWmrXRD4qM39cxTZrenoHxyhJkiSphb7xeqHfONZrCeK61b0Q6+1U0N5pDQkfwM8zc25mLqR2LeMqFxGLmhTPzcxbVkd/kiRJkgQ9liBm5m5d1BkZcXxTQ/l8oOnCMKtKZi4CFrU4HkmSJEl6QvVUgihJkiRJI5xg2rleug+iJEmSJKmAI4g95Pr/ubfrumvPmFzU951/eaTrum96/pZFfT+8stVCtGPrL7xwea0pZc/b0HD3t64svei6v6D6d35zf1Hf2623Vtd1VwyU3QVm/2euX1R/xuT+ruv+4f7lRX1vtvbaXde9eOEfivru2/Z5Xdcd/l3h5dNTytbumtx3wNhBLawzvfufN0AW3J32tnuXrrG+b/zVPUV9T59e9tk4bUr3z/u0gvcowGbrzui67vO3nFXU951/vK/ruo888FBR3ysHy26lXPL7rOWS8G2aUvILrVDJ+6x07RQXX9HqYoIoSZIkqSe1uGuARuEUU0mSJEkSYIIoSZIkSao4xVSSJElST+pzhmnHnpQjiBHx6jZido2IU9psb++IGHXVjIjYPiKe0WZ7X2gjZvOIeP6qipMkSZKkUuM+QYyI2RFxbEPx2+r2Pz0iFtV9/bHaNRVouuRfRCxqKDoaWL/at0dE/D4irq/72gx4HvCihnaOiojvRsS1EXFlRIwsj7h5kz6PjYhj6oq2Bw6s2//shj7vbRYnSZIkSavLuJliGhEbAicDw5n5rrpd/dVXU5n5f8BeVRvbAueO0v4Hqs1dI+Li6vFZTcI/l5nvbajf2N404ERgr8wciogDgXcAp7c41H5gtMWQfwucULd9ed3j4yLiuZl5+Cj1JUmSJNVxFdPOjacRxIuAFUDjzZO2BLZus40PAh+t2352RBwGkJn3ZuYJwJeAh4DvZeYJmfnXLo93JfAwf0tepwN3jhI/1nk8H/gkcEj19W91+/7V5FCSJEnS6jZuRhAz8/URsRePn065JzBltLpR+9PA+cDPMvNHLWJmAG8AXgA8Czg7Il4CXNDBYZ4UEYcCr83MgYh4B/C+iBgE7qGW4LXyYh4/EnpkRDwbeHO1/d/AFdQS92kRsX1VfmxEPCczj+zgWCVJkiSpI+NpBPFxIuKVwI+Ar0XEW1vE7AJ8A7gjM89r2P3LzLyyevwU4E+ZeSxwamaeDnwYuJf2fTwzD83MAYDM/BXwS2rJIcCbq+P8asMxHgH8J/DvETGnbteXM3N2Zt4P3E5tVPLt1BLG2cCOwCBwcavkMCLmRMTNEXHzHTde1cGpSJIkSdJjjZsRxEYR8QLgeOBwYAD4fEQszszLG0LXB+Zm5m9Gay8z7wK+WW2+pCq7reqrMXz3iDiV2ojfVGpTR5e0aPqPQOM01fOoRhMj4kXA64HXUEv2vhARS4E7Go7vdmqjmgcDfwdsDDwXuIba9NtW5zUPmAdwwL/8aLRrHCVJkqQJxUsQOzduE0RgZ+D1mbkSICLeALysMSgzF0bECyLizMz8YF35TcBNI9sRcSS1FUH7gG0i4jxqyd99DU3+HHg3tQVlElhGbYTw5S2O843AVg1l9ds7VecxUB3H/wN2Bx73co2IA4BjqC1282dgPeA04CTgn1r0L0mSJEmrxLhNEDPzkobtAeD6FuH9jHGdInAL8BtgCPg6tQVxlgKLqVvYJjMXU5dYjhhlBaTNMnPfVjsz8zMN2wPAd6vrLRttDvwiM0dGF++LiJtouL2GJEmSJK0O4ypBzMxFwKIuqx/bJOn6RWa+rWr7d60qFi5/u3FENEtc52bmzzts6/PA+RHxH9Smo/YBf6J2+w9JkiRJHfA2F50bVwliuxpH7KrppE8taO9NbcTMb1G+a5d9LqIhGa5GF+d2054kSZIklRrXq5hKkiRJkp44T8oRREmSJEkaS58zTDvmCKIkSZIkCXAEsacsXTbQdd1J/WV/Xlm+fLDruoNDZbdvXJMXHw9n6bEXVC6862VfQefLVg4V9Z0Fz1vpzT5nTO4vqz+p+/rTJpe9VqcX9L1kycqivocHCupPmV7UNyuXldUvUPqX55KPt9JPtij4E/DSpd3/PlkVSj5aCz+WGRzuvoFJhb+Pli0peK0vfaio79JfpSX1+4p/n3Vft+DHDUB/wfustG9pdTFBlCRJktSTXMW0c04xlSRJkiQBJoiSJEmSpMqEnWIaERtk5n1r+jgkSZIkrR5OMO3cRB5BvKJ+IyKOHatCRKwVEXu3EbdbRJzURtyrx4rpJE6SJEmSSkyoBDEido+I6yPiemDSyOOI2Bk4pi7uorp936/KFgDrA0fXxa0bEV+PiOsi4nsR8fpq13RgvSb9X99Q9LaG/RfU9XtLRJzdLE6SJEmSVocJNcU0M38QEbOBM4EtgT8C52bmAxFBRMwClmXmXICI2By4OiLeCqzTpMmTgc9m5rciog9YFBFfH+UQpoxxiB8DZlSPdwOeVj3uj4hFwEcy85tjtCFJkiSJstt6TVQTagSx8gng85n5WuDfgI9X5X3AJcBz6mJfClwD/BZodlOoe4Bp1eN+4GFgebNOI2IS8LzqeyufAw6pvjYErq3KhzJzL5NDSZIkSavTREwQZwF3Vo9vB9auHg9n5uzM/K+62DnA+Zm5AFjSpK2Lgc0j4gPA+4DTMrPVHeMPpjZi+aq6sr6ImB8Rc+rKrgC+AMwHFkfEWlXc9RFxSPunKUmSJEmdmVBTTCunAxdXN80cBt7RLCgi/gFYCBwXEU8DNm6MyczhiLgaOKAq2ici9qkeX13X1mTgRGB/4LKIuDYzH6FKSuuavILatNVhaiOW9wPfAB7OzENbHOccaoks2x1xGpu86FXNwiRJkiRpTBMuQczM/4mIT2fmdxp2fXjkQUQcALwSOAzYlNo00me2aHIxtSmo9Z5FbcTwx9WU0s8An8jMO6qFZ74aEUc31CEzL4uIDYG3As+j9vPZFpg7yvnMA+YBvPSiG7NVnCRJkjTReAli5yZcglh5f0Sc1lC2E7BxlaAdBczOzCHgDoCIaHYNIsAzgFMbyp4CfLt6vAXw7cy8GiAzb4qIdwGtpqJ+EfgIcB4wBDwXmB8Ru2dmq2OQJEmSpGITNUF8IDMPrC+obmNBZt4L/L8O2toEuCIzL2u2MzNvA25rKPtJ1WezKmsDN2Xm8irmZ8BKaqOYJoiSJEmSVpuJmiCu2+SehDsVtHdaRBzTUPbzkdtldOgUaiOGI9uTgIsyc3HB8UmSJEkTTosBGY1iQiaImblbF3VGRhzf1FA+n9qKo90cx75Nyr7P3xa9kSRJkqQnzES8zYUkSZIkqYkJOYIoSZIkqfc5w7RzjiBKkiRJkgCITG+d1ys++5Pbu/5hDg2XvQ4m93X/55kbf/9wUd9P22BaUf0SS1cOF9VfPtj9817wlANlf1Hbep2pRX3f+dDKrusuHSh7zqdMKnviVhb8zGZOKfub3Mqh7vt+2nplP7OSvks+H1aFU996Ydd1N9374KK+7/rPq7uu++b3v62o74GCn9lOm04v6ruv8E/2w2vw/yYlz9uSwt8J0yZ3/7z1Fz7nJZ/LAJP7u++/9PWyYrD7573gxw3AlILzLlX6NukvHCZ67/7bPynG5o7/6q/GdbLz6SOeNe6eR6eYSpIkSepJpX+AmIicYipJkiRJAkwQJUmSJEkVp5hKkiRJ6knOMO2cI4iViJgZEfuMEbNVRGzRRlv7RMRebcQ9IyJ2aCNuv4h4+VhxkiRJklRiwiaIETE7Ik6oK1oXeF1DzIKGai8H9mrSVmPclsAWdfuvjYhFEXF/9X1+tetFwAubtHd9Q9HmwGajnI4kSZIkFZtwU0wj4g3AbsCOwOSI2AX4IbCwIa4f2DUi+jNzaIxmR03eMnP/iJgC/J5aknl2RCwCNgHOaeh3U2D3iNgI2Bt4KfAM4LJ2zk+SJEmSujXhRhAz81LgLcD9wBJgbmZe3iR0DnAL8I7R2ouInYGnRcQLxuj6JOBfgHdm5vszcy/g/Ia21gI+DrwWmAf8MDPfClwx1nlJkiRJeqyIGNdf49GESxAj4jnAl4BPAacD8yPi6IaYY4CdgVdU2xdExOPuMh0Rk4H3Ay8DzomI9ZrETIuI9wLLMvODwB8i4tKqbn3c2sAngLMz89vAicApEbHm7gIvSZIkaUKZcAkisA210bwl1K47PAz4ycjOiJgJ9AMnZs15wKWZuQK4DfhjFfcU4KvAJzPzp8DbgSsiYkZDf8PAtZn5zwCZ+SXgpMwcAP4E3FGVP5yZxwLrR8TZwHHAfcCp1K5n/Fmzk4mIORFxc0Tc/N0rv1jyvEiSJEma4CbcNYiZeRVAtcrorMwcBG4dWZ00M5cAl0fEGyLiWGCgigeYCpxXxT0UEW8H7o2IKZn564h4RWZm/XBxZq4EfhARlwDbjZTXxZzbcIi/B1Y2lB0E7AL8ssn5zKM2HZXP/uT2bP+ZkCRJknrbRBwNKzWhEsRqAZhjqY0Q7gzMqG4zMQ34TkP4xsB7MnNRXf1jgEenkWbmbdVo343AoszMqvyyxr4z801NjufYqp96ewGNsZvQcL2iJEmSJK1qEypBBB6klggOAVcBg8AyYCkwk9riMGvaU4Fz6hNTSZIkSXoiTKgEMTOXAT9ttq/ZIjTARRHxQN12q5G8xjiAqzPzI2Mc0n3UktVV1Z4kSZKkynhdKXQ8m1AJ4mgy8w5q009Hts+njWmdmXkODfcy7KDPbzUpa6tfSZIkSVrVvG5TkiRJkgQ4gihJkiSpR/U5w7RjjiBKkiRJkgBHEHvKZjOmd113KMtuoTip4M8z685cVtT35DX4p6Fpk8v+xtIXa+7WlSuGhruuu+msZms6te/Ohxpv9dm+GYXP+Z8fWl5Uf3Co+5/ZcOHz9uDS7p+3528+q6jv393f/fO2zvT+or5L3+Kb7n1w13Xv+s+r11jf688o+xU9ONz9a3XD6WWv1TWp9FN15VCztePaM5Tdv0cB1ps2uah+ibtiYI31PVz4f5Dlg93X7y8cKsns/gNqoOA9umo4tKbmTBAlSZIk9SSnmHbOKaaSJEmSJMAEUZIkSZJUcYqpJEmSpJ4U4RzTTjmC2KGImBkR+4wRs1VEbNFGW8+IiB3aiNsvIl7eyXFKkiRJUqdMEMcQEbMj4oS6onWB1zXELGio9nJgr7r910bEooi4v/o+v9r1IuCFTfq8vqFoc2CzLk9BkiRJktriFNMWIuINwG7AjsDkiNgF+CGwsCGuH9g1Ivozs+na2Jm5f0RMAX5PLXk8OyIWAZsA5zS0tymwe0RsBOwNvBR4BnDZKjs5SZIkSWrCEcQWMvNS4C3A/cASYG5mXt4kdA5wC/COMZo8CfgX4J2Z+f7M3As4vz4gItYCPg68FpgH/DAz3wpcUXAqkiRJ0oTUF+P7azwyQWwhIp4DfAn4FHA6MD8ijm6IOQbYGXhFtX1BRExtiJkWEe8FlmXmB4E/RMSlETG5IW5t4BPA2Zn5beBE4JSImLZaTlCSJEmSGpggtrYNtVG/JdSuOzwM+MnIzoiYCfQDJ2bNecClmbkCuA34YxU6DFybmf8MkJlfAk7KzAHgT8AdVfnDmXkssH5EnA0cB9wHnApsAfys2UFGxJyIuDkibr76K59bdWcvSZIkacLxGsQWMvMqgIjYC5iVmYPArSOrk2bmEuDyiHhDRBwLDFTxAFOB86q4lcAPIuISYLuR9uuW3D23oevfAysbyg4CdgF+2eQ451GbjsqCX92bnZ+pJEmS1Ju8y0XnTBCbqBaKOZbaCOHOwIzqdhTTgO80hG8MvCczF9XVPwZYrz4oM9/UpJ9jq/r19gIaYzeh4XpFSZIkSVrVTBCbe5BaIjgEXAUMAsuApcBMaovIrC5PBc6pTzglSZIk6YlggthEZi4DftpsX+MiNJWLIuKBuu12R/zuo5aEjtUewNWZ+ZE22pQkSZIE9DnHtGMmiB3KzDuoTT8d2T6fLqd/Zua3mpR13Z4kSZIklXAVU0mSJEkS4AiiJEmSpB7laFjnfM4kSZIkSYAjiD3lz0uXdV03C++g2F9w/e8DSwaK+l5nen9R/RLLB4bL6g92/8T3FV5zXXLN9l2PrCjrvMDSwud8o7WbrTPVvpUFP7OZU8r+Jjd1UvfH/tdlZe+zGQXHXvr5MlRY/67/vLrrupvuffAa6/u+vbYp6nuw4K3y1+WNt+N9Yg2XvmgKDBS84JYPlB33/XT/Pu0vXIhjaLjs2PsLfimVLiIybVL39QcKz7vk0KeU/OeJVfB/N4eJ1IIJoiRJkqSe5CKmnfNvB5IkSZIkwARRkiRJklQxQZQkSZIkASaIAETEq9uI2TUiTmmzvXNWVb9V3HntxEmSJEn6m76Icf01Hk24BDEiZkfEsQ3Fb6vb//SIWFT39cdq11Rg7SbtHRsRsxuKX1S3/6iqnVsj4pfV4wMb+62LnxMRRzYUv6DN05MkSZKkrvXkKqYRMQX4GrAWEMBRmXlntbu/+moqM/8P2KtqZ1vg3DG6WwuYMkp7XwS+GBHvBe4Dvgl8LiLeCWzQpMquwPKIuAYYGTlcb4xjkCRJktSDIuIDwJ7Ucrc5mfmrqnwW8Blgc+B+4PWZ+XBEHArMpZajfCQz/62T/np1BHEQ+LvM3Ivak/b/6vZtCWzdZjsfBD5at/3siDisIealwIGMIiLWBbYCngsMZeZe1bHd3RD3amA5sBI4BnhbZr6V2g9ckiRJUgcixvfX2McfLwU2zsyXAccDH67b/Y/Av2fmnsB1wIkRMRM4FdgXeDnwzoiY1slz1pMJYmYOZ+bSanN74Bd1u/cEdh+tftR8CPhZZv5olLiDgD8CP4mI41vEPB+4GHgncApwQUQc0CTu/1XHekpmng48Ahwx2nFKkiRJ6mn7A18CyMxf8tiZhS8HvlI9/hrwYmqXui3MzBWZuQT4EfCMTjrsyQQRICJOi4jfAM8H/qMqeyW1J+lrEfHWFvV2Ab4B3JGZjYvD/DIzr6zijgTeAJxVxW0ZEW9q0mQCb8rMv2Tmg9RGBm+s9t30aFDm5Zl5IXB6RJxNbZTz6dXjr49ynnMi4uaIuPm7V35xlGdEkiRJ0nhS/3/56mtOQ8hGwL1124MRMZLDTc3MgerxX4F1m8SPlLetJ69BBMjMDwMfrkb5/jki/pnasOzhwADw+YhYnJmXN1RdH5ibmb8Zo4sfUsvU1wZWZubZEY8fKM7MWyJij8aVTavQOxvjgWt5fOL+YeBfWpznPGAewGd/cnuOccySJEnShNE3PhcKfVT9/+VbeIjHJnjDmTk88jgi+qrtdaklhg8B29XFj5S3rScTxIhYC3gkMxO4HZgF7Eztws2VVcwbgJc11s3MhRHxgog4MzM/WFd+E48d8ftT1c5XqM3xpeqPzNy3oc0bqRa+aTjO65sc/jk8ftGb9cc4ZUmSJEm95wZql53dEBE7AnfU7fsR8GrgSuA1wPXAj4GzIuJ8YDLwbODXnXTYkwkitXm2H4uIFcAy4K2Z+Yf6gGo4tlmCBrVVTluuTLqa9TUmmJIkSZImpG8DB0fEDcBi4PhqrZR3Ubvjwecj4u3Ab4G3ZOaKiLiM2iVty4D3ZOZgJx32ZIKYmT8BXlLYzLERsVdD2S8ys/HehTu3GAmcnZn3jdHH/zUpK2lPkiRJUmW83oy+XdX00RMbik+vvt8HHNSkzmeo3cmhKz2ZIHaqyZTQm4Cntll3w4J+39KkbNNu25MkSZKkEj27iqkkSZIkqTOOIEqSJEnqSU/yGaZrhCOIkiRJkiTAEcSecvmNf+q67tKlA2MHjWLjDWZ2XfdnP292O8j2bbfDRl3XLf2r0tBQ2a0n93hG15ew0r8Gb+zzz9++taj+PXf+teu6/f39RX1f+97HXcvdkYGh4bGDWvjzI8uK+t76Kd2/z0775q+K+v7G8bt1Xfe2e5cW9V36Sn/z+xvXFmvf+jPKfk3et9c2Xdf91Hs+WdQ362/RddW9j3h5UdcDg92/T9a0mdO6/5lvtt6Mor533bz79/iWs8r6/t97yj6fNpw8ueu6w1n2u/Qp07r/vbB0oOy1Orl/zf0ujsJPx8TbZ6s5RxAlSZIkSYAjiJIkSZJ61BqccPWk5QiiJEmSJAkwQZQkSZIkVUwQgYjYOiL2WEVt7RMRe62Ktqr2Xr2q2pIkSZImkhjn/8ajCXUNYkRcBOzcUHxO9X0P4MYq7svAeg1xO2TmVnVtXQtMAXYCfgHcnZmzgS2BwYZ+XwK8u74IeF9mfr8u5gLgudXmusCVmXkO8DbgG52dqSRJkiR1bkIliJk5NyKuycyDIuJYYDHwZmBb4Mq6uCMb60bE1Q1t7V+V/yoz9xqj64uAV2TmX6s66wNXA/Xrxn8MGFmjejfgadXj/ohYBHwkM7859llKkiRJUncmVIJYGaq+TwX+kplHVlNCx5pi+ribxUTEbsDG1Qjh84CXA1sBH2kIvQV4dURcX22/vCqr9zngW3Xb144cb2buO8axSZIkSWrgKqadm4gJ4sgdUacBy6vppNsCV0bEfsBZLertVI3knZ+ZCyJiGnAm8BLgE8DRmfnxamTyMTLzLRGxO3BwVfSLzLysSR9XUJt+2g+sGxFrAX1VYvmxzPxWkzqSJEmStEpMqAQxIs4EFkfE2cDmwGbA14G7gT0y8zrguir2CGCdzLwkIhZk5vp17axLLZn7YGb+X0S8BbisqlPfX2PC2U9tYaCBiEf/nHF+Zi6o2juZWgI7ANxP7drDhzPz0FHOaQ4wB2D7157Gpi92TRtJkiRJ3ZlQCWJmfhAgIg4Fng5sA2xNbTrnhSNxEbHxGO08EBHHA4MRMTMzfwO8oqpbH/dowlntOwTYLjM/1qTNyyJiQ+Ct1KarTqI2sjl3jGOZB8wDeNlHv/+4abCSJEnSROUU085NuNtcRMThwGuBdwGHAP8IPBM4sS7scuAPwK+r7QWN7WTmHcAJwK4N5Zdl5hUNfV7e5uF9EbgJmA0cBvwbMD8iJrdZX5IkSZK6NqFGECubATdn5m3V9l0RcQOwZ31QZt5S9/hjhX2OjEguBL43StzawE2ZuRwgIn4GrKR2veRA4TFIkiRJ0qgmYoI4Dzg/IhZSW9G0D7gNOKUuZsdqQZpGR2fmnQ1lH42IhxrKrs7M+pVMn1m3gmn9NNTXZ+af6+JOoTZiOLI9CbgoMxePeVaSJEmSHqP+8i+1Z8IliJm5kscmg81itmqzrfcC720jbus22/s+cEA7sZIkSZK0qk24axAlSZIkSc1NuBFESZIkSRODq5h2zhFESZIkSRLgCGJPmTqlv+u6g4PDRX1Pn9p935llt28cGur+2PsK/6w0PFz2vD2wbLDrupMKj73kou3+/rK+B1d2f96D0X1dgMKXG6zBu42WHPv0gs8HgIHB7jsvfc6j8E+ZA0PdH8DgcNnBF320rr9FUd/89Y6uq06bXPZ6KV0TouQ1U/o7paT68pVDRX1P7e/+xT6loC7AyoLfpVD2M++j8HfxGvxcjoJjzzX5C4U1+7xpfHMEUZIkSZIEOIIoSZIkqUd5l4vOOYIoSZIkSQJMECVJkiRJlSdlghgRW0fEHqu5j1ePtt2w78URsecTcRySJEmS2tMXMa6/xqNxfQ1iRFwE7NxQfE71fQ/gxiruy8B6DXE7ZOZWdW29Ajit2twaCOC2avsjmfnNhvpvA77Rajsi9gLOrja3qxXFb6rt8zJzYV3sS4B3158a8L7M/H5dzAXAc6vNdYErM/OcJschSZIkSavFuE4QM3NuRFyTmQdFxLHAYuDNwLbAlXVxRzbWjYirG9r6dkQsBF4L7Elt9PQG4N8yc1lVZ0f+lsitjIj51eN/anJsi4BFEfFS4APAEPDuzPxBk1O5CHhFZv616md94Gpgt7qYjwEzqse7AU+rHvdHxCKaJ7GSJEmStMqM6wSxMnJToanAXzLzyGr0bqwppo+5u0tEHEUt6bomMz9fle0NXBgRt2fmhzLzf4DZEXEg8ALgV9RG8rLxnnERcQrwMuC/gVdW/b0jIk4HfpCZH6oLvwV4dURcX22/vCqr9zngW3Xb146cf2buO8a5SpIkSWpQeNvoCenJkCCO3Ll1GrC8mk66LXBlROwHnNWi3k7VyNv51JLMOVX5fk1uEP6siPh5Zi6oEr+1gCuAg4ALqKamRsQmwJLqmK4Gvl7VX7/6/tnq+8yImJWZjwBk5lsiYnfg4Gr/LzLzsibHfAW16af9wLoRsRbQVyWWH8vMbzWpI0mSJEmrxLhOECPiTGBxRJwNbA5sRi0puxvYIzOvA66rYo8A1snMSyJiQWau39DcdXXtHgNMapGk7Z+ZB1aPPxkRC6rHfcA7ge8Cv6c2VXU0X4uIDXhsAttftTNQl6Sen5kLqCWHJ1NLPgeA+6lde/hwZh7aqpOImEOV/D5z9ulssUfLUEmSJEka1bhOEDPzgwARcSjwdGAbagvMXAtcOBIXERu3015EbA2cCuxd24znAx/OzD/Whf00ImYD/wbsC/ypKh/OzJPr4n4eEZsDpwA7VmX/C3w0M/9UF1efmB4CbJeZH2tyrpdFxIbAW4HnUfvZbAvMHe2cMnMeMA9g/3++KUeLlSRJkiaScbpQ6Lg27m9zERGHUxutexdwCPCPwDOBE+vCLgf+APy62l5Ac/OBr1JbLXRX4CvUEsF676a2IuqngecAJ41yeF8Evkxt6ujBVVtfanIOl4/SRmN7NwGzgcOq9uZHxOQ260uSJElS18b1CGJlM+DmzLyt2r4rIm6gthLpozLzlrrHH2vRVj/wX5m5EiAifkpDkpyZg8C/tHls04H/zcys2vsfaovpNBoZ4VwIfG+U9tYGbsrM5VV7PwNWUrv+cqDNY5IkSZKkrjwZEsR5wPnVLSqGqCV0t1Gb2jlix2pBmkZHZ+adddunAV+pu/4vgNMLjq3d9p5Zt4IpdfGvz8w/18WdQm3EcGR7EnBRZi4uOEZJkiRpQurDOaadGvcJYjXad8oYMVu12dZ3qS0y081xPO5WE+22l5lbt9nH94EDOj86SZIkSSo37q9BlCRJkiQ9MUwQJUmSJEnAk2CKqSRJkiR1w9tcdM4EsYfc8NnH3WGjfX39RX3/dHio67pvOvuEor7//MDSrutO6i8bRJ85tewt9MyNpxfVLzFravc/889cONpivGPb/e8O7rruypXdv9YAnrbRjKL6Uyd1/7wN/bHsVqXbbTyz67rXfeU/ivo+d/O1u65746/uKep76dKyRZzfctB2XdfdcHqzhanb99flK7uuu/cRLy/qe9rk7l+r13zy0qK+S3+n0F9wd6dJU8r63mTbrqu+eK8dxw4axVuu/GnXdafPKvt98tbZzy2qPzDU/efbyoK6AFP6C19vBSYV/DdiYLis78Fhb3+t1cMpppIkSZIkwBFESZIkST2qzymmHXMEUZIkSZIEmCBKkiRJkio9PcU0IrYGtszMG1dBW9sD/Zn56zHiXgy8IDM/XtqnJEmSpO71uYxpx3oiQYyIi4CdG4rPqb7vAdxYxX0ZWK8hbofM3KqurSuATYBdgf+qig8HngdMA35dxZ0NHAE8WMVskJnPBqYCj1nuLyIOBE4FhoAA+oELM/OahrhbgT83HN+9mfna1mcvSZIkSatGTySImTk3Iq7JzIMi4lhgMfBmYFvgyrq4IxvrRsTVDW0dU5V/LzP3rYtr1vXJmbmo2v+LiJgPbAQ0rid/DrB3Zi6uYtcCFgHXNMTdXt+nJEmSJD2ReiJBrIzcHG0q8JfMPDIi9qI2gjiaVjeR2T4iNszMe9vs/57MnN2iz/8Ejo+Im6iNIO5WlUmSJElaTZxh2rleShBHbjc6DVheTSfdFrgyIvYDzmpRb6eIWAScn5kLACLiecAK4DBgXpv9b9xqBDEzT6uuhzyR2vTST2bmH9s+M0mSJEl6AvREghgRZwKLq+sCNwc2A74O3A3skZnXAddVsUcA62TmJRGxIDPXb9Lk6cCrgX+KiPmZ+XCTmAeBMyLirdX2XY0jiE0S042pjSC+oG7K6qOJKfBAlayOxN1dlR+UmctanPscYA7ApK1ezqQNnt0sTJIkSZLG1BMJYmZ+ECAiDgWeDmwDbA1cC1w4EhcRG4/VVkScAdycmT+PiFOBf42I45r0+cmI+DQQmbmyxXE9mpi2eR6vrY7hGOD/s3ff8XIV9f/HX+/cNAgldARpioIKKkUICAISiohgFwERW0Ckg4IKUvVLVRBrbIiAiCC9tyAoXeSHSu8qTXqAkOTez++Pmc092Ww/9+a29zOP+8ju2fmcmS1ndz87c2ZGR8SpLcRMJfdyLrDOPvWGy5qZmZmZjTiexbR9w2YdREkfBz4FHApsC+wHvIM0rLPit8Aj5JlIgcur9rEoEBFxHOnC7cCJwMJ1qv0MsGNxQ0RMi4iji9skHdfBXTIzMzMzM5uvhkUPYrYcqefv0Xz9SUk3AB8oFoqIOwqXT6q67SXgmKptN0PdWUxbtXajG+udI5lnZK0oDkU1MzMzMzPrc8MpQZwKHCPpGtKMpqOAR4H9C2Xemc/xq7ZTRPynw3oPrkrkAO6OiL0K11drVG+7Q1HNzMzMzKw5jzBt37BJEPN5gPs3KbNiif2fVWPb6cDpLcSu0Gm9ZmZmZmZm88uwOQfRzMzMzMzMynGCaGZmZmZmZsAwGmJqZmZmZmZW5N6w9jlBHE40gIdA15iOQ2fM6i5V9RuzejqOjZIrR87s6rxugJ4S9XcN5DtelLvfM2bM7jh29uxydQ+k7rIvuDJKHKMAC4/r6jh2gQXK1V3WUF0Da1bJ13qpuz2q8+cbgJ5y7+ul3pxLvj8xY3rHoa++WnNZ5JaNGdv5sTJugXGl6rbOlJnlvuw7k1TuM2UgP5JscHNSbWZmZmZmZoB7EM3MzMzMbJgquZb5iOQeRDMzMzMzMwOcIJqZmZmZmVk2YAmipJUkbTRQ9bdL0kcGug1mZmZmZtY6DfK/wajfz0GUdCLwnqrNR+f/NwJuzOXOBhavKvf2iFixf1vYS9J7gBOBBYEVgPuAmyPiEOBrwEWFsqcAa+ar6wN3ATPy9S0jYmYu1wUcBWwIzCIl5U8D+0bEM4X9TQamAo9XNet3EfGrPrybZmZmZmZmNfV7ghgRB0i6LCI+JGlX4BVgD+CtwHmFcp+ujpV0adX1pYB9gZ6IODRvWw34CTAe+GtEfL1EW+8CJkt6F7BnRHy1Qdm9JK1AShxvAlYETo6IW6uKbgEsFBGbFu7H9sDX81/R1Ig4ptP2m5mZmZmZlTG/ZjGtLIg0DngmIj4taVNSD2Ij1Su0nAg8SOrhqzgJ+FJEPCrpj5LWj4hbSrb3zaSEryZJE4D9gf8Bx0fEc3nbLpK+CvwiIv6ai/8N+IqkTwL/BiYCHwV+W7KNZmZmZmbWwFBdC3cgza8EsbJq7XhgRh5O+lbgPElbAN+uE7empGnAMRFxeUTskhPLrQEkjQbGR8Sjufy5wAbALZL2BT6Ztx8CrAy8D1gaWBXYGzg4bz8iIs4u1LstsIqkiRHxYo12HQmsky9/psb0ud8DNgWIiGckfRpYC/hlrneviOh8JV4zMzMzM7N+MD/OQfwW8IqkQ4DlgeWAPwFPARtFxFXAVbnsJ4GJEfFLSZdHxBJNdr8U8Fzh+nPAOyR9AFgP+EBE9EgaRUoEF4yIT0naljQsdR1gUeBC4OzchhWBlYADgUOBA6orjYi5tkm6OiIm17jvJ9KbSJL3e2S+rbKvTfNtLwBbS9qadM7mXXn79RFxWL0HQNIUYArA6BU3Z/RSa9YramZmZmZm1tD8OAfxewCSPgqsBryFlChdCZxQKSdpmQ52/yJpyGbFYsCzpOTwnIjoyW3oyQlZ5fzAB4G/5YlknpU0JrdhMeAXpB6++yVtIGmPiPhJrcpzovl5YG1Jl5AS3VMiojvXO09yWU9E3EHudayXcNaJm0qa3IYF1t2vekiumZmZmdmI5QGm7Zsvy1xI+jjwKVKP3LbAfsA7gOIkML8FHgHuzdcvb7bfiHgdGCdp+bzp48A1wP3AVoX6x1RCiuE1drkhcFRE3J/3fyhpxtFa92kSsBuph3FJYGdSgvqNqnIb5klpzMzMzMzMBrX5dQ7icsDthXMFn5R0A/CBYqHci1a5fFKL+94fOEfSG8CFEXEPcI+kjSXdDEwnnYPYVERcUmPbuXWKTwQeiojKshQvSLqN3AtYsDRp0pu6agxFJZ97WWxH9X7NzMzMzMz61PxKEKcCx0i6hjSj6SjgUVJyV/HO6qQo2yki/lO5EhHTgGmF67eRJqaZS43lLm4u3HYvsGvh+rqt3pGCK4D1JF1HWt9QwJOkSWiq7ZPPryy6OyL2yvW3PBTVzMzMzMysv8yXBDGf67d/kzJ1l5UYDCJi66rrQZpw5sgmcecD5/dbw8zMzMzMrCavctG++XIOopmZmZmZmQ1+ThDNzMzMzMwMmH/nIJqZmZmZmc1X8hjTtjlBHE66BvDpHNXVcejsnnLLN/ZE5/Gzu3tK1d1dsu2jSrxndQ3kG16J5xugu8Tj3lP29VLuKS/1nJdserljZdyEUnWP6+r89TZ+bLnXS4lDHCj3HlHWQNZdququMc3L9FvlQJQ4UHu6y9X9xqsdh06f/kapqkeP6fxzfMzYcs9Z2Y+UMp9nI1XUXHHNbOB5iKmZmZmZmZkB7kE0MzMzM7Nhyr1h7fNjZmZmZmZmZoATRDMzMzMzM8sGbIippJWAFSLixoFqQzskfSQiLhrodpiZmZmZWWs8i2n7+j1BlHQi8J6qzUfn/zcCbszlzgYWryr39ohYsX9b2EvSe4ATgQWBFYD7gJsj4hDga8BFhbKnAGvmq+sDdwEz8vUtI2JmLtcFHAVsCMwi9do+DewbEc8U9jcZmAo8XtWs30XEr/rwbpqZmZmZmdXU7wliRBwg6bKI+JCkXYFXgD2AtwLnFcp9ujpW0qWFy2OBc4GFAQE7RsR/JK0G/AQYD/w1Ir5eoq13AZMlvQvYMyK+2qDsXpJWICWONwErAidHxK1VRbcAFoqITQv3ZXvg6/mvaGpEHNNp+83MzMzMzMqYX+cgVhYlGge8npPBA1qIKy4QMxv4TE60fgF8Pm8/CfhSRLwfWFnS+n3Q3jeTEr6aJE2QdCiwLXB8RHwTmAKsI+k3kjYsFP8bsLykT0qaJGlr4KPAJX3QTjMzMzMzq0OD/G8wml/nIFZWvB0PzMjDSd8KnCdpC+DbdeLWlDQNOCYiLgdey9vfBtwuaTQwPiIezdvPBTYAbpG0L/DJvP0QYGXgfcDSwKrA3sDBefsREXF2od5tgVUkTYyIF2u060hgnXz5MzXGNn8P2BQgIp6R9GlgLeCXud69ImJ6nftsZmZmZmY2IObHOYjfAl6RdAiwPLAc8CfgKWCjiLgKuCqX/SQwMSJ+KenyiFiial9fJ/XU3Q8cBywFPFco8hzwDkkfANYDPhARPZJGkRLBBSPiU5K2JQ1LXQdYFLgQODvXsSKwEnAgcCg1ejojYq5tkq6OiMk17vuJ9CaS5P0emW+r7GvTfNsLwNa5h/E9pHMaAa6PiMOq912oY0p+TBi98haMXrr6dE8zMzMzM7PWzI9zEL8HIOmjwGrAW0iJ0pXACZVykpZpYV/HA8dL+hDwY+CrwMRCkcWAZ0nJ4TkR0ZPjenJCVjk/8EHgb3kimWcljcltWIw0fHWviLhf0gaS9oiIn9RqT040Pw+sLekSUqJ7SkR053pbGUZbuW93kHsd6yWcdeKmkia3YYH1vx5NipuZmZmZjRiexbR98+UcREkfBz5F6pHbFtgPeAcpwav4LfAIcG++fnnVPhZW7zP8OGnil9eBcZKWz9s/DlxD6mHcqhA7Jl8sJlC1kqkNgaMi4n6AiDiUNONorfs0CdiN1MO4JLAzKUH9RlW5DfOkNGZmZmZmZoPa/DoHcTng9sK5gk9KugH4QLFQ7kWrXD6pah+rAydJegN4Hdgzb98fOCdvvzAi7gHukbSxpJuB6aRzEJuKiHkmjomIc+sUnwg8FBGVZSlekHQbuRewYGnSpDd11RiKSj73stiO6v2amZmZmZn1qfmVIE4FjpF0DWlG01HAo6TkruKd1UlRtlNE/CcibgPeX31j3r5Bje3VS0jcXLjtXmDXwvV1W70jBVcA60m6jrS+oYAnSZPQVNsnn19ZdHdE7JXrb3koqpmZmZmZWX+ZLwliPtdv/yZl6i4rMRhExNZV14M04cyRTeLOB87vt4aZmZmZmVlN82tNv+HEj5mZmZmZmZkBThDNzMzMzMwsm1/nIJqZmZmZmc1XXuaifU4Qh5NRXQNXd9eY5mXq6O4pt3xjOh20Mz1R7k2jp0TdAF0l3rRGjyrX9jJ1l9Xd3fnj1t3dU67ukq+3MvEln7JSr7dRY8eWqrurROPHjyn33lTyMCtX98BVXVqZ90ZGl3u9EOWOU3q6ByYW4I3XOw59dfrMUlWPHtv517Lx4/2VbqgRZT+Hh/I7lA1mHmJqZmZmZmZmgHsQzczMzMxsmPIA0/a5B9HMzMzMzMwAJ4hmZmZmZmZDgqSvSvqzpFskbVJ124qSLpJ0vaQrJS2Wtx8q6W+Spkk6rVkdHmLaIknLACtFxK0D3RYzMzMzM2tuOE1iKmkl4CPAJsDSwEXAeoUi44CdI+IlSV8DvgwcD0wEvhARd7VSjxPEKpJOBN4DrAHcB8wC9gAWB7YGbs3l1gFOzGHLAIsB9+brZ0bE1MI+3wccRW+P7Rjg1xHxu6q6/wzUmvpt84goOS2bmZmZmZkNYZOBP0aapvppSc9LmhgRLwJExAOFsi/QO9XtxHy9JUM6QZR0FPAB0v2YEhH/zNtXAG4B7s9F94iIf7Wyz4g4IO/jj8CeEfF0vj6pqtwdkiYD2wCfAF4BHgBOjYiXqnZ7AvCZiHgq72sscL2k8yPilUK5mRExubV7b2ZmZmZmQ5mkKcCUwqapxY6mKksDdxeuP0fqpHqxap/vAD4J7FLZBJwhqRs4OSLOa9SmIZsgStoYWCYiNpG0Bqn7dJt880TgDxGxX4kq3gysCDxdp/4PAe8Dro+Iz+dt6wCHS5oVEd8oFL8Q2EPStcBMYE3gvqrk0MzMzMzM+tCoQT6PaU4G6yWESFoPOC5fvY6UEFYsBjxbVf6LwLtIQ01fy3V8Md+2GHCtpGtrdGjNMWQTRGBL4PcAEfEPSYsXbptIjW5USTcDlwEfAs4HxgKbk4Z1bh0Rb+RyywBLAh8DbquxnzWBg/LVD6rG4GZJu0bEqbl9J0paFvg0Kak8OiJ+3u4dNjMzMzOzkSPPf7IpzMlBjgJ+J2lpYHRETK+UzR1Yb66MiCxsHx0Rs0kjHmfQO/S0pqGcIC7N3BnzbEmjIqIHWBD4hKStSAne1yNiFrAU8LuIOCIniz+KiCMl/RjYDLg87+ubwG7AQZJWiIgnihVHxN3kJwpA0kbA5Ig4vFguP4mnFDYtSsr0f15IKk+tJJLAPZKmFco9mrd/ISIeqfUgFLulR6+yFaOXeW+tYmZmZmZmNoRFxN2S7pT0V+B1YF8ASQcDp5ImsJkk6YM55NY8qvHUfAreaODHEfFyo3qGcoL4EnN3sfbk5JCIuAK4QtIo4AjgK8BPgP9FxMO5/KPAX/LlR0i9jkjaCRgTEddKegT4saTdazVA0pLAgaTkcqn8wJ+UE8h5EslmImKvvN+aCWedmDnd0gtscHDDXwPMzMzMzGzoiogjSPlNcdsx+eIedWJ2bqeOobwO4g2kky+R9E7g35UbJI0GyAnjc4WY6gRqruuSuoBVydl47rU7kDSDaS2/AW4mTTX7duBHpAx9war9Hlcj1szMzMzM+pE0uP8Go6Hcg3gJsI2kG0jjaXeTdCxwKGl46deAblJP4ZS6eynIS0lUZ+T3w7yzmGYTSF23M3KZfwCvkZaxKFq7Ub01hqJWtk8rXC0ORTUzMzMzM+tzQzZBzL2DX63aXJk45vf5rzpmUuHyDoXLJ3TYjH2AqZLGkKaP7QJ+WGNWoEWrkr2KAyLijnaHopqZmZmZmfWHIZsgzm8RcTNpOGlx293Ati3Evq+/2mVmZmZmZrVpkC9zMRgN5XMQzczMzMzMrA85QTQzMzMzMzPAQ0zNzMzMzGyYGqwzhQ5mThCHk6VX6Tw2LSHZMY0Z13HsuNHlOrLHdHUeP2pUuXeNUSXfdRYd3/khOK7E/QZQmbYvvnypunt6Ol+ys1S7gWdefqNU/LgxnT/uL7wxs1TdZdq+6jtXLFX32NGdP+7LLbZg80INzC7xegGY1d15/Mzu7gGre0KJ9weAKPOwLfvWUnUzY3q5+DdeLRH7erm6X32h49CnH3ioVNWrrbdGx7FLLFHuOCurq8Tn6ah5ViGbf8p+jg+kkl9hKPH2ZMOch5iamZmZmZkZ4B5EMzMzMzMbpkZ5FtO2uQfRzMzMzMzMACeIZmZmZmZmlnmIaYskLQOsFBG3DnRbzMzMzMysuSE8D9GAcYJYRdKJwHuANYD7gFnAHsDiwNbArbncOsCJOWwZYDHg3nz9zIiYWtjn+4Cj6O2xHQP8OiJ+V1X3n4Fa04luHhHlptIzMzMzMzNrYkgniJKWAvYFeiLi0ML2FYBbgPvzpj0i4l+t7DMiDsj7+COwZ0Q8na9Pqip3h6TJwDbAJ4BXgAeAUyPipardngB8JiKeyvsaC1wv6fyIeKVQbmZETG6lnWZmZmZmZn1tSCeIpB68B4HqxX8mAn+IiP1K7PvNwIrA07VulPQh4H3A9RHx+bxtHeBwSbMi4huF4hcCe0i6FpgJrAncV5UcmpmZmZmZDaghnSBGxC6SNiUN/SyaCMyz0q2km4HLgA8B5wNjgc1Jwzq3jog3crllgCWBjwG31djPmsBB+eoHay3cLWnXiDg1t/NEScsCnyYllUdHxM/bua9mZmZmZtYen4PYviGdIDawIPAJSVuREryvR8QsYCngdxFxRE4WfxQRR0r6MbAZcHmO/yawG3CQpBUi4oniziPibmDTynVJGwGTI+LwYrmcSJ5S2LQo6VzFnxeSylMriSRwj6RphXKP5u1fiIhHat1RSVOAKQCj370To1feuPEjY2ZmZmZmVsewTBAj4grgCkmjgCOArwA/Af4XEQ/nYo8Cf8mXHyH1OiJpJ2BMRFwr6RHgx5J2r1WPpCWBA0nJ5VL53MeTcgI5TyLZQrv3yvutmXDWiZkKTAVYYPufR6t1mZmZmZmZVRuW6yBKGg0QET3Ac4WbqhOoua5L6gJWJU18Q+61O5A0g2ktvwFuBjYB3g78CDhV0lznREo6rpP7YWZmZmZmndMg/zcYDaseREnHAoeShpd+Degm9RROaSU+LyVxRNW2+/O+J9UImQDcGhEzcpl/AK+RlrEoWrtJu6uHola2TytcLQ5FNTMzMzMz63NDPkGMiGnAtHy5MnHM7/NfddlJhcs7FC6f0GH1+wBTJY0BBHQBP6yxzMWiVclexQERcUe7Q1HNzMzMzMz6w5BPEOeXiLiZNJy0uO1uYNsWYt/XX+0yMzMzM7PaRg3OUZyD2rA8B9HMzMzMzMza5wTRzMzMzMzMAA8xNTMzMzOzYWqwzhQ6mDlBHEbW3uidHcd2d/eUqnvcuM5fSossUD3pa3tm93S+/GPZt4zRXeU64Rcc3dVx7LiuzmMBZvZ0/pyvsd5qpepeaKGxHceWfcyveeSZUvETxnb+uD//2uxSdT/20usdx07Z8q2l6i7zsK+7wkKl6h6tckfqf1+Z2XFsd3QeCzBjVufvT8stvmDzQo3qntndcewGm3b+eQLw6qvlHrfp09/ovO7p5ep++oGHOg9+8oFSdW/8ni07jn3TIp2/rwJ0x8AtpdxV8iSxMm0v+fZCd4nvIDHP6mvzV88APuc2uHmIqZmZmZmZmQHuQTQzMzMzs2GqbC/xSOQeRDMzMzMzMwOcIJqZmZmZmVnmBLENkj4y0G0wMzMzM7PWaJD/G4x8DmIVSbsAuwDLA7OAZ4CfR8Qfga8BF+VyXcA1OWwcsBZwc77+r4jYo7DPpYCTgGWBbmAs8FfgOxExu1DuaGAb4OWqZh0QEXf03b00MzMzMzOb17BNECWNBc4FFiatZrBjRPynWVxEnAacJulrwP8i4g91ynUDm0paB9gTuJ6U+J0cEY9VFT8AODci/lRo3w+ArYBLqsruERE3Y2ZmZmZmNp8N2wQRmA18JiJek7Qz8Hnge23EvxmouwiVpHcAnwH+BewWETMlvRn4kqSVgAMj4vlc/FLgi5JeA17M+14BcK+gmZmZmZkNGsM2QYyIHuC1fPVtwO2STgUeASYBbwCnAXsASwKfjYh7CrtYn5RkHl+nih8BXcCmwB6adw7d7wD75rb8WdLfgLWBnwFfJiWvna9ibGZmZmZmDY0anKf5DWrDNkEEkPR1YApwP3Ac8Ang0Yg4QtIJwFYRMVnSp0g9jAfnuI8BfwYWlLRdRFxYve+I2LyqrqsjYnKNNlxDSiQrVgJOyLcB/D0i9s23PQIck7e/B7grbz85Is6rcx+n5PvIWz5+IMtO2q7hY2JmZmZmZlbPsE4QI+J44HhJHwJ+nDffmv9/kNSLCCkx2xxA0ruB3YHt822nSXouIv5Svf88Uc1ewGRgHUl/BE6LiIsKbdi8Oq5Be38F/Crvu2bCWSNmKjAV4P3H3xCt1mVmZmZmZlZt2CaIkhYGpkdEAI8DCwHTgWISVSuh2gzYNSJm5P18Adi4TjUH5v1+DniJdG7hj3JC+ddCW74KXBYRj5a6U2ZmZmZm1rLBupTEYDZsE0RgdeAkSW8Ar5NmGj2sWVBEnFx1/VXg8jrFFwNujogX8vXHJd0PLF5VbjXghkb11hiKiqRphavFoahmZmZmZmZ9btgmiBFxG/D+qs27Fm7/WeHy7cDtHVTzf8APJe0J9JAezz8z79IVAL+R9GrVtt/lYaVtDUU1MzMzMzPrD8M2QewPEbF11fWXSJPbNIvbt7/aZGZmZmZmtc270IA1M2qgG2BmZmZmZmaDgxNEMzMzMzMzAzzE1MzMzMzMhimPMG2fE8Rh5L5//qfj2LHjx5aq+9WXq+ffad2+m7+1VN3/enZ6x7FjRpV721hoXFfzQg3845nOH7eukv3/C4zpfAcvvTSjVN1f3fItHce+PrOnVN0br7hkqfixozt/3O559uVSdb9tiYU6jv3goZeWqnu5FZfoOPY/j/2vVN2vv/p6qfj/22eTjmMXHz+mVN3PM6vj2LWWn1Cq7nEl3iS+dt7fStU9Zmy5x230mM6/noweW+6rzWrrrdFx7Mbv2bJU3b888sfNC9WzcLn3tiOP3KVU/MszujuO7e4pt4xzT3T+WT5zdrm6R5V4qZe828zq9vLX1j88xNTMzMzMzMwA9yCamZmZmdkwNcrTmLbNPYhmZmZmZmYGOEE0MzMzMzOzzAkiIGmCpM2rtp1XdX1DSfv2YZ0/bLHc9n1Vp5mZmZmZWSMj6hxESZfTe5+fj4hP521fBj4n6X/Aifn290q6Ol/+OjAWWKiwrw/n7QArkmbRfSxf/35EXFipMyK2zpc3BSZFxDHA26vadhywdr66GHBeRBwN7AVcUPKum5mZmZmNOD4DsX0jKkEEiIjJDW67Kyd+nwfuBh4Efg18HNgAeKpQ9hLgEknvBw7Km4+PiBuqdru4pJPy5TcDt+fLkrQR8EBEPA2cBCyYb1sfWCVf7pI0jULSaWZmZmZm1h9GXILYghOAacDhwPuBH5F6FRcClqoUkrQ7qcfvbuCTpB8o9pD0FeDOiPhBLvo8cGC+vAnwvsouSAnjf/P104CLC+24Mv/f3SipNTMzMzMz6ytOEGEt4Jf09g4uBtwbES9JuhdYBNgfWBc4B0DSksDf8x/0Dg29Kf+NkbRURDwLXAscU6jvkvx/T0ScVdWW00mJYxewmKSFgVF5qOtJEXExZmZmZmbWGo8xbZsTxJTk7QYcka/vB3wzJ2evAntFxFP5/MGNcplFgNWb7PdJ4NmIOE7SjqTzFAHWl7Q+cHVV+dOBfYEeYBap5/EC4OWI+Gi9SiRNAaYATNjgy4x/++b1ipqZmZmZmTU04hJESauSeugmAA8DAXRXbo+IZyUdAHwO2BL4laRnScM/j81lHgYelrQ8qXfxnTn8HuAHEfFEVbW3Av+q2vYj0nDWSr2nSloK2BNYh/TcvBU4oNH9iYipwFSAJXc9K1p4CMzMzMzMzGoaaQniecBXgTeAV4Az6pQ7iHTO4YHAc8AywLeB8aSevoozgW+QEkCA9YDf09vTWLEn8N6qbavWqPdM4PvA/5GS1rWBsyRtGBGzGt81MzMzMzMrkseYtm1EJYgR8fPqbVLNF80KwMURUTkv8d+SbsvbixYA7omIyPv6FzCuxv5Wj4hNW2jiIsDNETEj7+/vwExSYuoE0czMzMzM+tWIShDbcCjwgzzUtIc0JPVeemcjrfg68MdCkil6l7woGlNYU7Fo34j4R+H6/qQew8r10cCJEfFKR/fCzMzMzMysDSM+QawsYg/sWtj2PGktxGax1wPXt1CupZljIuIvwFatlDUzMzMzs8ZqDxa0RkYNdAPMzMzMzMxscHCCaGZmZmZmZoCHmJqZmZmZ2TDlEabtc4I4jExYZELHseMXGFuq7p7uno5jl16g1sSvrXt6wRkdx3aNKve2sdDYcofQ4y/OLBVfxqzuzpfNXHLJBUvVvdLCnce/UeK1BvD6zO7mhRro7un8cXt99uxSdb/+RudtHzNuTKm6n3t2esex0194qVTdvFYuvmsAT0ApU/cKC5U7zsZ2dT5IaIGFFihV97iS7+tjxnb+eh0/vtz78hJLdP64v2mRcp+lLLxk57Gv/K9U1SU/Dku9N5YVJaou+/ZQ5rO0rLKP+SifnGd1eIipmZmZmZmZAe5BNDMzMzOz4codpW1zD6KZmZmZmZkBThDNzMzMzMwsc4LYgKTzqq5vKGnfPtz/D1sst31f1WlmZmZmZlbPiD4HUdJuABHx88K29wAn5qvvlXR1vvx1YCywUKHsh/N2gBVJo5wfy9e/HxEX5nKXR8TW+fKmwKSIOAZ4e1V7jgPWzlcXA86LiKOBvYALSt5dMzMzM7MRRT4JsW0jOkEENif1os5JECPirpz4fR64G3gQ+DXwcWAD4KlC2UuASyS9Hzgobz4+Im6oqmdxSSfly28Gbs+XJWkj4IGIeBo4CajMr70+sEq+3CVpGoWk08zMzMzMrK+N2ARR0k7AkkBI2iUiTivcfAIwDTgceD/wI1Kv4kLAUoV97E7q8bsb+CSpB3EPSV8B7oyIH+SizwMH5subAO+r7IKUMP43Xz8NuLjQjivz/90RMbnE3TUzMzMzM2tqxCWIklYG9gVWAz4GBHCmpPcBJ0bEo6ThnfdGxEuS7gUWAfYH1gXOyftZEvh7/oPeoaE35b8xkpaKiGeBa4FjCs24JP/fExFnVTXxdFLi2AUsJmlhYFQe6npSRFyMmZmZmZk1JY8wbduISxCBXYHrI2JfScsDioht87DSzwFHAfsB38zJ2avAXhHxVD5/cKO8n0WA1ZvU9STwbEQcJ2lH0nmKAOtLWh+4uqr86aTktQeYRep5vAB4OSI+WqsCSVOAKQCLb7YHC62xddMHwMzMzMzMrJYRlyBGxOGFq5uRHoNTK+cT5jLPSjqAlDBuCfxK0rOk4Z/H5jIPAw/nJHN/4J15n/cAP4iIJ6qqvhX4V9W2H5GGs1badqqkpYA9gXVy294KHNDg/kwFpgKstPdF0cJDYGZmZmZmVtOISxDbcBDpnMMDgeeAZYBvA+NJPX0VZwLfICWAAOsBv6e3p7FiT+C9VdtWrVHvmcD3gf8DuklDV8+StGFEzOrwvpiZmZmZjTgeYdq+EZUgStqClORVb9+1cPWYiLgcWAG4OCIqs5b+W9JteXvRAsA9ERF5X/8CxtWofvWI2LSFZi4C3BwRM/L+/g7MJCWmThDNzMzMzKzfjKgEMSKuAq5qsfihwA/yUNMe0qQx99I7G2nF14E/qvcMWNG75EXRmMKaikX7RsQ/Ctf3J/UYVq6PJk2e80qL7TYzMzMzM+vIiEoQ2xERz5PWQmxW7nrg+hbKbd5ivX8BtmqlrJmZmZmZNeAxpm0bNdANMDMzMzMzs8HBCaKZmZmZmZkBHmJqZmZmZmbDlDzGtG3Kk2/aMPCdKx7o+Mks+zLoKtEX/cobPaXqHj964A787pKP28TxXSXqHrhj96UZ3eXiX5/dcWx3yQd9lSXHl4ovo7vcS73UcTar5OO2xITOf0+cObtc3Sp5iD/3auevt1ElK+/u6fy+v/JGueNsZokX3PKL1pqMe/4p+5wPVeNHd36Qjyr5mB2y7/dLxX/zuH3LNaCEMu+NZd+Xyyj7Oh/or/Df2WLVIXGk3vnYK4M62VlrpYUH3ePoIaZmZmZmZmYGOEE0MzMzMzOzzOcgmpmZmZnZsDRSh6yX4R5EMzMzMzMzA4Z5gijpty2WmyCp6UL2khaWtFn5ls3Z3/KS1m2h3O/6qk4zMzMzM7N6hkWCKOkdki6TdJWk8yUtl29apqrccZKuzn/X5W2XA4sBnyuUO7FQ7i+FcksAO9VpwwGSDmrSzsurNr0N2Lpw+/9Jmpb/7pe0W75pqWaPgZmZmZmZzU2D/G8wGi7nIH4f+FJE/FfSu4FjKSR8FRHxDQBJSwPH1NtZRByQyy0PXCppT2BirbKSJgBfAZbN1/cGfhERr9coPrbRnYiIbxb2expwfaPyZmZmZmZmfWm4JIizI+K/ABHx/yRNrNwgaSPgoYh4slB+E+CGFva7MXAZ8CAwq/rG3MO3MnAW0E3qkV0IOF7S4xFxXKGsgHUljY2ImY0qlbQOsFBE3FvYtgNwR0Q80EK7zczMzMzM2jZcEsSZkpYr9CA+UbhtEjAdKCaIuwEfzZdXAr5UZ79TgI9HxIuS9i3eIGlZ4KH8txSwOdAFXAmcn8u8qZCYbgH8G/gY8Id6d0TSO4ATgc/Wv7tmZmZmZtbUYB3HOYgNlwRxf+D/JI0iJYNzhmpGxAnFgpK+DFwaEdPzpunAfcAqVeW+AlwDfEnSKlSdz0gaLjqxcP2O/P/EqjJIGg3sDWwF/EbSZRHxclV944Hdge2AHat6PImIs2rdcUlTSIksH977SNbeZodaxczMzMzMzJoaFgliRDwm6ciIeKhROUkfArYBPlnY/BxwI3NPFrMV8BFSb9+bgPHAO6rqfFzSG8AZNaqaHhEfzfsaDfwU+GVEPCHpW8A5knasEfc/YIuI6G50P6raMRWYCvCdKx6IVuPMzMzMzMyqDYsEMfs5MLm4ISKKSd8SpIRvh4joqbcTSUsBO+Zy3aRhoUia5xzEiHi6us5c9urC1eWAayLi/Bxzq6RDgLmSuYiYAZwu6bzczpr3w8zMzMzMWiOPMW3bcEoQG4qI58hDMZuUexb4fB/W+zjweNW2WwHSvDXzWKCv6jYzMzMzM2vHcEoQl5U0rcb2b0bETfO5LZeWCa5zPw6IiDtqbDczMzMzM+sTwyZBjIg1OoyrDN/ctcVyX25hn99vse5pwLQ69ZiZmZmZWQm1B+xZI6MGugFmZmZmZmY2ODhBNDMzMzMzM8AJopmZmZmZmWWK8NJ5w0WZdRBHlRyf3VPiZVS27u66i5YMfmXGxZc9dMvUXfY5G9PV+Q7KvNYAZnUP3HveQB5n3SUfuFElXjBl6y57/kiZ19tAKvOYQ7nHbSCPEyh/rJTRNYCVz5zd+eNe9jgbP6Zcn8H/feOkjmMXWWeTUnUvt8ISHccuu/SEUnVPu/zvHccuvdJypeqesNC4UvHdJY/z+47daki8uf7j39MHdbKzxpsXGnSPo3sQzczMzMzMhgBJX5X0Z0m3SJrn1xVJz0ialv8+mLdtmGNukrRvszqGzSymZmZmZmZmw5WklYCPAJsASwMXAesVbl8Y+EtEfKywTcBxOe5l4HpJZ0fEf+vV4x5EMzMzMzMbnjTI/9ozGfhjJE8Dz0uaWLh9IvBCVcxbgIci4oWI6AYuppBU1uIE0czMzMzMbABImiLp9sLflAbFlwaeLVx/DliscH0hYANJN0r6dU4em8XMY8QMMZX0dmBURNybr68C7AG8g5S/3w/8OCIeHLhWmpmZmZnZSBERU4Gp9W6XtB5piCjAdcyd3C1GIfmLiHtIuQ2SvgJ8Czi1Rsy/GrVp2PUgSjqtcGLmXZK+nW9aD5hUKHoOcCnwKeCTwIV5m5mZmZmZDQMa5P+aiYhbI2LTiNgU+BPwCQBJSwOjI2L6nPsqFTv/KonjA8C7JS0sqQvYEvhLozqHXQ9iROxSuSxpL2CUpMnAu4D7CkUfI/UcdhX+f6yduiStDBwTETuUbLaZmZmZmVldEXG3pDsl/RV4HdgXQNLBpJ7C1SV9F5gJvAh8KSJmSToCuCbH/Cwiqs9TnMuwSxCrfJDUJfsuYCnmThB3BLYB9gaCNMT0M/O7gWZmZmZmZq2IiCOAI6q2HZMvPgW8v0bMxaTJaVoybBNESdsAj0bETcBNkmYAoyVtAXy7RshWwF5pJliOiYjLa+xzc+A7+eqFwLnAwpJOB94J3BAR+0haFDgNWJQ0jHf7iHhB0u3A7cB7gUci4rN5v8cBGwFPAxOAvSPiXkmHA5uRejj3i4g7yj4uZmZmZmYjhQbdMvSD37BMECW9G9gL+ISkrYFNSb2I50bEVcBVedzuKNI43tHAH4CeiHimzj4XBr4HbBkRL0kaBaxIOhF0TeA14M48W9AMYOeIeEXSYaSeyjOAVYFtIuIZSRdKWhNYFlgsIjaUNBa4Jdc3GZgYEZtIWpyUcG5bo11TgCkAH977SNbexqNdzczMzMysM8MqQcwLQe4C7AB8MSJek3Qb8CCwfVXxHYCxhes7A58nJXu1rAbcEhEvAURET+5tvD0iXs3130daf2QMsK+kV4DVST2DAPcVEtB7gMWBtUiT5RARMyXdnW9fG9hc0rR8vatWo4ozH33nigeiTtvNzMzMzMyaGlYJIrAgaa2P7SJiFkBEPAc8J+lp5r6/HwIWqIpfvMG+HwMmSVogIl6XNCZv7ymUqSRoewOnR8RNkk6pcXvlsoDHgY2B8yQtSO9Mq/cDZ0fEUQD5NjMzMzMza5FHmLZvWCWIuSfv+BaLK08X2+q+n5V0EnC9pOmkIalX1Cl+IfArSQ8A/2my63OA7STdREoWHyYNUb0A2FrSjcArwG+As1ttr5mZmZmZWbuGVYLYpjULwzeLdouI+2psJyLOBM6s2rxD4fbK5UdJk9ZUx08qXD4YIK9HslNERJ7c5jrgiYgIYPeW742ZmZmZmVlJIyZBjIjTq64v36h8jeTxgH6aRXRp4PQ86c0Y4OCI6O6HeszMzMzMRhaPMW3biEkQ29XO8NOS9TwJbD4/6jIzMzMzM2tk1EA3wMzMzMzMzAYHJ4hmZmZmZmYGeIjpsDKze2gugzi2a+AGh/fEwD5mXer8vpcILW3m7KH5WgMYParcA1fmcS/7cusq8ZNe2feHMg9bT/Mijesu+biNKvGklX2PGNC6S5x4M1Q/T/rCKDq/710l31+6e4bu477IOpt0HPvyHdeXqnuVVT/VceyYMm+swEZbvKfj2EcefaFU3WPG1Fwiuw0jY8oL+STEtrkH0czMzMzMzAAniGZmZmZmZpZ5iKmZmZmZmQ1LA3lKzlDlHkQzMzMzMzMDhniCKGl5Seu2UG77+dEeMzMzMzOzoWxQDDGVdD/w36rNz0bEp6rKXR4RWxc2vQ3YCLg9334S8N5824LALRGxF7AXcEGdur8KEBE/LXcvzMzMzMxsMPEI0/YNigQReDwiJrdQbmyjGyNi38plSR8Dlm9UXtIoYCsgJP08ItqajV3SysAxEbFDO3FmZmZmZmaD0ZAZYipJwLqSGiaJBdsAlzTY34LAj4BfAb8Efipp4dINNTMzMzMzG6IGSw9iK7YA/g18DPhDo4KS1gYWiIhH8qZRks4H/hoRx0n6DvBO4NiIuDPHPA5MlXR/RBxWZ7+bA9/JVy8EzgUWlnR63t8NEbGPpEWB04BFSUn49hHxgqTbScNh3ws8EhGfzfs9jjRU9mlgArB3RNwr6XBgM1Lv+H4RcUfrD5eZmZmZ2QjnMaZtGywJ4guSpgHLkJ7Gp/L2D0XE65JGA3uThoP+RtJlEfFyrR1JWgk4BigO++yJiI8Wrp8YEa8W4yLibuCzuWex1n4XBr4HbBkRL+XhqSsC7wDWBF4D7pQ0EZgB7BwRr0g6jNSbeQawKrBNRDwj6UJJawLLAotFxIa5d/SWXN9kYGJEbCJpcVLCuW2Ndk0BpgBsteeRvPdDn6nVfDMzMzMzs6YGRYJYmYxG0s7A6Ig4tXJbTg5/CvwyIp6Q9C3gHEk7Vu9H0seB3YGvRcTzDep7tcFtr9W5aTXSpDcv5XI9adQrt1f2J+k+YCIwBthX0ivA6qSeQYD7IuKZfPkeYHFgLeDSvM+Zku7Ot68NbJ4TZ4CuOu2dCkwFOPjS+6Pe/TIzMzMzM2tmUCSITSwHXBMR5wNExK2SDgHmSoYkjSHNavrRBkleZZjoN5vUeVxEXFm17TFgkqQFcq/mmLy9OLFNpU17A6dHxE2STqlxe+WygMeBjYHzcu/lpHz7/cDZEXFUbnfNnk0zMzMzM6tNHmPatgFNECVtAXy7xvZdC1ePiYizirdHxK25XHHbLODYZnVGxDXANe22NSKezctoXC9pOuk8yCvqFL8Q+JWkB4D/NNn1OcB2km4iJYsPk4aoXgBsLelG4BXgN8DZ7bbbzMzMzMysVQOaIEbEVcBVA9mGdkTEmcCZVZt3KNxeufwoadKa6vhJhcsHA0jqAnaKiMiT21wHPBERQRoua2ZmZmZmNl8MhSGmdUXENGBaC+VaWWNxLoVz/yoO6KdZRJcGTs+T3owBDo6I7n6ox8zMzMzMrKEhnSD2p4jYdD7V8ySw+fyoy8zMzMxsJJFPQWzbqIFugJmZmZmZmQ0OThDNzMzMzMwM8BDTYWXxBWoulThf9JRYgXFmd7nlG2eViB81wOMOYoiuXDmx5GttVokXTFfJ5+z512eXii/zmin7i9zsEi+YRceXe85mzOq87rFd5Z6zUSUP0zdm9zQvVMeM2eUO0vGjO2982eeszPvy2K6B+zwZyrpLvqn3ROevl7KfJ10l36CWW2GJjmNXWfVTpeq+6w9/7Dj27dt9rFTdEyaMaV6ojtemv16q7nHjyh2nb7wxMqa88AjT9rkH0czMzMzMzAAniGZmZmZmZpZ5iKmZmZmZmQ1PHmPaNvcgmpmZmZmZGTCCEkRJb5O0euH6GEmL1So3f1tmZmZmZmY2OAy7BDEnflMlTZN0jaTl8k3rAJMkjZe0MrAZcKyklSUtIenyXO6UgWi3mZmZmZn1LQ3yf4PRsEsQgS8A/4qITYFvAZdKOhX4ar59CWBbYBNgNrAdsGYnFeXk8qyyDTYzMzMzMxsMhmOC+EHgVwARcQvwNLA78Mu87T+k+z0DuAlYP/+/jKSrB6LBZmZmZmZmg8FwnMV0wYh4pXC9JyJmSJoFVFYUnRwR2wFIeivwLuDpiNi6MNR0HpI2B76Tr14InAssLOl04J3ADRGxj6RFgdOARUnJ6PYR8YKk24HbgfcCj0TEZ/N+jwM2IiWzE4C9I+JeSYeThsIK2C8i7ij1yJiZmZmZjSAanKM4B7Xh2IP4b0mrAkgaBSwv6cukRKviKknnSDoBmAT8s9lOJS0MfA/YLiI2AX6Qb3oHsBvpHMdNJE0E3gB2zsNcrwG2yWVXBb4TEZOACZLWlLQFsFhEbAh8Blgq1zcZmJjr+ihwRJ12TZF0u6Tbb7nYo13NzMzMzKxzw7EH8ZekyWcOBnYBrgAeBVauFIiIUySdDXwJeAb4E/A2SbsBh9fZ72rALRHxUt5Hj9JPErdHxKsAku4DJgJjgH0lvQKsTuoZBLgvIp7Jl+8BFgfWAi7N+5wp6e58+9rA5pKm5euV3s+5RMRUYCrAcdc9FA0fGTMzMzMzswaGXYIYEX+TdCxpspp7I+I0AElLAuMLRbcBlgUOJiWJi5B68HYAbq6x68dIs6AuEBGvSxqTt/cUq8//7w2cHhE3STqlxu2VywIeBzYGzpO0IKlHE+B+4OyIOCq3f8FWHwMzMzMzM2OQzhM6uA27BBEgIm4Fbm1SbAXg7xHx33z9eUl/ASbX2eezkk4Crpc0HfgDqXeylguBX0l6APhPk3acA2wn6SZSsvgwaQKdC4CtJd0IvAL8Bji7yb7MzMzMzMw6NiwTxBZ9H/i+pF3o7QV8Hti/XkBEnAmcWbV5h8LtlcuPkiatqY6fVLh8MICkLmCniIg8uc11wBMREaTZV83MzMzMzOaLEZMgRsRZVdenA1PqlS+c+1dxQD/NIro0cHqeUGcMcHBEdPdDPWZmZmZmZg2NmASxXXkG0vlRz5PA5vOjLjMzMzOzEcUnIbZtOC5zYWZmZmZmZh1wgmhmZmZmZmaAh5gOKzNmd74MYk+UW0JxlDrvv5/VXa7usm0fSF2jOn/cSoQC0FPiYSvzWgOYXaLyUSpX94JjBu53sTLPN0B3icdtxqxyj1vXAP6cWOa1ClDmLabs/Z5VovGvzeppXsj6XJnPsxKhAMws8d5atu6y4/CWXXpCx7FjSh5ob9/uYx3H3n/heaXq3nz3z3cc++oyi5aqe+LE8c0LNfDss6+Wih8q5DGmbXMPopmZmZmZmQFOEM3MzMzMzCzzEFMzMzMzMxuWyg+/Hnncg2hmZmZmZmZAiQRR0vsk7d9CubdJWr2Fcou1Uq5G3GaSFm43zszMzMzMzObWdIippC7gJOAdwBjglxHxO2AcsEih3OHA9sBLhfDNgXWA8cC9hXKXR8TNhdjLgcOBrfP/1W2YBJwJPJw3nQSsC1wO7AQ8ArySy54PLFTjrrweER8p7PP3wFL56geAP+fLz0fEp2s+GGZmZmZmNmR4hGn7WjkH8YvAwxGxV04W/yjpxjpl94qIuW5TnYG/kkYDO+SrrcyNfFpEHF6IX7dWoYj4qKRtgRsi4qXcu7hZRFxYVe6zeT975vrPjoipLbSj+n6cChwTEfe2G2tmZmZmZjaYtDLE9D3AJQAR0Q1cDbyrTtllJa0saaUW9hvAjPzX1wvZbQEsU2kTsGXxRknLSfqSpN8AL0fEBsAsSb+VtJukFfu4PWZmZmZmZoNeKwniHeQES6k78APA/6tT9qPA7sAUSW+RdBawd41yCwALA7cCVwGvtdfsOY4FJtfY/iq9w0wXzteLXgf+AXw5Ik4DiIjfAF8C/lWvPZIWkPRLSddJ+qukyhDbz0q6StL/k7RGLvsFSddIukPSlLztcEnHS7pM0j8lbZS3rynpz5KukHRSftyQtJqkK3N9P+nsITIzMzMzG5mkwf03GLUyxPS3wDGSziWdg3haRDxep5ftZ8UhppJ2Bj4NjC2U+Tvwubz9ZeB3HbYd4FukIbCV+sYDFwNvBSZLepmUIC4jaR1g+4h4FfgRsHyOqbXfp+gd/lr0deCOiPiy5g58OiK2kPRxUpK5H3BxRPxG0gTgRqAyfHV2RHxI0trAt/NtJwFfiIiHJH0K+EQuezLwpYh4QtJxkjaOiBuKDcrJ5xSAj+xzFOt+uFazzczMzMzMmmuaIEZEj6RjSZO8NOvpW0jSRKCL1Es4A+ip2t/5wPmV65KOAH7WQlsXl7QqaXKcSnLWTWF4akTMICWGR5MStJvzuYqfjIiDC+V2Ku5Y0tURUasnstp6wC55H5FjAabl2+8BtsuXPy9paWA2aZKeij8Xyi6eLy8YEQ/ly3fQmyCuBfwu17FQvm0u+bzJqQBHXvVgXw/VNTMzMzOzEaSVHkSAr5J6uqZVNuSewuKENLeThphuT0oKXwUubbRTSRsDnweuy7Oa3lyn6JOkZHAKaXjoPS22u6/dT5pp9UxJxeG5lSS4kjQuAWwREVtJWg7YsVA2Cv9XEt0xkpaLiP8CHyyUvZuU3L4oaRwp2TQzMzMzM+sXrSaITUXExaThnXORNM+Yx5xcfYE0mcy7gZ9LejNwRqVnrmrfj5GGbRb3cXiN/Z5BHjoKbFQcBSppGvBURJQZg3k08GtJu5MS1U/UKfc88JqkvwB/AZ5pst+DgEsk/Q+4jdTzCnAIcLGkN4BnSY/Z6yXab2ZmZmY2ggzSE/0GsXYSxJMkvVi17e8RsW87FeZz8s4gJZM75iGsOwNfAc6WtGNEzGpnnxXVQ0fb8K8W9/88qZe0aNfC7fcWrn+sRvzhhcszgE3z1T9HxFoAkvYjJ5S5V3WjVtpmZmZmZmZWVksJYkQcTeo9a1tEnFV1/VWqkqy8fMbPaO1cxErM4flivWGpLYuIeWZalbQrheQPuDsi9ipbVx37Svow6SeOR0gzwZqZmZmZmc1XfTbEdLiJiFOBU+dTXccDx8+PuszMzMzMRorBupTEYNbKOohmZmZmZmY2AjhBNDMzMzMzM8BDTIeV8aPL9KEPXP972a7/Wd19046BMHpU53e+Z94Jf+ebBcaU+22pu6fztpcIBeC518qtFlPiKWNMmWDgje7O7/wSC5Z7u58xu6d5oTrKvlS7Sv6UObar88c9otxzVub9bUyJdgOoxPv66JKPuUbomK4y720Ao8Z0HjurxPtDX5h2+d87jt1oi/eUqnvChM4fuM13/3ypuq/52W87jn3LNts1L9TArJJfgEaXPdCHiJH5blTOyHhlmJmZmZmZWVNOEM3MzMzMzAzwEFMzMzMzMxumRuiI91Lcg2hmZmZmZmbAMEgQJS0sabM+2tfbJK3eF/syMzMzMzMbaobMEFNJVwOLAYsAjwEHAMcCuwM7AddVld8TGB0RJ9XY17eBLfLVLuC1iNgKWAcYD9zbP/fCzMzMzMzmlzIzOo9UQ6YHMSImk5LCX0XE5Ii4q15ZSZsAmwDr58vV+/puRGwaEZvmfd7fSZskrSzprE5izczMzMzMBpsh04OYLQFMlLQG8F5Sb+IcknYDPgDcCewIBLBf3v7XiPhRjX1uC1zYn402MzMzMzMbCoZagrgWsAbQA8wmJYBFZ0TEz6u2HQ8gaZGq7UhaAXg/cFgrlUvaHPhOvnohcC6wsKTTgXcCN0TEPpIWBU4DFiX10m4fES9Iuh24nZTcPhIRn837PQ7YCHgamADsHRH3Sjoc2Iy0xud+EXFHK+00MzMzMzPrxJBJECWNJiWIjwHTI+IsSbsWbt8C+LYazGUr6ZiIuDxfXgz4OfCliKhONGvFLgx8D9gyIl6SNApYEXgHsCbwGnCnpInADGDniHhF0mHANsAZwKrANhHxjKQLJa0JLAssFhEbShoL3JLrmwxMjIhNJC1OSji3rdGuKcAUgI/vfzTrb7tDs7tiZmZmZjYy+BTEtg2ZBBHYBzgduIuUqO1cvDEirgKukrRv9cQ01dskbUTqNTwkIh5tsf7VgFsi4qVcX09ORm+PiFfzfu8DJgJjgH0lvQKsTuoZBLgvIp7Jl+8BFiclvZfmfc6UdHe+fW1gc0nT8vWuWo2KiKnAVIDjrnuoaaJrZmZmZmZWz5BIECWtBKxbGJJ5Q+59q2VvSdU9bW8BTipc3xDYMSKebaMZjwGTJC0QEa9LGpO39xTKVBK0vYHTI+ImSafUuL1yWcDjwMbAeZIWBCbl2+8Hzo6IowDybWZmZmZmZv1mSCSIEfGYpB0L138OUGc46f0RsXVxg6TLq/Z3XAdteFbSScD1kqYDfwCuqFP8QuBXkh4A/tNk1+cA20m6iZQsPkwaonoBsLWkG4FXgN8AZ7fbbjMzMzOzkcojTNs3JBJEgFbOE8zentdMLHpLH7XhTODMqs07FG6vXH6UNGlNdfykwuWDASR1ATtFROTJba4Dnsj3d/e+aLeZmZmZmVkrhkyCWEuhp/DLhW0dJ4MRMWdNw8K5fxUH9NMsoksDp+dJb8YAB0dEdz/UY2ZmZmZm1tCQThD7U0RsOp/qeRLYfH7UZWZmZmY2kjRY4MDqGDXQDTAzMzMzM7PBwQmimZmZmZmZAR5iOqzM7mleZjBqefqhOkaVGDrQU7Lusm3vKbuDEso8brO6y7U76DxeJecjG9c1cGNNyg5zKdP27gF8rZW932WP0zJmlax87AC+3socZ7NKfp6UvdcD+R5RRpl2w8C+1ssep0uvtFzHsY88+kKpul+b/nrHsa8us2iput+yzXYdxz586YWl6h67+vql4mdOf6VUPEwuGT9/DOR7wlDlHkQzMzMzMzMDnCCamZmZmZlZ5iGmZmZmZmY2PHmEadvcg2hmZmZmZmZAHyeIkrZvcvs6Le5nc0kTWig3QVLTNQQlvU3S6n1VzszMzMzMbDhqO0GUdLmkq/PfRZVt+ea98vUNJF0n6SpJ50taOt/+3ap97V/Y19WSnsk3fQ5YrFBuDUk3SPqrpA3ztqtzmc8Vyv1M0so1mr0OMKlQ7vRc33OFuhepLmdmZmZmZkOXBvnfYNTROYgR0Wxe2xOA7SLiOUkbA0cCu8OcxO6UiLggIr4v6WRgQkS8nG+r5XDgM8BrwB+ArTppd6H9O+e2/Ll4X9TmHM85GT0mInYo0x4zMzMzM7PBoKMhppIWyn/j6hR5NSKey5f/DixZuSEiJkfEBYWyKwDfz5dnFbb/XtKX8uWxEfHfiHgReF1S08RW0kaSfinpl8CUOsXeJmmpZvsyMzMzMzMbCTqdxfRn+f+bgB8Da0g6v3D7pZKOAG4BPk1vAjinBxG4GVgRWB5YRtImwA8lrZ2LfjYi/l2j7leBPwHvatLGW4F/5Msfr74xnw/5BvAxYGqTfVViNge+k69eCJwLLCzpdOCdwA0RsY+kRYHTgEVJSfj2EfGCpNuB24H3Ao9ExGfzfo8DNgKeBiYAe0fEvZIOBzYj9UDvFxF3tNJOMzMzMzOzTnQ6xHTnqk3/BD4JXJ5vPykPv1wF2D8ins/lno6IzwNIejfwPqAbOA94M/B6vl6tOPZzUWA74MombZwJzMx1vQaMrypyELA9cLKksyLi5Ub7k7Qw8D1gy4h4SdIoUoL7DmBN0vDXOyVNBGYAO0fEK5IOA7YBzgBWBbaJiGckXShpTWBZYLGI2FDSWFJSjaTJwMSI2ETS4qSEc9sa7ZpC7iHdft+jWW9bj3Y1MzMzMwNo8wwyo8MEUdL4HLsg8BIQETG76hy+ccD+wIJKNwg4rnJjRPw/4P9Jelsu95Z802PAr4AnC/t6OidT04E3IqKnwfmCX5H0IjCG1Bv3ICnxLLb/m8DtEXGXpAOBXxWGs9azGnBLRLyU219pw+0R8Wre733AxFz3vpJeAVYn9QwC3BcRlYl47gEWB9YCLs37nCnp7nz72sDmkqbl6121GhURU8k9oN+75qFoch/MzMzMzMzq6iRBnEZK4GYCrwAn1yn3U2D3iLgf0nmLwLWSro+I1/K20cCZwJdywoikNYBTgQ3p7U08mDRMdTywX4O2HQssA/QAs0kJ5b9JPY7k/S9KSmiPI124XdKJwMJN7vdjwCRJC0TE65LG5O09hTKVBG1v4PSIuEnSKTVur1wW8DiwMXCepAXpnUX1fuDsiDgqt3vBJu0zMzMzMzMrpe0EMSKOqd5WpzcvmDt5qmVs/v+hwraHSJPVjCUPEY2I/wG7tNC2R4BHGrUv9wDOdR8i4ubqcjX2/aykk4DrJU0nzaZ6RZ3iF5J6JR8A/tOk2ecA20m6iZQsPkwaonoBsLWkG0mJ+G+As5vsy8zMzMzMMg3axSQGr04nqWnFHsAPCgveCzis0nsIEBGv5XP0zpdUSSZHAd+NiOn92LaORMSZpB7Poh0Kt1cuP0qatKY6flLh8sEAkrqAnSIicu/mdcATERHkpUHMzMzMzMzmhz5JECNi6/z/5MK2+4CPtBB7KfkcvDbrrNS1awtlz2pxn3PKFc79qzign2YRXRo4PU96MwY4OCJqTdRjZmZmZmbWr/qzB3FIi4hN51M9TwKbz4+6zMzMzMxGEs9i2j4niGZmZmZmZkOApK8CnyWtGPGNiLi+cNvRpLXVIc3nMj4i1pZ0KGnt95eBxyOi4dwuThDNzMzMzMwGOUkrkU7h24R0mtpFwHqV2yPikELZA0irMEBahu8LEXFXK/U4QRxGumPglkEsU3XZrv+eZnPlNlD2ISvb9lEldtBTsvFl6g5G7pKbQ3WoStnXendP5zso81ob6kq9Nw7gzHuzSzzfANJAvkeUfW/so2Z0YFZ3520vc4xC+eN0wkLjOo4dM6bmUs8tGzeu8/iJE8eXqnvWrM6njRi7+vql6p557y2l4pfYYHLzQjbYTAb+mCezfFrS85ImRsSLxUKSFga2iogt86aJwAutVjKqjxprZmZmZmZm/Wdp4NnC9eeAxWqU+zJpibwKAWdImibpY80qcQ+imZmZmZnZAJA0BZhS2DQ1IqYWbl8POC5fvY65E8LFmDthrPgEsFnlSkR8Me9rMeBaSdfmteFrcoJoZmZmZmbD0mA/yyEng1Mb3H4rsCmApDWBo4DfSVoaGF29dryktYD7ImJWYdvoiJgNvALMoMlYfCeIZmZmZmZmg1xE3C3pTkl/BV4H9gWQdDBwakQ8RUom/1IVeqqkFUi5348j4uVG9fRbgihp+4i4oJ/2vWlETGsz5iMRcVEL5fqt3WZmZmZmZp2KiCOAI6q2HVO4/IMaMTu3U0epSWokXS7p6vx3UWVbvnmvQrn1Jf1FUhTKh6SbJG3YYP//yidTTpN0l6QD802HNIiplH8u/39GvulrVeWuLbTl6lrtNjMzMzMzG0lK9yBGRNM5ciPiFklbAqdFxCcAJJ0DfLFJF+fjEbF1Lj8ZeG8LdW0qaQHgnojYtEHRnmLbCwliWyStDBwTETt0Em9mZmZmZv1jIJcMGqpKL3MhaaH8V3cBHEnbAhcAm1R67EjjY8+TtH3ZNtSwN3CNpK9UtaOlqV3NzMzMzMxGor44B/Fn+f+bgB8Da0g6v3KjpKWAF4HD6+1A0tIR8Uyd267OF8cBv27UEEmjSENEuyLiS5IOk3QEcCSk3sXmd4dRuXfz6oj4WfWNkjYHvpOvXgicCyws6XTgncANEbGPpEWB04BFSYn49hHxgqTbgdtJvaGPRMRn836PAzYCngYmAHtHxL2SDidNUytgv4i4o6o9c6bG3W7fo1j3w+7INDMzMzOzzvTFENPqkx7/CXwSqAzZXBhYtXD7BkAXcGNh21PAPAliZXgpgKSNgLH5avXMPBUTgf9GxB9z/BGS1oiIbkmPtnJ/SENPP1nrBkkLA98DtoyIl3JCuiLwDmBN4DXgTkkTSVPI7hwRr0g6DNgGOIP0WGwTEc9IujBPV7sssFhEbChpLHBLrm8yMDEiNpG0OCnh3LbqMZozNe5RVz/YcMpaMzMzM7ORZLAvczEYlU4QJY3P+1kQeAmIiJit/GxExMPAw5LeCuwHvJ/UGzYD+EFEPNRg328Ffp6vLkPq3Xsy37ZuRNxeLB8RzwN/lLQScDSwdCqq14Fjq3Y/StIJbd7d1YBbKgtLRkRPvp+3R8SruV33kRLVMcC+kl4BVif1DEJal6SSDN8DLA6sBVya9zlT0t359rWBzSVNy9e72myvmZmZmZlZy8omiNOAXwEzSQsvntyg7OnAN4ADSQni2qQetUn1AnLyODn31J2X27t9XuixkV8D+0bE3TBnmOtFkj4YEa/lMjsC4wsxrzfZJ8BjwCRJC0TE65LG5O09xWbn//cGTo+ImySdUuP2ymUBjwMbk87JXJDex+R+4OyIOCrfjwVbaKOZmZmZmVlHSiWIxTU3KlSjH1e9G++IiBl5251ASFJE1B0aKWld4GDgN8AsUg/h90i9dvXixpES1opKUjjn/uaFJNsSEc9KOgm4XtJ04A/AFXWKXwj8StIDwH+a7PocYDtJN5GSxYdJPawXAFtLupF0f34DnN1uu83MzMzMRiKPMG1fX0xS01REhKRDSD1klaROwKFNksNtgXWAr0bEs3nbrcBupPP+TqsTujvw47zcRaWX7ogmS2q0el/OBM6s2rxD4fbK5UdJk9ZUx08qXD4YQFIXsFN+nBYFrgOeyI/N7mXbbGZmZmZm1oo+TxArE8tUr48YEdcA17S5r4uBi6u2PUs6v7BR3D+AD7dTVyG2uDbitKqbD6ieRbSPLA2cnofSjgEOjojufqjHzMzMzMysrvnSgzhUtbgsRl/U8ySw+fyoy8zMzMxsxPAY07aNGugGmJmZmZmZ2eDgHsRhpP7ZnINb2XYP5P0uW3dXiZ9oFAP3k1jPgL7WylU+kOshdY0qV3n3AD7wo4bwQlJljrOyPz2XqTtKvtbLvFykcu9vQ/XzCKC7RNt7BvCOd43SgD7u3WUeOMqdVfPGG53HP/vsq6XqHj2684N8pbe9iQfuvL/j+CU2mNy8UAPP3XR1qXj4aMl4G6ycIJqZmdlchnKCN1L5ORt6yiSH1jp5jGnbPMTUzMzMzMzMACeIZmZmZmZmlnmIqZmZmZmZDUtD+BT6AeMeRDMzMzMzMwOcIJqZmZmZmVk25BNESStLOquP93lCG2V3lbR7X9ZvZmZmZmY2EHwOYg0RceBAt8HMzMzMzMrxKYjtG/I9iBVKpkraTdKPJE2TdLOkb+TbJ0m6UdINkr6Wt90s6bu57A2SVqlsb1DPvnk/N0raNG9+t6SLJN0j6bO53LqSrsrlfp23bSrpdEl/knS3pH3y9omSzpN0naSfSro9b19I0pmSrpV0saTF++nhMzMzMzMzGz4JInACcAfQAzwTEZsCGwIbSXo38BngsIjYGPhpjlka+GMueyjwnUYVSPoAsB7wgYjYCPhzvmmJiPgIsAmwf972CLAVsDGwkqTl8/aVgE8B6wKVoalfB86JiM2A7wFL5u0HA2dHxAeBnwBfq9GmKZJul3T77Zf06UhbMzMzMzMbYYZLgjgJeE9E/Bx4L3AxQET0ANcBqwFHAx+UdCzwphz3bET8PV++BVixST3rkRK5nsL+Aa7P158hJagA6wMnkxK+xYGF8/a/RkR3RLwBvJy3rQVcmvfxBPBM3r42cICkacC38n7mEhFTI2LdiFh33Q/v0KT5ZmZmZmYjiAb53yA0XBLEm4FrJZ0E/BPYGkDSKFIP3v8DXouIbwO/Bn6Y45aQ9JZ8+cPA35vUcz+pV5C8/zH5Yk+hTOT/DwP2I/VMRo3bi5cfz+1E0urAcoX6vhURm+Yey281aZ+ZmZmZmVnHhs0kNRHxPUlHAO8Cxkq6gZS4nRYR90k6VNJWwGzgpBz2PLCPpDWB6cCuTeq4UNLG+RzF6cAhDYqfB/yNlJz+p0nzvwucIelAUk/mE3n794BTJR2Z6/sm8I8m+zIzMzMzM+uIIqJ5qWFK0s0RMWkQtGNMRMzKl9cBDomIj7W7nyOvenBEPpmzuofu3R4/pvOxBT1D924PqBmzepoX6iddo8qNJeku8aSPG11uwMhQPs66Stz17pIvlzJ1j+kq93op8x4xgr8alNJT8oEbyOes7OvtjKsf6ji2q2Tdb7zR3XHsuHFdpeoeXeK99YE77y9V9xIrLNe8UAPP3XR1qfjX7/zRIB0gObfXZzGo39EWGDP4BpoOmx7EvibpvfT2NFZsHhGdvwvVt5mkb5GGnL4B7NEPdZiZmZmZmTU0ohPERr2HefKaTedTO64ErpwfdZmZmZmZmdUzohNEMzMzMzMbvjToBnAOfsNlFlMzMzMzMzMryQmimZmZmZmZJRHhvxHyB0wZiNiBjnfdQy/edQ+9eNc99OJd99CLd91DL36k1u2/of3nHsSRZcoAxQ50vOseevGue+jFu+6hF++6h1686x568SO1bhvCnCCamZmZmZkZ4ATRzMzMzMzMMieII8vUAYod6HjXPfTiXffQi3fdQy/edQ+9eNc99OJHat02hCmfhGpmZmZmZmYjnHsQzczMzMzMDHCCaGZmZmZmZpkTRDMzMzOzKpLeL+lTSsYNdHtaJWktSRdJmiZpvKRPDnSbbGhxgmhNSdpyfsdKequkt3Za71AnaRlJK8zv2MGmzGtvfpE0WtLa8zu2L5Q9zgbqOJW0bf5/m/ldtw0fknYZwLq/Px/qKH2c9MUxXiZZGchER9KPgO2ArwNjgN+0GT+QSdoPgF2AiIgZwBdaDZQ0UdIhkk6UNE7SO/utlTZoOUEcIUp+0T64al9vmg+x6+S/uUhaq426kTS5nfJ9rZP6JR0IvAt43/yMLeyjzxLMTl53Vb/SHly3YB/V3QdJ2lhg6wGI7Yu2lz3O+uQ47cD++f99C3V2SZrQKEjSZpJ2rPp7Z+VyLrNvX8e2StLiTW4v9YW/vxLrwfxDjiRVXV+pcHXXkvtumGBWHweSti9cfW+LdZR5zjo6Tqr0xTHecbJSMrZskvaOiDgIeDUiZgJLt1M3A9t2IuIFoDIT5SJthJ4G3AG8LyLeAP6vnXpteHCCOHK0nKhJ2lrS7ZKOrWyqKnJGP8WeJulSSZeS3ki/IOmyfL3ixHrxVfv6gqS3Ad9opXyN+LdJmiDptA7jO6pf0nhgpd6r+pOkK/Pfvv0VW9hHXySYbSV4kv5Qtemy4s39WXfWUZIm6WRJlwHnAhtXXqf5cX8mv3af6evYsm0ve5z11XEq6Zz8/1lttH07SVfly1cCXfkxWwW4Cbhc0kcb7KKL1BOwa/5/DPBR4C30vl7qfREvE4uk70m6Kr8/Vo7L3SVdK+nOXKzZY1H2C39fJAyVuL76IefaTmNbjL+m6nqxF6jp+0vJBLP6ONinWX01tP2clT1O+vKzuKJEslIqlnJJ2mxJywMhaRGg7SGmA9j26yT9AFhS0reBf7QRu2BEXAbMztcXbiPWhonRA90A6x+StgaOBq7Jv4DVStQ+WCf8AGBTYDelnqTqtVAafah2HBsRrQz3aTVheD/py1ZbCUbB50i/oi3bYXyn9X8ZOBNYIF9fKCJa/XW+TGwxwfwbOcEEFso3XxoRJ9WJ+0NEfKaw6TJ6X1ut3P/qX2WLMQ3X4SlTt6STgbcXrl8aEdvk+70R6RfUdSKi5q/GEVHzy15EfFzSVRHxocqXtL6MLdv2ssdZ2XhJ65CS2rUlfQtYR9L+EfF9SXsDbwK+FxGv1Kj7QuDCwr4WAhYF9gP2BO4CLgbOr9P2q3PcuhHx25zkHEh63XygUdvLxOb4b+X4UyJir3z526Tha5Vf6GvGS9oOqMTM+cJPer/9A/CGpBMjoub9Lhuf48oca1+IiN8Urh8WEUe0EtsH8dW3t/z+kl3D3J+Vv6H197dOP39KPWd9cJz05WcxlEtWysQCKUmT1EmSthfwS+CdwDmk470dA9b2iDhC0ubAf4H7I+K7bVT7dH79dUl6P/B6G7E2TDhBHL7KJHk9ETFd0i2kN8jqJKnRh2qZWCR9Bbg+Iu6vU6TpB7rS+RIvRsTrVT/+tiT/YrxaRDxY/etxi/Ed1S/pG8ASwPXA9sBt8yO2oNMEs+MEr06ZZZWGbvVrclk2SQOQtCJwDPAs8K2IeLWVusvG9kGCWeo4Kxn/JHBj/gP4C+mX+s8BywE3AycBX6pT97fyxSuBV4DNScnyHRHRLam7UduzGyS9mfQ++WwL5fsqdg6l4WItLUTcB1/4S8VnZY7zzzF3z90mbcSWja++fWVJ36H1BKdMgll9+3tzste07rLPWdnjpC8+iwv3peNkpWSiAyWStHzfP9RmfcX4AWu7pLcDT+S/yufNE9Ha4udTSKMCpgOfoORQbBuanCAOX6WSvEKZ7iZl+zIW0i90G+XhM1+LiKfbCZb0VWAr0heKyrbir6FPRcSVTXbzbeBX7dTbR/VXhnP00Ps4tqpMbNkEs0yCV29/s1uML1V3mSQt+ylwEOm1fiBwROPifRZbtu2ljrMy8RHxX9IXJgAkrUr6hf5DwJ4R8bykrzXYxceB7wMbknpSFie9Xrpo/T3nOuDnwB7AF6ub2I+xAN+UtBvwatOSBX3whb9sYl3mWOu4J62P4oteAK7O+9ykSVkon2AW3VX50U0tDK0t+ZyVPU7KvkcU70fHyUrJRKdUkibp98z9OM0A/g78LJ+TOGjbDpwCLElKKicBDwFLSzq4MhqiQb2vAoe2UZcNQz4Hcfgqk6iNzh8K65O+xLbzwVAmFuC/EfF50pCr30taps34YqJU3NZd+KtL0t+AdxeTOPWeL3SlpOP7q/6I+D7pg2AU854301CZ2EIbocMEs7o5eX+zmxWs4+mIODMi6p6v2od1/xT4HvAz2h8+BDAmIv4REfeQvnjVak9/xEK5tpc9zkrFK51neYOkPYE3gNWAiRHxfC7S6Dh9gdTLqFxuDPD/gM0kLUrz4Y5XAY8Av4iIpwrlJekDwGL9EZsLfYr0Q8DKEXF6jbY2es4/DjxK+sL/InN/4W8W2xfx1do51mr2pDXroe/D+KKXIuKvEfGXDmKhN8Fs+CU7W1TSevlv/Q7qKvOclTpOKP8eUXQK8HvSj68Xkd6zblNrk7iViS0maRcA90hasY2RQU8Bf8p1X0Ma/TAqt6EVA9n2V4FJ+TlcC3iJNDT6Oy3Ue5ukhyXdLOlxSX+RdK6klVus24YB9yAOX9WJWjsfTicA04BrI+LxyvuR0sQzawONprwuEztHRNyRexHOkLQFaTKPBUi/4DWK+0X+ZfZbpDdlIuLMVurMZdeWdKikD0bEtXlby+fxla0f+AW9H0bQ3q/UHcfm87/2oTfBnNhGvdWertxnSTWHCVZZPg+7gtTmViZn6au6x0TEP3L5TpK0MUrnogVpwhiUzhPqVpqEptGX5zKxfdH2jo+zPoi/C9gd2DaXXZB03styuYdxTCvVk37MEOmL2JmkyRT2bxgUsYXSJF0nS3oQuBb4N+lcow1I5xr1eWw2kd4h3JCe4x5gVn7O39UgtvKF/yPM+4W/kgg0Uja+WrvHWlFbPWkl47sK7y8Ad3dQX9FLEfHXXHezspeSHu+K37VZV188Zx0dJ3OCS75HZK8C20bELEkLkkbo7EAaItss0S4TCyV60oDVI2K/fPlXkq6IiK0kTWuh3oFu+9IRMQsgIl6TtGJEvCyplR90biOdB/5vSauTRkqcBfyEBhNx2fDiBHH46jhRi4grgCsKm5S3H9Ss0jKx2U2Ffd0j6SLgsxHx8RbjiYiHJC1W+PLdrqOBU0lf/tpWpv78Rv4YvR/8O82P2KzTBLNUghcRqzW4uVkbyiaXZZO0/yMNy32G/IWrjddqmdiybS97nJWNj8JfN6lH5GzgOEl3A3c2iP0badKEj5ASzNMj4n9AOz/kPJmTmh9GRGVmwOrZdPsj9hdAZZbJ/SOiMtvzh1ttOyW/8JeIL3OsraQ0jL0S2+77csfxEdFoGGkr73EdJ5gR0WiYXjsjNTp5zsoeJ6U/iwvKJCtlYqFckragpJUj4tH8w9BSeXurr7+BbPtfJP2c9CPFB0gjH6C1191qEfHv3O57Ja0XEd9QmsjORggniMNUHyRqRe2eWN1xbOSZ/gpaHcpR7c/A8nRwnkhEhKQHlKYz7yTBLFv/1DycZ2xEtJtslYntKMEsmeA10/D10wd1l0rS8lDkZue09nls1nHbyx5nfXCcKv99iDQxzcyIuEzpnKrlaTCFfuE9bIs266zezytKs6bO19gcf6HaX6S97Bf+UvElj7UpVdeLQ0NbOU7LxtezV7MCfZBg1ttvK8MMO37Oyh4nffhZDOWSlTKxUC5J+xrwy5ycjQYOlDQauKTFuges7RFxkNJQ1rWAW4FzJI0Cdm6h3pckfbbQ7jlD6Vtstw0DitbOlbUhTtLkFoYkDDvFoaJtxq1COv/gpxGx6wDUvySwSEQ8PD9jc3wlwXyik/iqfbX9upO0ZTSfSKhf6rb5Q9K7gAeBdfOmxzt5vUn6ckT8sk8bZ20rc6xJOiEiOjn/t6N4SbtEREfr29bY1xqVYd4tlv9+RLTa01uapKVJa9o9Or/qbNCWSrLyOGkodpASoKf6OfZY0tDuSrKzTETsLOnqFpP0Ugay7fl9dnF6Owj+3GKbFyUtv7MW8BjpXPengM0iopPzfm0IcoJoc5G0Gi2cr1jrA7ZMbI5fhzQDaLP47zUrI+mj0WBNr/7WSf2SJkXEzZI+AjwHrNrqF5kysTX2VTbB7CjBk7QH6RydCyKi3hqd/VJ3h3UN2LFSRtnjrC+P07y/iRHxYitla8SeGRE7tlH+bcD7qjb/m3RuV2USjufyCIw+i+0PZV/rAx0/P0maEHmWX0nXFt9fJK0VEY2GNFfvq+UEM/fYbEWadfSZGnXPtb5jnX10nORJ2hB4c0ScXeO2d0bEv+rE9ekxnvfZUbJSNjbHd5Sk5cdvv6q62/psGsC2nwFMAO7Jm6JGr7BZXR5iOgyV/PLZTZpVsBNlYiHNENbpzHLV9qewPpSkiaQ3yJdaCZZ0YURsN5/rP1HSVsDewGE5bhXS+SY9wKENeiPLxNZMMIGOEkTS+knFWWDfFBFPthC3YUT8RMk+pOFfDwBvi4hVGwUWksu56m4SUzZJG7BjpWTbyx5nfXmcQpr4oKUkT72Lh1d+2aycH1Y5L02k46zeELxRpITuINISISJ9Dn6bdN6xqD2jbNnYYtuXIf0aD2kCklVIyxAFcF9ENB32mFUfZ8u20ivRj/GtHufzJGntaide0s7AHpLujYgvMu8wuRPpXfi+3j7mJJikNeFOK9zWKME8kjQB0xck7VCj7ur1HWtZFXgzaTbT6nbVTPIknUxaDkPpqnYlnbP2MeAtEbE8aa3ResdJnx7jtZIV0mkY/Rpb8CTp/VbA+3OS1spr/efALrnutntTBrjtb4mIDdqsC4A8fH530synkN5TN+xkXzZ0OUEcnjr+8hkRD5KGfs3X2Bw/1/poFZIWTzfHC43iJU0hfQAG8KqkS0mzfl1Mmto5JH03Ii6rE78V6Uu3gPcorXX1FCnxOJKUaB0REa/1R/2kWRB/DbynskvSr5cHkNZeOpf6E+eUiYUSCaakrUkT+1yTz3up/hJ0Bs2/gG2c2wnpuT5Z0rbRwmL1WSfJZakkbSCPFcod46WOsz44Tou9EwLepd713or1zNM7EVWLh1fVPTsiXm7S9vuA+yTtGhGnSeqKtJ7coc16hcrEFtsu6bpiApuvb9YsPvdmfB+4PSL2ZN7j7DQanJvWB/EdH+eSliItxXJJ/oKrqttPjoh9GtRdJv4LpPUOv5B7gau/6DdbFqVMgrlhRHxQ0ieA97ZTd5kkr9ZjIekgYM8c07Dussd4DR0nKyVjyyZpT7TTu1zDQLb9TklLRMRzHVT9JeC90cJajzZ8OUEchsp++VSaAfF+4MKIaGtNvTKxdfa3EClJOQS4vVHZiJgKTK2xjytJJ+qL1KtXL0G7h7TWFMDl+f9XSV8Arie9Of8A2K2f6r8mIj5dSIg2Ik1t/fWIeEONp1QvEwvlEswDgE2B3SStQPtfwPYB1iP9ml7U0i+2nSaXfZCkDdix0hdtr2pLy8dZH8RX907c2G59VXUvCJxOWtj5jhbKn0nvTL1T8+uv1bo6js3xWxUub0F6HFrtmfgOaYr5j+Rkr63jrA/iyxznPyDNUvt5SbWeozWb1F0mfnakWSDvJr1GVq66vdnjXybBrHzB/jdpBsoVW627bJKn3llfAW4p1NXReUUl3yPKJCtlYqFckvYPSd8lJWUBcyYXa9VAtv19wAOS7svX2+kFfNDJoTlBHKZKJmoTSF+4tpV0MPCliHh8PsTOoTRT2MeArwDfjoiWPpAkfRG4IiL+U9gclV4/SXVnD8vtnKetklaLiD3y5erZ9Pqsfub9AO/Ol1v5YC8TC+USzJ6ImC7pFlLP3bJ12lbPbNJ7UdszpPVBcln2B40BO1b64seYTo+zMvENeid2JP1if0OLdY8CtgP2IPVwN00Os2UjYkdJ3wSuyq/dFkNLxUIanvo5ScsBu0TEVWpjBxHxvNK6f9uQljmpzKT6G1p4zZeML3OcLxNp5tY3SOdTtZuklImvlB1LWt+t0VqTtZRJMCtDjhcljc44op2KSyZ5t5Bm4fwZaQbUZ9upu9CGUu8RWZlkpUwslEvSKsOKJ1Xqpr2Zpwes7RFRfb50O16TdD3wV3oTY5+/OMI4QRy+ynz5nB0RtwG35V+KfybpsBY/GMrEVr70jiXNbvgEsFVVstXMN4DJkh4HvhkRxSQJmnywSnqINIX60ZHXAQJmFYp092P9kyX9kTQUCdI6VLOAdSX9jXQOVH/EFtvVSYLZUyjT3aTsvBVH/Dh/+dqHNASuXttq6Ti5zMr+oDFgx0qZtpc9zvrgOK3e31dIvTSfb6HsVbnudUjnZW2Zk85WvScfnz+JiLPytlZfs2ViIa2jth1pLdqvtRlfXa6HNIQd0rHe7BgoG1/mOK/EvkhKWKp70vozPpQmetkM+Ckp2WlHmQTzaUkfJT3nc84tlbQiaR3DCU3iO07yIuL6XPf1pOVk5inSKL4vj/EyyUrJRAdKJGkR0VZCXyN+wNquNBPpNqTXWSV4nhFOdXhmaGv6pdGGrtkRcVtEHAZ8EfippHWbBWVzvihEmnp+Z+C7kpbo51gi4kMRsXlELEqa6OWnSpM7tOqJSLMa3gIcn7fNkrSs0kK3zdYPehj4IfBzSe/N28YVbh/bj/X/lfQF+a58vTKk9QTSsLZj68SVjYXaCeb1pARzPI3fK0ZLmkA6f/OnwNNN6ppHpPOK1spXlXsG35q/pLylQdyPgR+TksuaRZpUXeY4gQE8VijR9rLHWdl4STtK+pykQ5SGYI+PiJ0jotkPMETEFpHWplsU+BbwC6Xz41p1F/BW0nH51bztoQbl+yoW0vvHUqTnfkze1uqPG5K0GLA58P+A7oi4JP/NoPlrvWx8meO8cl+XB76c629HmfhDScNTX4qIOW2WdGz+saFZklZMMM+md+KOVuxLerx+Hb2T3ED64v5l0vt2/Yojrgf+Q3ovrlmkSf3FH/keB6YDd+X31Yavuz74LJ5D0qKSPitpSuVvfsRCStIiYvGI2CD/tdyDJ+nLkv4m6Z+SHpZ0czt1D2TbgQuAt5F+HFgDeHcb9V5PGp3yZOHPRhj3IA5fc335VDrR/ixJO7YwXGGu87Yi4gVJR5LOxTihH2PnEhFX5uFQP5E0PmpM1d0g9jxJK0n6OOmcifNIv0J/tXEkERH/UppU4Hf5S+B1ko7Kt0/rx/r3j7QY7kkwZ0rsh4FWPhTKxEJvgnlB5S6QEszT8+VDGsSeQHpcro2Ixysj5pTWcFqb9IW6FTfkL6BExMnAya0ERcSfcw9Urra15LJSvrCfdo8TGNhjpWzbK7FXSrqG9AWwreOsRPwY0vC7LtJxsYDypC9t1NtNmvTlMtL5gBMi4twWQmdFWnz6REmHKc3g+5WmUeVjAf4bEUfkRO0nkr5M42Or6EjSemi3R8SphePsVNLMqG/r5/gyx/lN+b1peeAz5KQlJxwr5O2NdByfe+Q3LWyqvD8eVDNgXpUE84KIeLrG/a6bYEZa1P6bhU09eXs7i853lOTl2xcnTZJ2baHHe7826ia3t+PP4uwC0jnsa5F6I9vpnCgTW7YnbTfS6RbfBn5ESvjbMZBt74mIIyV9LyK+Jem8Nur9JWko9WJ507+B7VuNt2EiIvw3DP+Ab9XY9n7gwIFuWwf3pQtYocWy3ytcFnBxm3VdVbj8VuCn+fLOwE79XX8hdklglfkVC6yX//9wfp3sUuL5uq7k8z25g5gppC9qbdU9lI+Tvm57O8dZX8cDnyBN4LRIibpX6iBuHDCmwzrbjgU+W7i8DrBWicf7upKvn/kWT/pivBWwVDGWNDnW9sD2/Rlfta81BvJxa7Ouy0ijUS4dDO9JnR7jpAR1zucjcN78iM3lp5EmaDqPNDroR23EXp3/Pyb/f8P8ut990Pbz82fij0i92P9sI/bPlXbn5/x3A/m689/A/A14A/w3Mv5I5wm1G7NMmS+seR+Ltll+9arrX52f9eeYtwJvHcDnquPkNMe3neD1YdsHrO7h8lf2Mew0Pn+J+dJA3/+h8jdQz1NfxAMnlKy7o3hK/PBV2EfbCSapJ+b78/s1Uqh/CdKMmJ3Gl/osLpmsdByb48skp7vmz8MDSDOb/2l+3e8+aPsipB+xVs3JZcvHK3Bl/v9k0o8zd/X1a9J/g/9P+UVgw5ikLaPFqZlVfvHwevtta2FkSQcCfwMmRsSf2qmrsI+dIuKMTmJzfFtD3iTtRe+QjIpLSb1yEWm4x/ER8fUm+/k0KeDsqu01F2SW9EHSLJ71Dmbl+r/Y4v1o+fVSVlXbxbz3oa22z0/5+V641m2R1/BTnfXZysT2BUnbRMSlhes/i4jd8+Uro/5C830SX6LdpY4xSZtQZzhiRJyZy+wbESfViF2eNJFO0WOk53Hx6v10QtLiEfF8p/Ft1DMBWDUi7mpaeIiT9OWI+GUeEvq+yueQ0rnVYyLilTb2tUs7n32SfhQRe0r6FelHt0rdk4DFi8dQC/tagvSD48Mtlt82Ii7OQ+5vJ/3o2Nbndt5PX3wWL0Jat3UF0myuF0bE1f0dm+PPB3YinYf/O9L5oO3OZNvRsTnQbc/1T6xcj9YnMVsHeIT0XfAwUmLabB4DG2Z8DuLIcDBVUzNLelNE1DrxuIfemTo3Bl6md+KTpiT9G/hX3k/kfe1MG7NM5g/ulUgfSpL0J9KXsAAurfXlrY5PkBZv7tQfgY+3Uf4WYIGqbesBr5DOmzmS3klg5iLpNNIvlZAfK0lfIH3p3SZvr7cg883AffQmWb8gnTtReQ7a1fLrRWldsOqZ2h4kfWFu5Utzx20vm1z2wY8ht5F+oT0UOIo0FOjIqjL11mcrE9sXCea+pMQKSesz9+RJrRyrZeMbkrRmRNxd46aOj7Gsi94JT+rZht515opG1YgdTTrH7Oek+30Qaa24eeTzmCcx9+u08hqtJNRnUWPh8zKJbWEfm0XEdZK+DlxCen9s6b297OtN0uiImC1pA+C77fxY2AfxO0r6A4XnTtIawKnAq5J+GA3OXa1OMIHT8vZWEsx3Kc1Q/BiwSo7blrRkxP2S1o2I6uO+WPc8SR5pIrVW7E86/3Bt0qRjlR85ziJNlnRQRExrtIO++iyOiJdzsjKT9uci6Dg224X0/nQSKUlr+Uc3Se8kLRq/WL5OOz9WDnDbTyL9oHVvpTnAjq3ERu+SQZdRf91mG+acIA5Tkh4F/pGv1vqieQY1ko2IeAB4IO9jNPBsRFwqaSxppsGXm1T9QK3eA0ntJCpfJn3JqnwRXCgitmgWlD94v0ZvwrC0pOIvtJUvY9vUiS8mDAJWkrRLdbl6CUNE3Jr3syAwIyJ68heRf9Jk5ruImKeeWk2sE/uapHPpvd9rAVPp/SJaSZ5q3u/c5kfp4PVC75fmg4Bjcl1dtPiluWTbyybG3aRfdzsSETcDSNot0pTyT0ea/a1fY7NSCWaFpJWB/yNNwz+nea02opN4SacDy9H7eg7gHNJx/+aIWJr0Y8g87yNljrEcf22N9oyPNIvnnE11Yp8AfluIGxNpfbyZhSRt1wZ1H9qsffXqZu7Edi/SkLHqsvUS24pvAteRzlP9A7SVMJR9vV1Jev+YM6GP0jqW3yD9kHR0k8+WMvEiDRU8nd4fD/Yhvd7+Sfqho9HkRqUSzFzXD+idKOdzwNci4t+SmvUmlUnyJOn9QGXUiUgT1BwA3EP6AbRebEVHn8U1GnISHSYrZWKhdJJ2JnB4rrvtH1sHuO0bR8RazYvNS9JnSK+TOcvZRHszqNow4ARx+HogIrYFkHRdIVG6PCJqfbmYozBE7G5guqQxwK9JQxyuaFJvqTHLSgsDL0Ga1nt70heTlkTExaQP0+p9rgA8FWn2wUaqE4bjWq27UNfOpC8xL+Vf6tuJ/QpwfUTcX6dI3cc2IuZZ50ppBrRF8hfbZjp6vUTEfcB9knaNiNOUh+W2+qW5TNvLJsYR8aCkpyJielXdCwEL1+lhr27n3aRp8K8ElpV0Wa3709exfZBgLp97RNYizV67jNKMu632/nUcHxE7V2+T9DVSAnNAZVO9+DLHWI19LUZ6X9u22MQWw49SmgG0WL6t9z9JX4yIXzeLLya2kj6aj7VxEVF8v2r22EtpaGOl17DlhKEPXm9SWoLlVnoXmt8LGE96r/8hKYnrj/jVgbdFxClKvgNsBuyWf2DoqRM3p246TzAnATdFxH9y3VcBa0fvGrvNll0qk+StBHwd+DS9Swi9o/AjS7OKO/4srqHjZKVkbNkk7ZmIOL/TuhnYtv+rxo9frfoOsGlEtLzupg0/ThCHr7m+tNToNWvli8w/SV+cfgKcFBHNksO5SPop6UNKtL4GT+UDs4fexZHbqfMbEVGd2H2F9Mt/w/XKcsIwPSKeqtrnF4CLIk1Z3syXSb8Ujyb98li9sHCjx/1AYCOl84O+FoU1u5qRdFZE7FC1+S2kXphWzh3o+PUi6UzSWouQ1o/cv9XYHN9x2/sgMf4ThZ6qnBz+itSD1craT/+LiM0K8X9sIaYvYkslmFk3vUPKi0PL+z0+J2bfAP4TET9qs94yx1ixDesAR9Pm1PVK36y/AbwQEfeq2Tft+vuZQjo3aa7NDcqfGWmN1WuVzkc7FfhIoUijY3Rj0jIWR5G+7C+Vb2onYSjzehtPSqp2IyUsAJOBnSPiJaUhlP0V/wJzD4+9hvSj0WhSz0yzz5kyCeadpB9PxpDeV7eQdJGkRSPiJZove1Amyau8Huq1r9lxUuqzuEqZZKVMLHSQpEl6e774V0m7k5LwyhIl9X7ArWUg2v570nO7CPAPSbfn65HfP1rxkJNDc4I4MkhSZdz8vRHxVxr/2ry2pGmkX0tfIE0h3u7CxkTEnDX/JF3XYsz384f9KNIH+cQ2q53MvD1/r5PeLFtxGvMObXszaRa3VhLEmRERpIW0i1+YpTRc9U0NYv8bEZ/PX1x/L+mzbSSJtRZXf5U65w010e7rZVlgJ0nfBi7Lw2La6UnpuO19kBhX9rME8DHSr7Nfj95zMJqpvp+hNDR7R9Jjtmw/xUK5BPM/kdbGWoX048nHIk/oJOnz8yH+l6Te3gUk7UF7PW9ljjGU1odbjtQTtUlE3Je/wG9AetyrJ8Gpjn0vcEelxx0YI+kDzWJz/KdJ70VbA7fVGHba6HGovB7uIA353rNRXVVm5X13Uf9YbvYclHm9vYc0I+NrhZ60tXKSBM0TkDLxTwPn5ucoIuIv+fNoa0m30rwXr0yCOYM0g+VHC9uuBvaXdAfw3yZ1l0nyHid9Fu5Gb+/fPbkn9l6a9Dj3wWdxqWSljxId6CxJK65duRK9p54E0PQcxAFu+8FtlJ1L/tEK4Il8H66nNzFudf1FGyacII4cL5I+EF7P1xt9sNwZ+TwDSRsBh0n6S0R8v4V6Ov3yUfQL0sK0lV6pdn6hr1V2Nq2/1mvFv8G8E2PU84qkbUi/eP+PdO7MK6SeimXz/w1FxB1KQ+7OkLQFafjSAqQvG3XDamybTTpvqBMv0vrr5T2khXQPjd5zccZIWi/vo1lyXqbtZRPjyo8hbyc9vttH7clR6lksf/GEdF8rEzhUEpfv9lMslEswBRARj0j6Jun80XYSjrLxC1VGJEg6Eniq6vZGr7dSx1il10vSe4AjJP2QdD7rxrnI+Y1ilc59myLpJxGxB6knb4Nc5JxGdZOO4/Gk53jx/HwtRBoqCI1HWrw79+ItA7w/j3hYkJSwCli0QbtvlvQgcASp9/NX+aaWEwbKvd5uISXwi9Pbk3a2pOUj4j+k8+kaKRt/KekzpeIE4De0NvFHmQRTEXGnpOI5uqeQRotMyvU3UjbJ+2v+weY20vP3fdJ5deNJPZPNlPkshhLJSsnYUklaRHwh72OhyKcgKHXXLthi9QPZ9sfyPvaLiB/ky6OBL5Cez0YqQ9ZvLdF8GyacIA5fLxQuR0T8SdLSwG/zsJS3NIidMxVyRNwI3CjpYEkHRfOpjuvN+tnyB0v+lfixQsxOrcZS+4tldxv110tWWo3/EmnI2lPAKbmnA9KXjGZumtOIiHskXURaWLuVmVS7lc4brG5nq9OSl3m93AV8CNhX0lci4hekSRQqw8+azYJWbHsU/j+vhXaXTYyLP4asAxwi6baIaHVCgHPoTSwALo60NEors+eWiYVyCeaJlQsRcXuhx7iyr2bKxo+DOV9cRpNef9NJv1xfRu3Ev6LMMTZHRNwl6VOk5OzBiGiWkFfieoCfSdpJ0uci4tQ26qxMcvMjSVuTzmv7bLQ28cfdEbGZ0qyxxymdA/oIUIltumRCRNyotGwBtJ8wlP1B48f0Dg+F1PP805y4tjLCpNP4A/JQ0NvIE21FxHPMPbFSM50mmJvn//9APtbz66fl89tLJHnH5///Rnq+FBH/pXeynFbqLvNZXCpZKZnoQMkkLbsc2Khw/Rx6P9fqGiRt3440ORKRZgD+TLO6K+9Pkj4QEX/Ol0eTJkmyEcbrII4Akq4rDg0qsZ8JEfFqh7GTo431f3LMMsDYaO1cskrMVcydNFSSjb0iTajSLP4hCjMV5vgNgO9EPu9jfpE0DiDmnohiftTb1utF0hURsVW+fBjw54hoaUhxWTmZKCaVc5LLnKg2i/9dRHyuatvBQE/Mey7roKI0pLfoxYj4cQf7ObCYEEv6YNSY7bON/TWNl/RZ4KukmUe/ERH3dFpfWZIWieazM9eLXSAiXm9esm78p4C/5l6wZmWLx9l40pfVKflLfyt1bRJpgpn9SAnPzjWGuDaK7/j1pjTT596SDgE+GL3rAa5PWl+v4fntZeML+1kjIv7RvORcMWtHxN9yQn9QX3yWtlH3NpFmEd8N+DuweuFHhnb2swTpvOxHOmxH25/FVfFzfaZIujoiJvd3bC4/T5LWymdDLj/X+s2Sro+ITdqoeyDbPg3YNiKm5/eL6yOi6bJOOfbPEfGBwvV+W9vWBi8niCNAO8mZ0tpy88wyWCwCtdeWUx8v2D4QlGaMq+WuqJrtcj60paUF68s8Z3X213YyX4gdS3pfaTupVV7zq5N6+1qZpGGokfSnFnup+7recfSeTzjoDbb3N0kTI+LFDmMXBFaNDs4tLyPXe2REHNi0cD/El9VJgtmHdZdK8gZSyWSl49gcXyY5/QVp/ck/kHoOPx0RH2uj7oFs++akXv2bScOZT4qIs1qMvSEiNi5cvykiNmgUY8OPE8RhKCc5tX7lOgHYgzRBw5G1Ep78AVxvooX3kGY2nV3rF+8ysTl+U9IQlmZfwKbUuX1YkPRl4ALgD1W/XtZbrL7s497x66XGvlpKauvEVv9aOxboaqWHZiCSS6Xzivaq2lzpxZxzvdYvr2ViyyrUXTnOuph7BtLKcVazbqVF06tfb5cCH85xR0o6PiJaWoJCeWmUFstuSon3CKU15Kpf64+RhksuXtkQeYmWqthSx1nVvrbP9VzQrGyd+I6Psxy/ELB5p/UPFZLeR2tDAusuVl+i7uK6vDDvKIfKa7Xu+rQl6t4HmFDjpmOBz5Bmzz2p3g95ff1ZXDJZ6Tg2x0+j8+S0Mox3PdKau9+NiBcaRw2Otuf4hYDVgMciz8Iuaa2IuLNJ3D7A+0ijFLYGXo6Ib7Rarw0PThCHIUkrAquQvuAfmP8/gHQe2TuBG4CPNHpzVzq35nd5KNhtkSZEOAk4KtL5G43q7yg2v5ktQZMJbSLi8Vrby/7Cr7S8RKNznxrW31eUFhL/HGnWvuKvh3MlUDXiOn3c++L1Mop0Xti21W2U9JaIeLhO3EbAYaTnbDQpUXmYdK5EZfmDQyPiqnp15/20nVzmIXP1XivHR1oE/ZiIaPl8EPUuRdC2dmIHOMFcj3knbXoX6Zyoz0TE+pKuihYX1G6nB7MP3iNWIJ+HVvAoadH3n5Mev4Miou5kMSWOs/3onTxpzXwf/pHbe2Quc3JENJs0peZ7Qb0fkOrELw0cHBHVS9LUK78avTM51hURp7Wyv/kl389VmpWLiFvqxA9kgtlxkidpA9LEPZ8krWe8O2n9xCVIM33fRlqPsfo9pBJf6jhrsM+2k5U+iC2VpNXZZ0vHaS472Nre8HtEodzGpMT4/oi4KG9TOGkYMTxJzTAUEY8rTT//cKRzTh4mzTC3JbBfRDwtqdnsaRtIOgf4LGl4BaQZrhYEGiaIncbmX8n+SJqNbxbwGrA08Hy+Xvnltd4vrjeTfuWrZc4v/A3a/T7qn4Rf/OW333owlRayviciQvOucdVs8o9OH/e+eL2sTn5sJa0EXEhabP4tpCUNan4gRZoEaZ5EQtK5pPXaXiNNtDNPgliVXKJ0/ulcyaWkRsnljYXLxwIHkSaiOIneHrWGJ+er9xzIiuWVJtwp3sear9cysRFxIekxLu6vnQTzZNKxcknkCRVaFb1rsC0IzIg0AcgapOPrpYbBzJNsCFhJaXmK6nrmSTbKvkdEOodqzjlcksbkHwJmVnoNJe3a5C50+t54Hb2TJ9U7Z27NesGSHiUnlHXKnUGd46xGr7GAUeo9Z7thrzHpeOjoXOgaPWlzbqqqu95x0nF8RDyjNFz8wap9LgssHhH/atL8x6j/XDUl6RPRO7NzZdsGpPfGZj3At1I7ydueNHHKbaQf8+ZJ8iLiJqVZem8ircW4bn5v/zVwSET8V1Ld94o++CyuuU/SEi1FJ1LnNduHsddIuoWUpB3dbpJWR93jtEb9g63tLU24FxE3kH4cLrqGFtptw4MTxOHr26QZ3rYGfgZsRRoeVVnLr+6QLqUT4t9LGuZ4MLBpTiDeSZPlHsrEApVp5L8GPBARV0o6hfSrWcNF7nPsa8BrdX7h/zpwS6Nf+CNiGjBN0uIR8XzuWXs2Il5Xmsr/lOjH8xAl7Uma6a6SpI4rfHG+gAa/5pZ93Cnxesk+T/rQ+xhpyOKZ9M7g1/IMtpK+AVwCTIi8BmTunZxHmeQyx18v6a2k2TBvz9e3IA3jaWlh6Px63RT4V/4yugLpvLqmM2qWiYVyCSbp1+jrgG8rDV3aO9o4n03SzsBXgJfysdWO6mSjrcmAyrxH1HCUpFOZ+3Hsl+MsIv7eQfuKHoi89qKk6wrP9eUR8UMaHGeVHxQkTYqIm9utOL+HPlX9/pd7RxZu1HMZaeh3x8O/y8YDP6Gwtq2kN5N+QGp6HmMfJJi7kZYpqsR9hPT+/oUW6i6V5JFmMf0IafbXhXNv6tL0zvbb8D29j4+zetpdNqOj2DJJWj8ZyLaX6QEs83zZEOMEcfiqTEO+FGno1yLAM8DypGUsGj33L5J+JXyVNMzkNdIU9K83iSsbi6QbSOuCXSbpZtI07u3OElim9xPSOmp7kM49OJ70eC2Z29WfE9X0MO9jVPkQb/am/iIlHndKvF4kHQo8lb9MtVBV3f18ElgqIv5ZtZ+WkrV2ksuC3UhLDfxF0hXAjdH+TL0bAs9I2p/0GE6QdGtE/KQ/Y0smmK9FxPnA+ZLWBs6StEfUGQpcw5dJ0+WPBg4Hqs+7q/t6zcnG9IiYa+1DSV8ALqr8Sl5PX7xHKL3AvgG8EBH3qvUX7ouUe397hPSF/wcRcVuz8lXmSmJrJP+tfPHbG7hZ0nHAGsATpB8HWukd/BNzJ1oLkdZTPBFoOLRV0pER8Z2qbbsDT0dE0+VsSsaPkbQUsCLpB6x1gK9GxKPN6s06TjCBZZRmql2R9GPW34HPt/h4Q7kkT6RF3c8lrZn4TVIP4BKk9/aG74199FncTJlkpexQx/mSnNYxVNvu4aUjSLMvTzZ0RUScFhFT86/L/yF9wH9X6dyGuxoE/gH4F/AJ0hfBB/K2u0i9Q40q7Tg2m0Ga7OIu0jp442jy5aOo6hf+w0m/8H+J1nvS8m60A/Bq9J5jMYPWF8ntSE4KjiOd/wfwRkSckf8azqjZB497x68Xes8f7IikiyT9Hdgueic2eV7SqkrTq89qYR9zksuqm1pJLpcjrd/5IWC0pK3aaPtewPtJifWEiPhaROwKfKBhYMnYgg2BJSUdQ+rROlbSHm3EExF/IyXKP8m9ia2YGcksqia4yb3eb2oSX+tctTeTFoFvpux7xGXAf4GNo3dd1zGSPiBpE+pPRNMXx9mjwCHAAZIOarXNNUjSF/PfhpVtLcZ9lHQ+1DakNSDber1IWkJpIq0LgeOiteV/JhXiF5F0AvCmVpLDPohfnZTQnUJaR/HYNpJDyAmmpHUkHU0awr5vda9ivVjSj4tL5Muv0d6X7GKSdzBzJ3lQ5zucpD+RTqtYlfSj1yOk8xmvAvbM73HNlkcpdZy1aKgmaaeWrLvf2y6p5qkwUW6ZFvcgjiBOEIcvSbpE0oWSzietn3TB/2/vzMPlqqq8/f6I4oAiCKYVVAYHWmlQZBIUJxAEozT4Kcik7dC28CmD2AqRQUwUNQg4RXFAUUREQVAGUYiCiHTnQyaHRkUFcUBtowiIkPy+P9au3EqlhnPqVN17c7Pe56mnTp066+xddaa99pqIQf/9DC7Eek1xs5vHxMN5KdUGQU1kbfs3ts+2vTPwB+C8GgPXJaw4w38v9Wb4FxGWxxMJ97PjFXE6+1C9+PrQOJIl/HPrY+nTOWVQu9EA8Sb/+9Dni+15wGMkrd1rk34N234JMAf4vaTDyurjiIfwBaxYoLqz00Mrl5K+SAz0W4OoZcClwFMkPb64dz2sX98JZeEOYjC1Ttv6NQfINZVtqmBe1/7BEYf4cbrEM/XgTkl7SNqbcEO+tOxzHnHNzRvU/S7r7qXaJE6je4Tt3QnL+NcltSy1nyHqnT6TyNzXj6b3t1ts70sUnj8EQNJRihqiG1f5DYUlRMxny6rTzzX2peU+9nAiodBFpTPfYuJ+M4hnKLIq3ggcDRxqu9P1rRf/LOkjkr4OfA/4lu3jKso2lb/J9j62dyRi9/aU9CFJVY4XNFMwb7e90PbR5Vy9ATi/3Jv60kTJcyR9up6wHO4i6SnAnbY/Rzwb5xDxjP1o+ixu/y1dY1vrKiuSlpd4aKjowABlR9Jjy2TIShmNPUQtyg75sfa9ULneYg0OG8M+k+mK7XzNwBewoOPzUSPY56OBB49TtrPfZd1uwOk12lpITH6cDcwu6+YCW9SQfw7w6bZ17wD+ZZKO3auJ5ACLJuuYNT1fgK2IWoyXE4rsocSs88XAL2vs5x2Eslen7ccSrliHlc9PIhLQXANsNUD2/YT72FeJCYD3EQ/W/YD3AO+p0P5cwkL9qvJ7LwFeWLHv3WR3qSi7M3A6kfDlc23rz21wvjyg4nbrEBb6/4DIhl2znUu7rDsC2LbuuVrW1bpHtMntDxw47P/Vtp+q19mijs/nA08AtinHcfs+sme3LV9e3meX86bSdQacVf6rY8rnVxDullV+4zfblrcm7q9HVpS9qpznuwIfLNfbE2r8v0PL9zhf9mv9BzV/92zgZEJZnFVBdqVzi0hw8qaqbROxvnsBTwFOKuvfVvqw7gDZNcv/dQawfs1zepTX2eVd1j2pouxxrWur231j1C/gi+X99cSEwkp97yO7GXDQoNeY+v3Scsxbr8vali9tvQ/Yx/vK+9XERMzVreVx/+/5mn6vLHORrBJIWt8DYpPatn217c9I2gLYxPYFkt5OJHO4roL8QttvLK56t9r+uqSjiYyP/VwtR4oaFKyfbMps/CuB17hCCu0B+3mUO+LTKsq+A7jBkZCjqsz7gc8Rg/TXApfZPrlmu1sQLnt93YD7yN5qe2D2zx7ycwlFfFtgX2JmecF0P28k/Zy2bKJEv3cAjnUFl0VFbOkW7ddjnXtEx74e4gq1NkeBpCfbvrnt89OIZCeLau5nkYewQkg6y/YrFSU3diWSXxzrCkmZJH3O9oEd694OLLPdN9GQOsqeKBKAnUbUV/1ehbYbyffY5xoVf/cC20d2rNuPUFDfNUzbVSlW3xcT2UrXAY6o8Rzc0vYNPb5rUq924HWmSP71ZcKlel9i4uvlxATiOrYfrwrlFhRxrqe5ZGfuPA96yDyRUJ5bg9tWxtXjiWfUY4n/8bYe8pfa3lXS6YQb+beqXmul7a0HbedwS+8mv0qWk0lmJqkgJtOaUSlJiqxzS2z/vcK269v+o6SHAI+w/TtFooHFDjefpAejVmrrDGSGUS4lbUokuqibmGbQfhsVMq/RztDK6VQi6Vk9vrreFTIFK2qWfsI1a06qYa3U6cKw15mkp9j+8Yj7svag86+bsiJpHWBH2xd1lxqdfJvMA4Hn0+bSbftLVeU79lVJwWzbfjPCU6C97b7xn/2UvDoUhfpA2/PL50q18Bq0dxLwNcLt+hHA/yUUxYOAPWy/YNAkhyQRCYI+Yvumsu5S16jt2r69pNeX/lxFWI9f0UPmm4R1/P4y0TzUZMwwjEDB7HUtvMr2H2r0YyPCcvs4InRgvmtkuU5mBpnFNJmWKDIafpfINDi0wtEaqNdRGlqzo8WqcE9ZPmfYPlShY+DamvFcYRNWgYFrU+WwPJgOaA1kiNjHqorWznWVMrdl7RyxUte336OaKbZ9Y9nfpCikpa3nEa6Zg5SsnvVCbV81ZNuvIlyZDczSRB2/BYRF8jrg6bZ7JclpWit1SigK9XM71m1H/O6DiURLJwxSrlvKYdPzpV2+yuRENyWnDDgrKXdN5du4hIj9/WVrN3WEOxVMSXUUzLOAdxPZQKu09QLgQEmjmMx4C/Hb22UHts3wEylPJlwTH0gohxBx/JX+b0WG2hcCn2wph3XQRAmg9YvSJCKWc1vbSySt10f8OcBDbS+fxJLUfq38yPZhA9q+GbjA9mV1+u0G5WQKD+y0sBYvmaoJ+lqcARxD1OKcQ8Ro/2vNfSSrOKkgJtOVZwFfpHnWrBUG6pI2tN2Zkn8lJO0J4EjUMhm0Bq4tBfETRGbJZUzj1NKStibiUvpi+90Vd3kENQYyHayklEl6TIWH6tDykn5NDDhbx2kpocAM6vcyJrJ/7gT8lf6ZYgfR9LfXYTExyB3qvCzWv34DNAA8kUG4fd1nJf2gm8Ig6SZH6Y+udS+LfKNaqU3QysXql3/FigXfu1lIbiMsHwuI8goLiEH/foRyeCXwAaCnUi5pjsNd/j+BF1F94qUbQ59viozDRxDjj9Zv3q5qww3lZ9mumoipG00UzD/ZHpQAqZ2RPBMkHQhsavvittWD5Dvbfi2R8Oa7dJ/A7EVLHmLipVICrsIaDJ9IcX8i1vNqIinTD4mEa63JjH79v4Io/3OA7c8D1LFaEomEPg/MKS7Yr+12L+vD0OVkGN1YYZntK8rylyW9cUT7TVYhUkFMph0lfmGJo0B9XdmLiXiyO4hA/k5Op+3m2yF7OJHlD+Lh4hIjhO0Tyjan2j60VqcqYPtuRYH31gN1KyLGpjOOolfh86nit8TAtTHDDGQk/RJozTBv0WWTM+lTULipPFHmYKXzqc+sPwC2fwr8tGz7AOAPti+StCaRkGGgVWYEfR8K23+TdA7hOnYfkbp/NpF+/z4Gn6vbEgO4rrtvk++l7CwoLt8fIq7XtzpKDtQZHDWtlVobl2L1Q8reKmkT4BZHsfRbiMQ4uwKH2/69pDcP2M0RRXl+fGtFcT08m/jP32b7O72ER3i+HQc830PEi45A/jJF/OBVlPOl5uC9iYL5UUkLCeWr1XZPD4GmzwRFmYNdiLIte0vakEhsNfCh2qXtjYhs4K+u0jbwYyLDrwjF8oVEqY72GNae16vtj0n6OPBhSb92/dj/hwFbEjGEPwPmE2OC2cDv6J9x2LY/IulT6pLBtAL3O2qc/reiNu3HJB1ne3GdnRQr517EJNBbXT1jcCfDKI1XSdrC9o2SNiay7yarGakgJtOKMlO1G20PEkVdtRa/6+caVSwIi4jslN3Scfd7OC5iopTFN3ps021gNBIc6fdXuE038AAAH29JREFUQNIjgLXdI6B+qrH9GwbX0+pLk4EMoaDNKftZ1BaDcYmjnuOgfTSVH3rGti0+5kbgb8V97dNE0pxe5187Tfs+NOU6O6T04VJJHwJOsf3zCrLfBr4t6ZG2/7coKX8oE0JHAR8a4CopIvvrBwnLWqv8QCW0Yq3UtxO1UjehXq3UkVEmRm63ffmATecCCyW9CPgYcZ9clygzAv2LpkP8b/sQyUNaReePJCbSfkDUROypIDK68+1XwJ8rbjtq+X8QVtw5TCg5deJYmyiYBxHKSuUyESN4JrRb8FoeDkO3XYOPMpGkZn/iP19G/P9/LxO5TxrQviUdSVjPKh8jRWzqXGKy6hLbZxY3y/8F3q4oi3Rz7z0sv56uIrIL173HL78ObN8m6QDgi5L2q+id0Con82SiBNKerVCCCswq7rDtXgkq+6nDzsArJd1B1PH8X0lXE4dlx/6iyUwhFcRkutGK/1nWsa510638gCtIEwVjz6L/rOV1Nfc9UiR90VEfrZ1NCSvBe7uITAskPZKYod2YOD5rAGc5am5VZdiBTPvxtKP4d6/vxyG/nGId2Ij4HVtWlSPcn+YQg6pTbFdRDjv71qjvdZF0JTFLf7Gk7xMup3Uzgc4j4ufeSkzo3EoMRh5GWCs621yPcN0ysFFrRl6R0bSdQb97CSvWSr2bGrVSR0lRsrcH/q3K5oTF9FGEkrE2YRXZkPjvBvV9Y2An26+XdFyZeHs+kdHx/greGqM6304ErpV0bdu+6sRWN5Hf0/YONdrqpImC+SBP1GqtRJNngu3TgNMk7U+UbngxYeVF0msrtH0ZcV1fCZxT3LMr4agTuU3bvlQsvh8qr6r7uUfSjzWRabjKJMTfCOX0uUzUFd2YKGH0YiLxyhF92mwdz4uJe0LdCdAVXNxt/1nSCcQ1vqCC/A9c4ghLCMc7JP237YGyjnqVjWl4jSQzhFQQk2mF7U9IupwoxDy3rBvGzaOd1qzdUgYH5/+CiFs4ubiJTCbd4rLuYsLtdbryScLqswiWu0zOk/RSVyg50XQg04YktQaKP3Gkv69jRWskb3t5nEaxYg+iNVP8dMIisqeHz1jY9LfX5e+ENWonoszGtxgcH9OJJO0L3NVmhfk74ea5EmX2vRVjeFtx/7697GdXYO1imeh7vdg+W5Fo5xBi0uhNtq9SZBCsWjx9KIpSNouYSNgR+Irtg/pLLcftLomKEic3AfMlLWZwDKtZceJtKR1KX8V+lOaHPt9OJe7vP6vR3qjkL5G0ke1fDdl2EwXz+8Va/F9MWB/7WbJgBM+EYkHbRtKerhdTvww4ilC0zpd0oe1Tasi3M3/wJt3xiqVE3lNh+/sl3UxY4NaQdD5Ry/IPRLKVqu227mcH1Ohu13h7R1KuqqEYyxPqFbfSfSS9XdJ/ekA5mRZDHOtO+TfaXihpA+J6O8P214bdX7JqkgpiMu2w/XNJ60p6EM2tILb9ldYHDYgNI1xi3gG8W5EMYzItd936dj8Tbq/TlfXcVsetPKAXEkXUK8dcNRjItLOEGKi2rFl1z5+68r0GxVXabZ8pfjZwnKSrbH+gSke7sIRmv70OLu7FZwNnS3odcJ6kfV2tlMwiIqZqd2BzSccTiak2IayEg3gPYYlYi4id+wn1kq5cY3uZpHlErNQFhMI0VgWRiHOcRRyj+4DZkh5gu0rmVEm6kOjnMuBO2/OLBXUDwl22H78CrpC0FXH8zpS0PfDM4nZXd0JhCcOdbz+3fWHNtkYlvztwkKRWyv+6LnNNFMxNyqu9ZMIgy+eongmnEPGDrftqpWNdlKovE4lKXquI29130PmqLlmatWKoSGv/A+v5STqyZT3zYDfsFr8Fziv3qMoWyx7tL6+TKukLrl9ap1bGYHfUGi3rTpS0do1mD2XiWCPpwcADXKGEUGFfYCFhLZ9LuLSngriakQpiMl25gnCdqjVoKdaFxxEpmt/atv5UIsZokOufHaUP9pV0oqRDHAHrRxEZ2Dau05+aLNVESu52zh1jm6PgVkmvBj5r2yUG5BgiVXZdTqHeQKY9Fsm2z5U0G/hscZnbdMzye/dYX+W8XR67ZPu7wHfLTPHbKk5MNO17E1awdNr+pKTbiEHFQHdJ288vkwhnEdbn1wBIegeDlbRjizWx1kCto/3PlPcbiRhQCOvCkmH3WbHd9vpl75U0BzhX0kEeXGfsercVbC/3JGyfV6ML5xBxhy0WENmi16DtftmDUZ1vd0j6FCta0k6rKNtIfgSuc7UVTEmPIeoffpmIc/8IMbFRxd209UxYvjviN9c55hSF9p1tq6pY9K5t/2D7U5J+A3yYmPzrRytL8+aE2/h3CI+DRYRbdB1qxby1K6f93KZ7KaeSzre9Z9uq85lIbNerfE63/RxMxJPXKdXUEw+uNTqH8IowcG/xpvgF8Rw+GbCkd7paCMMakp4PLLV9syI+PlnNkD1tM+gnqzGS/tX2VyW9oMasYbf9LHKNIred2xf3lCOIZBCzAGxfM2x/ZiKSHkLMWO5IPJzuJIqY90t4UXXflQuC1z3Wo5bv2NdQhcyL7Fq276opM7K+12hzDWALt2UYlLS+K2aXlLTQ9hvLQOpWRwmGo4ELXT9r4SqLpG2ALW1/eszt7OHIlPtK4N+n6lpR1LJcAdufHae8pH8uVmYkzQJeX776lO37qrY9DMVa/kkiKcvWhIJ1G/Be2y8ZZ9vjQCW5VMVtdwY2Lsrle4jnwi0DZDrLwcxixZj0fuVg0ESx+f8gEtzcR1ht7yDivYGVJmva5b9JuFXuSsQn70NMZAnY3nalzNCSPm/7gHL8v1p+00+BJ9l+Yg+ZkdTHLftao3hJnEdkc/07cL7tXSrIbk/87ncRHgJH2p43SC6ZWaQFMZmuHAF8taUcFquUbf+l5n7qxj68oePzscDj210ox4GiMHG/WIfWQ7FOModJobjfnDiMrCoUZFZkf6vyu4eOcxlGflDfFTGVXY/ZoOOtmPquc7yb/vZheAiRAXO5Ja+qclg4pryfTpTMgBhADSzxsSrTZlG6EbicmPVfS9JlQ7ouVsL2ReX9rDYL2LA0Od9+4VJjTRGv/IxJkP8oEyU43k8kMvkTUTZioMW7qYJpuxVTfXPLglMm1qY9kh4NzHaJj66hHB5F/M//VVZ9mwrZZ92gHEyR/xnwM0m7AV+y/Q9FLcFfVJxsNmHp/AkR6/k8wvq7BhWUNwBJOwHXTXTJpyrqkPat00oowveW5dcT7vaVk39J+lybi+oxxSX4IcXjoq9FtR3b10i6m7hmbkjlcPUkFcRk2qDINroXcYO+q7jW/Bz4OqGoWdJ8r1gnr9e+tgV2ANaV9GTgMtv/M0jOHUkDJtGS0SpM3I2nETOfVeKUppS68RY0+N2SnkUkUGhftx3hNncwEZd1Qq+4i6byTfreUHYUfR+aYsE5gLhOZ5UBj0vbnyUGRk+33dcdq6VMlgmGe8ryOaPu7zTkC4RFaVvCyvERwt34w8BkWZRqFSAf8fk2D3gOLI9XnkeP2rRjkt/W9k5QOZkUNFMw75T0YEdsbrsrbOVyF1PMpkSc7gpu5ZK2H+BNsw9xnr9NkfxtrivEJ5d9n0rcHy8cZtKkTMJsRSTXMRGucgkxITOQ4sHxs7Kvv9q+tixXaftQYDtWrPkIFWJ0W8pt2c8uwLm2/1ruuWdX+P82LLKvi935h1WVwnYU5UWeTSj1+0n6motbfrL6UOshkSTjxPZptne3vUfb+5uAtxCFdnejT3rqFpLeS8TZ/J7IHPYH4HhJh42v982wfbft24EXlPfnEDN/txODn7+V5enOSokyysO6Kw1/923E8d2r7f27hEVrAyI9e7+EL43km/R9BMe76W8fmuLO9xbbu9re2fYLy/KlwE2O+mk3DdgNENn2JO05eMuZhe0zbR8PbGb7Ets/YnJrMNa6Thnt+dY5Yq2bpXkY+c0knSTpGKKMSothJsm3tX2s7VOpFpP+MopVyCXZSrFoHTZE25OCpM9IuqjEsR0DvFDSxVoxHnJQRtE/2/6w7b2JLMdfkfRPFbvwTKK8xFxJZxQPojqcAbyhNY4gMkXfq6hJOBBJD5f0REVCp7UlbVfcLqtwP3FejTKL9JOAx1bYbktJtxCusCeUdXdIeqqi3mzVeoh7A3s5sta+nPB4SFYz0oKYTCsUqdO/0TE4tksNJknLukuuwI6tGeI2zlGUzzilT9udsQ/Lvyrr+sY+jIgdilvIK4kMkRCDi4cyUa5jWiHpl0woBFt02eRMJmbfe1H7d9u+VVHg/Bbb3ykPxkcTCtbhtn8v6c29Gmwq36TvTWVH2PdhWSDp5USGwIcDby2z3wNnySUdzsSgfgvCM+BpAK1BjaRTbR86lp5PPVNiUWpynY74fPuypM8TbnsvIpTLOgwjvz2wTnldA8tdRT9Ssc3NJJ1EJDGqpWB2c0EtltbFFduedGy/usJmgxSg5fcC2xdLuh34tKL80aA6t3fb/irwVUnPIArNH+wB8YttPMB2y7UV25Z0BtXrje5EnNt3EXVHW3UvB+JIancjEZffbdKkauKPzxAxkJR+PKz3psu5AdgDeLOkt9s+kcjK/mkiyd6g5EIt7rXdSgC1rFwryWpGKojJdOM/gV0k3QocVW5SdWt13SvpcbZva60os+N9B2BNYx+aIukNxEzn+cQM//PKoOypTK51oS4/tT0HwmWrbZb5EtsfZMCDteHvngsslPQiIhX3bkRCoVYs3KCBSCP5Jn0fwfFu+tuboNL+Bwnr0oeAV1SUXcREmv5eGfW6KTAzhZdR3Icn2aLU6DplROdbicfaiXDDu9A166sNI2/718CvO9YtLZMzVWiqYK5yKGIP30fEB98GHO0VM2kOehbf1v7B9g2SzibO85Oq9sP2teVe+XFF8roqVrCby4TFp2zfJekJhMWzSnbovznidS+CcKW2fWxZruqieoWkVpyqitvpE4pFtlK2X0ftxBb3UW28rvL/vE/SmyW9zFHma2Bimg5uUmSU/jqRuffHNeWTGUAqiMl04zbb+0nai4j1OBK4rzysRLU4vIOJh8mDCCvMusTs2VAWFUVx49vdIJtqRZYQD4K7iALJdxOxLvcwva/VFRT44tLT6/tuLGH43y3CGvUoYgJgbSJb3YZEXNe45Zv0vYnsKPpeG0nrEYkTDGxke3FZ3xmu0POY275u1P1alZhCi1LT67Tx+aa22HDC9X9QofiRynfhXUQx+L6MQMFcFfkocJztGyVtSShYh1QVtt0t2+wZkh5aQfy6DrlfSfo44eHz/gryhxDWwk8qkgH9Gni37R9U6PdeHavmtC3/pkLbLa6UtFbZ56lEZtSBFFfQTh5BhZAwr5hZ+EPEhMYw3EiUKnkdEQ//jyH3k6zCTOdBZ7IaY/s8SRtJ2ptwkTiPuGG9sYLszcAeZYb3UcCSirOOKyHpEGL2uIprSiNsny3pecTD7SzgTbavUqTtXlVcPFTchAF+Yvt7DLBMNPzddlvKb0lzCTe6+ZIWA4OSDDWSb9L3ERzvpr+9No5seK1MfLcV19Dbo3ntSsTrXMyAuDBF0oqrgZNt//eo+5kMpPZ1SsPzTREbvjFR1/VHhJJ3vKRrSqzToA4PLS/pKURCnXWJScZlhNLwtkHtDmAeXeI5ZwhrOeqEtqx/VVwcB9IKFxmwzeFd1p2nyFpbpY37gU+UVyNs39u2XCmGsWx7GoCkuhl/e01Y/L7OTor31cCssT3YGlhs+/9KOplpGt6SjJdUEJPpRvtg8VTga8UtqnKBY0nvBB7YsQ4A20cPkD2IGJxvRNT1+4rtg6q2PQKuKT7/84hA/QsI161VRUGEsIyJifTcVdyCh/3dknRh2XYZcKft+cWitQGDB29N5Zv0vansKPrehPcQs9RrAW9zlAGomsH2l8TEz7sl/cB2FdevZLQsod512vR8Gyo2fETypwH/YXt5HTxJTwU+zooWolrYnqnKIcBSSf9U4ksfTcQKb0r8ZwDrT3aHiuI3NorFb70K/bi1h/zzgP1Z8VqSpJb7fSuPwb/32ffASfBxY/sNkhZIuhS4vMQyJqsZqSAm04p2Ba4Elu8/xG5mEe56dZMfQCQImUUMmu4DZkt6wLgfTC1cUkmXmdsby+rPEIO56Ur7LKVtnytpNvDZopgPjLlo8Luvt31k64Oi9ha2z6vY96byjY5Zw+PduO8NOLZYE/cbuGV37Eg4sa+kEyUd4kjucBThDr7xqDqaLKfpddr0fBsqNnxE8kvblUMA2z+StHaVhrtNOrbtp++k4yrMEcDpku4jXAyPKP/9C8fZqKStifjWvth+9xia35YJBU/AzsBlrSaZSFjXS8FbDPyC6olophWSzmKi7yKyp/5J0hdsD3uvT1ZRFFboJJk5SFofOKlbDMQQ+5pDPAwOsr2k6f5mOpIWdcRBJMlKdJ4nks4nBqTrUqyn7l9jLWnAVFyninq0pxAJitpjw9/SimUdl7ykE4DZhCv3H4rsy4E1bR9coe15RImAlSYdbX9nkHxSHUkbEIpJX8b1vyvKWbSUwfcSLp/t2dPttgypXeQvLvJrl/c7WTkTemf8b0v2BUT9xNa27bTLv6ZTdhRI2qjXdx6iHmWyapMKYpIMQNI2wJa2Pz3VfZnuSNrF9remuh/J9EbSk0uscOvz04BH2q5auDxpwFRep01jw4eVl/RsonTBbOAvhLJ3oSsMgkY56ZgMh6RHEsrRsHF1Vds5jpUVtHarmj1RY7Cb/JYlZnN/4H7bZ5f1/2K7b31YRQKfdRlggbRdOVmOpGfYvrYsH2D781Vlk9WbVBCTJBkaSc8CntvlqwVENtkNgBMcWRqTJJkCZsJ1WtxJX0W4Yl9OZNlci6jBmdaNGUxJkPNl4B1VrM0N29rDUeaifd3mwOa2v1RB/lLbu5YY12VEZur3AFfYHpg0pyQAaymoTyWyiA6sxSzpuURcd7sr7PeI2N1dy0T3brbrJs1JVlNSQUySDlbTeJOhUKTk3oQYaB5Z3t9CxDM9lZilf0m/oPwkScbLdLhOm95XJS0CPkm4H25N1CC8DTjR9ktG2NVkmlCylu4FvB6Y60nIeNxS8DrWPRV4ue13VpC/mThP1wU2J0rAfLgk8arTj1nAubb3rCPXZT+XAi8iFOzXl9jxJBlIJqlJkpVpkuRmtcL2rYri7rfY/o6kW4BHE65ch5cMeEPVn0xmJpJeStQz65ydHDhLngzHNLlOG99XbZ8JMQi3fUlZfshoupdMF0oc35rANsQkwG62b5/CLt0LVD3P/gp8n8jyej+wFfA0oJKCKOmZwPHEtXKnpAtK+4c76nH2kz2i7eOfCOV0A+B84KOpHCZ1SAUxSVbmFCLeZN5Ud2QVYS6wUNKLgI8RGejWBf5Yvl86VR1Lph+2LyDKeSSTy1Rfp6fQ7L56p6QHl7jD09rWV82Cmqwi2N69tayor7pQ0ifLvWPcPEHSsR3r1iOUvSr82fYVZfncYgk8VNKZtqtkZV8AvNj2X1oryuTOAmDfAbIHEcm+BBwLHE24uS6lh/U+SXqRCmKSdGD7j0SsS1INEYXRH0UM1tYG7gA2JGYw8z6TDETSgcDtti+f6r7MUKb0Oh3BffVllEG67QWwPDbtsMadS6Ytti+VdBmhJD64ShxgQ3qVc/htFWHbL+z4vBT4QHHzrsIy4vr8S9u6tQgr4iD+3Lp/Snqb7ask/Y5w0/2SpKvSiphUJQduSZI0xbbPaH2QNBe4CZgvaTFw/ZT1LFklkHQIsD3wb1PdlxnMtLhOJe1q+9K6crbv65QvSXXGmrQkmXpsL5X0RmCDYc+fGm2NpbyO7VsrbvpG4MOSWha/NYDfEZbBgc10WSfblnQikZDqXRX7kazmZJKaJEkaUbKu/YNwY1kG3Gn7QEl7EfEPp7UGd0kCIOkgIiZtI2BH4Cu2Pz61vZrZTJfrVNLltl/Qse4xtitZaJrKJ6sekh5k+96yvNLxTwJJPwR+RVu9RUmb2r6lfP9i2xdOaSeTVYa0ICZJ0pTrbR/Z+iDpKADb501dl5Jpzr2EgngPcB8wW9IDbFeN80nqM2XXqaRfEtZKgC26bHIm0HPQ31Q+WbWQdLbtfdpWXczE8e0sID8jkfRvtk+vI2N78y7rbmlbTuUwqUxaEJMkSZIpRdIc4N+Bg2wvmeLuJCNG0jdbsVmlXMU95atLbH9Q0iLbzx+XfLJq0Xk82z/PZAtiyci7LqEEfwF4Zfnqt8SE2pq2756i7iWrGWlBTJIkSaYU218vyRT2Bj491f1JRk77TLRt79Hn+3HIJ6sWncfz0cUtfcqth5JmlcQz42AH4MCyfAswn/gvPkVkAf6HpPm2LxpT+0mynFQQkyRJkinH9mIy4cjqgCS9piz/xPb3qDfwbyqfrHqYyGA71uMsaTOilMRKEw62TyiLXwD26fx+FJQMpMuzOEvaiogZPhh4NaE0fhVIBTEZO6kgJkmSJJOOpHfSozaX7aMnuTvJ5LKEGOy3XEXrWgCbyierFr+3/QUASa8dZztEvGMnKm3vR5sCNw6KJ8UNRGz2B4GHAhvZ/mH5Ps/1ZFJIBTFJkiSZCmYBdwNXTnVHkrHz57Zl2z5X0mzgs5IANh2zfLJqsaGkVikLEfU6x47tJWXi6qHEpMM95f1jkp4DzAGqFLtvwo22dwWQtBOwXmc3q+xE0vrA2u1JapKkDqkgJkmSJFPBKcBJtudNdUeS8dKRkVJl3R3A7pMhn6xa2N6sz9djdTO1vbuk/YG/A98EHge8HDgI2NLjz+xoSQ8DTgZmA+cBv5C0OeFiOquXoKRn2v6+pJcAfwKeWGSSpDZrTHUHkiRJktUP23+0/aqp7kcy6cyfYvlk1Wayjr+BRwAH2D4eeBVw2iS0K+AuYB6RsOuBwAeA04Fvl+VenFSUyzcv35m0iaSrJV0laUZmf03GQ1oQkyRJkiQZC5KeBTy3Y912wAIi+cYGwAm2/zYO+WRmYftbk9DMFwkF8eHA2qXdKyU9SdJrbI8z0/JFxUr5K0mPAh5j+2eSdiDKXNzTR3YHQql8Wvks4HDgLcB1wFcYcwxlMnNIC2KSJEmSJOPiNuAqYK+29+8C+xHK3ZX0t4o0lU+SypTJh62BbYCtgAe1fX068JJxtm/75LaPtxLnPLaXDlAOAS6z/Qrg+vL52cDzgf+X9ROTuqSCmCRJkiTJWLB9a1m8xfZ3iJioRwO7EjGoXwM2GZd8ktRk97bXc4Gvtb4olr1xJ6mhxBACbG/7xhqi7nhfWpY71yfJQNLFNEmSJEmScTIXWCjpRcDHgN2AdYE/lu8HFR5vKp8klbD9zgHfT4Yl7k2EYtp6R9KDS/t/7yO3i6RzgKeXz1cT5TK2kXQtaRRKapAnS5IkSZIk40REPNfjgS2IuK47gA3L94Mmq5vKJ8m0R9IzJF0MLG17P13SbsB3gG+X5V58j0im03IxNZENdQFwGfDe8fU+mWnkTTVJkiRJknFi22e0PkiaC9wEzJe0mIkB7bjkk2QgkjYDth+0Xfu5OEpsX0uX0i2SLiNiCdcAzge+0WMXR9i+W9IpTJSDuQXYcRz9TWY2qSAmSZIkSTJOJOlCwhV0GXCn7fmS1iASzbx9zPJJUoWlwL1tn98EfJhJjN0rBe7fBaxHxNheAxOurVLvMpC2/6u8X1j285uxdziZsaSCmCRJkiTJOLne9pGtD5KOArB93iTJJ8lASjmJn5dkNEj6V+BLRLzr5ravmIRunAacRFjFPyjpf4hJkeXdrLIT239kIkY3SWqjch0kSZIkSZIkyWqLpMttv6Asb2L7F5I2BN5ke+yWaknfsL1bWd4duAc4gqhnaOAU2y/tIvdSwuLZwhQ30/Z1tncdS8eTGUdaEJMkSZIkSZKkKFWSHg+8BjiGUNLWmqT2HyhpHdtLgO2I2otHEpbFZcDB3YRsXwBc0Pos6Vzg/9he1m37JBlEKohJkiRJkiRJMuHCKWBWWV7K5GX9nwt8XdLfgIva6oDuPEiwZD5t9X8L4EJJK7gJ2t5jlJ1NZi6pICZJkiRJkiQJrCNpR+AxwGPL8sNZ2V1zLNi+Gnj2kLLdMqCuCTy2ZDNNkspkDGKSJEmSJEmy2iPpuB5fLbZ94ZjbbsURtg/MK8cRSjrf9p5FKXyt7YWSHgXMtX3YWDqdzFjSgpgkSZIkSZKs9th+5xS23TSO8KHl/YHADsBC4G7CApoktUgFMUmSJEmSJEmmmIZxhN1cAu8H1hxdD5PVhXQxTZIkSZIkSVZrJB1OD2ub7RPKNh+wfcQk96tSHGGbctnulmrg27bfN8YuJjOQtCAmSZIkSZIkqztXAg8asM3Tx9mBbnGEwCOANwOH9ZPtlqQmSYYlFcQkSZIkSZJktcb2YgBJGwGbAzfY/vUkdyPjCJNpwWTVdUmSJEmSJEmSaYuk/YGTgI2A90vae5K7kHGEybQgLYhJkiRJkiRJAq8Ddra9TNLHgPOAcyex/aWSLqLEEbbFFX57EvuQJKkgJkmSJEmSJAlwf6ushG1Lul/Sg4HtCKVtnXE2nnGEyXQhFcQkSZIkSZIkgR9LOhS4ENgN+DnwEGCn8v1XpqpjSTKZZJmLJEmSJEmSZLVH0hrAa4CnAYuBM5wD5WQ1JBXEJEmSJEmSJEmSBMgspkmSJEmSJEmSJEkhFcQkSZIkSZIkSZIESAUxSZIkSZIkSZIkKaSCmCRJkiRJkiRJkgCpICZJkiRJkiRJkiSFVBCTJEmSJEmSJEkSAP4/C/xUE8wuiqgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(total_df.corr(), cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c55d99",
   "metadata": {},
   "source": [
    "# 코스피 보정값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809112cf",
   "metadata": {},
   "source": [
    "### 코스피의 영향을 줄이기 위하여 각 테마에서 코스피change를 뺄때\n",
    "### 코스피의 change가 0보다 크면 0.1 곱한 값을 빼주고\n",
    "### 코스피의 change가 0보다 작으면 절대값에 0.1 곱한 값을 빼주기 위해 함수를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceacc927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kospi_co(x) :  # x는 코스피 y는 변동값\n",
    "    i=0\n",
    "    L=[]\n",
    "\n",
    "    while i < len(x):\n",
    "        if x[i] > 0:\n",
    "            t = x[i]*0.1\n",
    "        else :\n",
    "            t = abs(x[i])*0.1\n",
    "        i +=1\n",
    "        L.append(t)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa77257b",
   "metadata": {},
   "source": [
    "# 테마별 변동률을 이진분류하는 함수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2299cc5f",
   "metadata": {},
   "source": [
    "### 이진분류모델로 만들기 위해 0보다 크면 1, 그 외에는 0으로 리턴하는 함수를 생성했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b73934de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus_minus(x) :\n",
    "    i=0\n",
    "    L=[]\n",
    "\n",
    "    while i < len(x):\n",
    "        if x[i] > 0:\n",
    "            t = 1\n",
    "        else :\n",
    "            t = 0\n",
    "        i +=1\n",
    "        L.append(t)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f72164e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>평균기온</th>\n",
       "      <th>최저기온</th>\n",
       "      <th>최고기온</th>\n",
       "      <th>강수계속시간</th>\n",
       "      <th>10분최다강수</th>\n",
       "      <th>1시간최다강수</th>\n",
       "      <th>일강수</th>\n",
       "      <th>최대순간풍속</th>\n",
       "      <th>최대풍속</th>\n",
       "      <th>평균풍속</th>\n",
       "      <th>...</th>\n",
       "      <th>소형증발량</th>\n",
       "      <th>안개계속시간</th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "      <th>kospi_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.3</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030136</td>\n",
       "      <td>-0.020502</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>-0.119001</td>\n",
       "      <td>0.054689</td>\n",
       "      <td>0.031705</td>\n",
       "      <td>-0.007652</td>\n",
       "      <td>0.0301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>2.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023748</td>\n",
       "      <td>-0.015360</td>\n",
       "      <td>-0.096321</td>\n",
       "      <td>-0.118948</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>-0.025857</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>-0.0687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            평균기온  최저기온  최고기온  강수계속시간  10분최다강수  1시간최다강수   일강수  최대순간풍속  최대풍속  \\\n",
       "Date                                                                         \n",
       "2000-01-04   0.3  -4.3   4.3     0.0      0.0      0.0   0.0     4.5   3.0   \n",
       "2000-01-05   2.8   0.1   4.6    13.9      0.0      0.0  18.4     9.1   5.2   \n",
       "\n",
       "            평균풍속  ...  소형증발량  안개계속시간  겨울_change  도시가스_change  여행_change  \\\n",
       "Date              ...                                                     \n",
       "2000-01-04   1.7  ...    0.7     0.0   0.030136    -0.020502   0.100968   \n",
       "2000-01-05   3.2  ...    1.7     0.0   0.023748    -0.015360  -0.096321   \n",
       "\n",
       "            인터넷 대표주_change  제습기_change  태양광에너지_change  태풍 및 장마_change  \\\n",
       "Date                                                                    \n",
       "2000-01-04       -0.119001    0.054689       0.031705       -0.007652   \n",
       "2000-01-05       -0.118948    0.018182      -0.025857       -0.020016   \n",
       "\n",
       "            kospi_change  \n",
       "Date                      \n",
       "2000-01-04        0.0301  \n",
       "2000-01-05       -0.0687  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbdc7828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['평균기온', '최저기온', '최고기온', '강수계속시간', '10분최다강수', '1시간최다강수', '일강수', '최대순간풍속',\n",
       "       '최대풍속', '평균풍속', '평균이슬점온도', '최소상대습도', '평균상대습도', '평균현지기압', '최고해면기압',\n",
       "       '최저해면기압', '평균해면기압', '가조시간', '합계일조시간', '1시간최다일사량', '합계일사량', '최심신적설',\n",
       "       '최심적설', '3시간신적설', '평균전운량', '평균중하층운량', '평균지면온도', '평균10cm지중온도',\n",
       "       '평균30cm지중온도', '0.5m지중온도', '1.5m지중온도', '3m지중온도', '대형증발량', '소형증발량',\n",
       "       '안개계속시간', '겨울_change', '도시가스_change', '여행_change', '인터넷 대표주_change',\n",
       "       '제습기_change', '태양광에너지_change', '태풍 및 장마_change', 'kospi_change'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41b17632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 표준화 함수 생성\n",
    "def standards(x):\n",
    "    return (x - x.mean())/(x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f65251b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40ffb15a",
   "metadata": {},
   "source": [
    "# 1. 테마별 지수 데이터와 날씨의 관계 분석\n",
    "- 분석기간 : 2000-01 ~ 2021-10\n",
    "- 테스트 데이터 : 2000-01 ~ 2019-12\n",
    "- 실제 시험 데이터 : 2020-01 ~ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2171834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = total_df.loc[:,'겨울_change':'태풍 및 장마_change']\n",
    "x1 = total_df.iloc[:, :-8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ada0ee0",
   "metadata": {},
   "source": [
    "# 데이터 이진변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "989599c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y1.columns)):\n",
    "    y1.iloc[:,i] = plus_minus(y1.iloc[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bba886",
   "metadata": {},
   "source": [
    "## Case 1 : X를 날씨, y를 각 테마별 변동률로 설정하여 모델을 학습.\n",
    "## 변동률은 0보다 크면 1, 0보다 작으면 0으로 이진분류로 분류함.\n",
    "## 사용모델 : \n",
    "### DecisionTreeClassifier\n",
    "### LogisticRegression\n",
    "### KNeighborsClassifier\n",
    "### naive_bayes\n",
    "### RandomForestClassifier\n",
    "### VotingClassifier\n",
    "   \n",
    "## 2019-12-31 이전 데이터를 학습 및 평가용으로 그 이후 데이터를 \n",
    "## 실제 데이터에 적용을 하기 위해 아래와 같이 나누었다.\n",
    "\n",
    "## x1_tr y1_tr : 모델 학습 및 평가때 쓰이는 데이터, 2019-12-31 이전\n",
    "## x1_te, y1_te : 학습된 모델을 실제 데이터에 투입하여 확인하는 데이터 2020-01-01 이후\n",
    "\n",
    "## 테스트 결과는 ensemble 계열의 모델은 과적합, LogisticRegression은 점수가 낮게 나왔다.\n",
    "\n",
    "## 모델의 설명력을 올리기 위해 Case2에서 코스피의 변동률을 각 테마에서 빼서 실행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0bfc58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 모형 평가때 쓰이는 데이터\n",
    "x1_tr = x1.loc[:'2020-01-01',:]\n",
    "y1_tr = y1.loc[:'2020-01-01',:]\n",
    "\n",
    "# 실제 평가를 하는 데이터\n",
    "x1_te = x1.loc['2019-12-31':,:]\n",
    "y1_te = y1.loc['2019-12-31':,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2af6e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e536bd9",
   "metadata": {},
   "source": [
    "# case 1 머신러닝 시작\n",
    "- 결정나무, 로지스틱 회귀모델, K_Neighbors, 앙상블(랜덤포레스트, 보팅), 나이브베이즈 사용\n",
    "- X : 날씨 y : 각 테마별 변동률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a13cdccd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================겨울_change==============================1 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.545339412360689\n",
      "LogisticRegression 정확도(테스트셋) : 0.5617408906882592\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5483146067415731\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.5050607287449392\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.48089887640449436\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.6864235055724417\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.4817813765182186\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.5168539325842697\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.4804964539007092\n",
      "GaussianNB 정확도(테스트셋) : 0.4433198380566802\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.451685393258427\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.52834008097166\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5550561797752809\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9541540020263425\n",
      "VotingClassifier 정확도(테스트셋) : 0.5161943319838057\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5213483146067416\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9987335359675785\n",
      "VotingClassifier 정확도(테스트셋) : 0.4939271255060729\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.501123595505618\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.19      0.27       411\n",
      "           1       0.59      0.82      0.69       577\n",
      "\n",
      "    accuracy                           0.56       988\n",
      "   macro avg       0.51      0.51      0.48       988\n",
      "weighted avg       0.53      0.56      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.52      0.47       411\n",
      "           1       0.59      0.49      0.54       577\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.50       988\n",
      "weighted avg       0.52      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.42      0.40       411\n",
      "           1       0.56      0.53      0.54       577\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.47      0.47      0.47       988\n",
      "weighted avg       0.49      0.48      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.83      0.55       411\n",
      "           1       0.58      0.17      0.26       577\n",
      "\n",
      "    accuracy                           0.44       988\n",
      "   macro avg       0.50      0.50      0.41       988\n",
      "weighted avg       0.51      0.44      0.38       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.38      0.40       411\n",
      "           1       0.59      0.64      0.61       577\n",
      "\n",
      "    accuracy                           0.53       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.52      0.53      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.44      0.43       411\n",
      "           1       0.59      0.57      0.58       577\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.52      0.52      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.51      0.45       411\n",
      "           1       0.58      0.49      0.53       577\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.50      0.50      0.49       988\n",
      "weighted avg       0.51      0.49      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "=================================== 1 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================도시가스_change==============================2 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5255825734549139\n",
      "LogisticRegression 정확도(테스트셋) : 0.5030364372469636\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.4314606741573034\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.46356275303643724\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.5056179775280899\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.686676798378926\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.48279352226720645\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.4943820224719101\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5172239108409321\n",
      "GaussianNB 정확도(테스트셋) : 0.4868421052631579\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.503370786516854\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5040485829959515\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.46741573033707867\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9136271529888551\n",
      "VotingClassifier 정확도(테스트셋) : 0.49898785425101216\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.47191011235955055\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.997467071935157\n",
      "VotingClassifier 정확도(테스트셋) : 0.4757085020242915\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4966292134831461\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.46      0.46       453\n",
      "           1       0.54      0.54      0.54       535\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.47      0.45       453\n",
      "           1       0.51      0.46      0.48       535\n",
      "\n",
      "    accuracy                           0.46       988\n",
      "   macro avg       0.46      0.46      0.46       988\n",
      "weighted avg       0.47      0.46      0.46       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.48      0.46       453\n",
      "           1       0.52      0.48      0.50       535\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.48      0.48      0.48       988\n",
      "weighted avg       0.49      0.48      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.57      0.50       453\n",
      "           1       0.53      0.42      0.47       535\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.50      0.49      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.49      0.48       453\n",
      "           1       0.54      0.51      0.53       535\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.51      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.51      0.48       453\n",
      "           1       0.54      0.49      0.51       535\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.49      0.46       453\n",
      "           1       0.52      0.47      0.49       535\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.48      0.48      0.48       988\n",
      "weighted avg       0.48      0.48      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "=================================== 2 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================여행_change==============================3 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5311550151975684\n",
      "LogisticRegression 정확도(테스트셋) : 0.5263157894736842\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5168539325842697\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.5131578947368421\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.4943820224719101\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.6887031408308004\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.4898785425101215\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.4651685393258427\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5240628166160081\n",
      "GaussianNB 정확도(테스트셋) : 0.5273279352226721\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.48089887640449436\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5101214574898786\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5213483146067416\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.8814589665653495\n",
      "VotingClassifier 정확도(테스트셋) : 0.5273279352226721\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.49213483146067416\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9969604863221885\n",
      "VotingClassifier 정확도(테스트셋) : 0.5172064777327935\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4696629213483146\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.41      0.46       478\n",
      "           1       0.53      0.64      0.58       510\n",
      "\n",
      "    accuracy                           0.53       988\n",
      "   macro avg       0.52      0.52      0.52       988\n",
      "weighted avg       0.52      0.53      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50       478\n",
      "           1       0.53      0.53      0.53       510\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.46      0.46       478\n",
      "           1       0.51      0.52      0.51       510\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.62      0.56       478\n",
      "           1       0.55      0.44      0.49       510\n",
      "\n",
      "    accuracy                           0.53       988\n",
      "   macro avg       0.53      0.53      0.52       988\n",
      "weighted avg       0.53      0.53      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.45      0.47       478\n",
      "           1       0.52      0.57      0.55       510\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.51      0.51       478\n",
      "           1       0.54      0.54      0.54       510\n",
      "\n",
      "    accuracy                           0.53       988\n",
      "   macro avg       0.53      0.53      0.53       988\n",
      "weighted avg       0.53      0.53      0.53       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50       478\n",
      "           1       0.53      0.53      0.53       510\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.52      0.52      0.52       988\n",
      "weighted avg       0.52      0.52      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "=================================== 3 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================인터넷 대표주_change==============================4 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5301418439716312\n",
      "LogisticRegression 정확도(테스트셋) : 0.49291497975708504\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5325842696629214\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.49696356275303644\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.5123595505617977\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.693515704154002\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.48785425101214575\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.4898876404494382\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5040526849037488\n",
      "GaussianNB 정확도(테스트셋) : 0.5182186234817814\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.48314606741573035\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5020242914979757\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.4966292134831461\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9121073961499493\n",
      "VotingClassifier 정확도(테스트셋) : 0.4949392712550607\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5168539325842697\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9883485309017224\n",
      "VotingClassifier 정확도(테스트셋) : 0.49696356275303644\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4966292134831461\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50       504\n",
      "           1       0.48      0.48      0.48       484\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.50      0.50       504\n",
      "           1       0.49      0.50      0.49       484\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50       504\n",
      "           1       0.48      0.48      0.48       484\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.94      0.67       504\n",
      "           1       0.56      0.08      0.13       484\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.54      0.51      0.40       988\n",
      "weighted avg       0.54      0.52      0.41       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.52      0.52       504\n",
      "           1       0.49      0.48      0.49       484\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.64      0.56       504\n",
      "           1       0.48      0.35      0.40       484\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.48       988\n",
      "weighted avg       0.49      0.49      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.65      0.57       504\n",
      "           1       0.48      0.34      0.40       484\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.49      0.49      0.48       988\n",
      "weighted avg       0.49      0.50      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "=================================== 4 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================제습기_change==============================5 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5349544072948328\n",
      "LogisticRegression 정확도(테스트셋) : 0.5253036437246964\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5483146067415731\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.4868421052631579\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.5258426966292135\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.7001013171225937\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.5121457489878543\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.5056179775280899\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5048125633232016\n",
      "GaussianNB 정확도(테스트셋) : 0.47874493927125505\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.47415730337078654\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5101214574898786\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5438202247191011\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9146403242147924\n",
      "VotingClassifier 정확도(테스트셋) : 0.4979757085020243\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5303370786516854\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9901215805471124\n",
      "VotingClassifier 정확도(테스트셋) : 0.4868421052631579\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4764044943820225\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.33      0.39       439\n",
      "           1       0.56      0.68      0.61       549\n",
      "\n",
      "    accuracy                           0.53       988\n",
      "   macro avg       0.51      0.51      0.50       988\n",
      "weighted avg       0.51      0.53      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.46      0.44       439\n",
      "           1       0.54      0.51      0.52       549\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.48      0.48      0.48       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.47      0.46       439\n",
      "           1       0.56      0.55      0.56       549\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.79      0.57       439\n",
      "           1       0.58      0.23      0.33       549\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.51      0.51      0.45       988\n",
      "weighted avg       0.52      0.48      0.44       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.42      0.43       439\n",
      "           1       0.56      0.58      0.57       549\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.48      0.46       439\n",
      "           1       0.55      0.51      0.53       549\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.56      0.49       439\n",
      "           1       0.55      0.43      0.48       549\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.50      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "=================================== 5 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================태양광에너지_change==============================6 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5615501519756839\n",
      "LogisticRegression 정확도(테스트셋) : 0.562753036437247\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5146067415730337\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.5192307692307693\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.5146067415730337\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.7094731509625126\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.5111336032388664\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.5123595505617977\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.47391084093211755\n",
      "GaussianNB 정확도(테스트셋) : 0.46558704453441296\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.4157303370786517\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5435222672064778\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5415730337078651\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9637791286727457\n",
      "VotingClassifier 정확도(테스트셋) : 0.5404858299595142\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5191011235955056\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9949341438703141\n",
      "VotingClassifier 정확도(테스트셋) : 0.5344129554655871\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5168539325842697\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.10      0.16       420\n",
      "           1       0.58      0.91      0.70       568\n",
      "\n",
      "    accuracy                           0.56       988\n",
      "   macro avg       0.51      0.50      0.43       988\n",
      "weighted avg       0.52      0.56      0.47       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.49      0.46       420\n",
      "           1       0.59      0.54      0.56       568\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.51      0.52      0.51       988\n",
      "weighted avg       0.53      0.52      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.42      0.42       420\n",
      "           1       0.57      0.58      0.58       568\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.88      0.58       420\n",
      "           1       0.64      0.16      0.26       568\n",
      "\n",
      "    accuracy                           0.47       988\n",
      "   macro avg       0.54      0.52      0.42       988\n",
      "weighted avg       0.55      0.47      0.40       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.35      0.39       420\n",
      "           1       0.59      0.69      0.63       568\n",
      "\n",
      "    accuracy                           0.54       988\n",
      "   macro avg       0.52      0.52      0.51       988\n",
      "weighted avg       0.53      0.54      0.53       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.40      0.43       420\n",
      "           1       0.59      0.64      0.62       568\n",
      "\n",
      "    accuracy                           0.54       988\n",
      "   macro avg       0.52      0.52      0.52       988\n",
      "weighted avg       0.53      0.54      0.54       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.50      0.48       420\n",
      "           1       0.60      0.56      0.58       568\n",
      "\n",
      "    accuracy                           0.53       988\n",
      "   macro avg       0.53      0.53      0.53       988\n",
      "weighted avg       0.54      0.53      0.54       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "=================================== 6 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================태풍 및 장마_change==============================7 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5460992907801419\n",
      "LogisticRegression 정확도(테스트셋) : 0.5101214574898786\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5146067415730337\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.4898785425101215\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.48314606741573035\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.6957953394123607\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.5151821862348178\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.48089887640449436\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.49822695035460995\n",
      "GaussianNB 정확도(테스트셋) : 0.47874493927125505\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.49213483146067416\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5151821862348178\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5235955056179775\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.930597771023303\n",
      "VotingClassifier 정확도(테스트셋) : 0.4949392712550607\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5078651685393258\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9941742654508612\n",
      "VotingClassifier 정확도(테스트셋) : 0.4939271255060729\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4898876404494382\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.29      0.35       444\n",
      "           1       0.54      0.69      0.61       544\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.49      0.49      0.48       988\n",
      "weighted avg       0.49      0.51      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.45      0.44       444\n",
      "           1       0.54      0.53      0.53       544\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.47      0.46       444\n",
      "           1       0.56      0.56      0.56       544\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.52      0.52      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.80      0.58       444\n",
      "           1       0.57      0.22      0.31       544\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.51      0.51      0.45       988\n",
      "weighted avg       0.52      0.48      0.43       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.36      0.40       444\n",
      "           1       0.55      0.64      0.59       544\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.51      0.52      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.45      0.45       444\n",
      "           1       0.54      0.53      0.54       544\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.50      0.49      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.51      0.48       444\n",
      "           1       0.55      0.48      0.51       544\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.50      0.50      0.49       988\n",
      "weighted avg       0.50      0.49      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "=================================== 7 page ===================================\n",
      "\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for i in range(len(y1.columns)) : \n",
    "\n",
    "    # 훈련용 데이터(X_tr)을 train_test_split으로 나누기\n",
    "    \n",
    "#   from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x1_tr, y1_tr.iloc[:,i], test_size = 0.2, random_state = 1)\n",
    "\n",
    "    # 데이터 표준화\n",
    "#     from sklearn.preprocessing import StandardScaler\n",
    "    stds = StandardScaler()\n",
    "    stds.fit(X_train)\n",
    "    X_train_std = stds.transform(X_train)\n",
    "    X_test_std = stds.transform(X_test)\n",
    "    X_ftest_std = stds.transform(x1_te)\n",
    "\n",
    "    # 분석 시작\n",
    "#     from sklearn.tree import DecisionTreeClassifier\n",
    "#     from sklearn.linear_model import LogisticRegression\n",
    "#     from sklearn.neighbors import KNeighborsClassifier\n",
    "#     from sklearn.naive_bayes import GaussianNB\n",
    "#     from sklearn.ensemble import RandomForestClassifier\n",
    "#     from sklearn.ensemble import VotingClassifier\n",
    "#     from sklearn.metrics import precision_score\n",
    "    \n",
    "    # 모델 생성\n",
    "    log = LogisticRegression()\n",
    "    knn = KNeighborsClassifier()\n",
    "    tree = DecisionTreeClassifier()\n",
    "    gnb = GaussianNB()\n",
    "    rfc = RandomForestClassifier()\n",
    "         \n",
    "    hvot = VotingClassifier(estimators = [('log', log), ('rfc', rfc), ('knn', knn), \\\n",
    "                        ('tree',tree),('gnb', gnb)], voting='hard')\n",
    "\n",
    "    svot = VotingClassifier(estimators = [('log', log), ('rfc', rfc), ('knn', knn), \\\n",
    "                        ('tree',tree),('gnb', gnb)], voting='soft')\n",
    "    \n",
    "    models = [log, tree, knn, gnb, rfc, hvot, svot]\n",
    "    \n",
    "    print('==================================={}=============================={} page'.format(y1.columns[i], i+1))\n",
    "    \n",
    "    y_fin = y1_te.iloc[:,i] # 최종 모형 평가 변수\n",
    "    \n",
    "    for m in models :\n",
    "        m.fit(X_train, y_train)\n",
    "        \n",
    "        # 데이터 예측\n",
    "        preds = m.predict(X_test) \n",
    "        \n",
    "        # 정확도 평가\n",
    "        accuracy0 = m.score(X_train, y_train)\n",
    "        accuracy1 = m.score(X_test, y_test)\n",
    "        accuracy2 = m.score(x1_te, y_fin)\n",
    "        \n",
    "        print(m.__class__.__name__, '정확도(훈련셋) :' , accuracy0)\n",
    "        print(m.__class__.__name__, '정확도(테스트셋) :' , accuracy1)\n",
    "        print(m.__class__.__name__, '정확도(실제 테스트셋) :' , accuracy2)\n",
    "        \n",
    "        print('-'*80)\n",
    "\n",
    "    # 분류 레포트\n",
    "\n",
    "#     from sklearn.metrics import classification_report\n",
    "    \n",
    "    y_fin = y1_te.iloc[:,i]                \n",
    "    \n",
    "    for m in models :\n",
    "        preds0 = m.predict(X_test) # 데이터 예측\n",
    "        preds1 = m.predict(x1_te)\n",
    "        class_report1 = classification_report(y_test, preds0)\n",
    "        class_report2 = classification_report(y_fin, preds1)\n",
    "        \n",
    "        print(m.__class__.__name__ , '훈련 데이터 테스트셋 \\n',class_report1)\n",
    "        print('-'*80)\n",
    "#         print(m.__class__.__name__ , '실제 데이터 테스트셋 \\n',class_report2)\n",
    "    \n",
    "    print('=================================== {} page ===================================\\n\\n\\n '.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "816ec6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4023f96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da9fc1bd",
   "metadata": {},
   "source": [
    "# 2. 코스피 지수 보정값을 적용한 테마별 지수 데이터와 날씨의 관계 분석\n",
    "- 분석기간 : 2000-01 ~ 2021-10\n",
    "- 테스트 데이터 : 2000-01 ~ 2019-12\n",
    "- 실제 시험 데이터 : 2020-01 ~ \n",
    "- 코스피 지수가 실제로 영향을 주기 때문에 코스피지수에 0.1을 곱한 후 값을 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c6f02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kospi_co(x) :  # x는 코스피 y는 변동값\n",
    "    i=0\n",
    "    L=[]\n",
    "\n",
    "    while i < len(x):\n",
    "        if x[i] > 0:\n",
    "            t = x[i]*0.05\n",
    "        else :\n",
    "            t = abs(x[i])*0.05\n",
    "        i +=1\n",
    "        L.append(t)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29057528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68f4d10c",
   "metadata": {},
   "source": [
    "# 데이터 이진변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d93f49d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "      <th>kospi_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.030136</td>\n",
       "      <td>-0.020502</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>-0.119001</td>\n",
       "      <td>0.054689</td>\n",
       "      <td>0.031705</td>\n",
       "      <td>-0.007652</td>\n",
       "      <td>0.0301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.023748</td>\n",
       "      <td>-0.015360</td>\n",
       "      <td>-0.096321</td>\n",
       "      <td>-0.118948</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>-0.025857</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>-0.0687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>-0.019810</td>\n",
       "      <td>-0.024013</td>\n",
       "      <td>-0.055905</td>\n",
       "      <td>-0.120027</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>-0.026880</td>\n",
       "      <td>-0.045861</td>\n",
       "      <td>-0.0259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.010704</td>\n",
       "      <td>-0.030269</td>\n",
       "      <td>-0.119311</td>\n",
       "      <td>-0.119290</td>\n",
       "      <td>-0.005948</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>-0.0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.059410</td>\n",
       "      <td>-0.007423</td>\n",
       "      <td>0.010749</td>\n",
       "      <td>-0.031333</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>0.0407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            겨울_change  도시가스_change  여행_change  인터넷 대표주_change  제습기_change  \\\n",
       "Date                                                                        \n",
       "2000-01-04   0.030136    -0.020502   0.100968       -0.119001    0.054689   \n",
       "2000-01-05   0.023748    -0.015360  -0.096321       -0.118948    0.018182   \n",
       "2000-01-06  -0.019810    -0.024013  -0.055905       -0.120027    0.037346   \n",
       "2000-01-07   0.010704    -0.030269  -0.119311       -0.119290   -0.005948   \n",
       "2000-01-10   0.003991     0.059410  -0.007423        0.010749   -0.031333   \n",
       "\n",
       "            태양광에너지_change  태풍 및 장마_change  kospi_change  \n",
       "Date                                                     \n",
       "2000-01-04       0.031705       -0.007652        0.0301  \n",
       "2000-01-05      -0.025857       -0.020016       -0.0687  \n",
       "2000-01-06      -0.026880       -0.045861       -0.0259  \n",
       "2000-01-07       0.006642        0.017759       -0.0126  \n",
       "2000-01-10       0.002046        0.006444        0.0407  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = total_df.loc[:,'겨울_change':]\n",
    "x2 = total_df.iloc[:, :-8]\n",
    "y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e33b39a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "      <th>kospi_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.030136</td>\n",
       "      <td>-0.020502</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>-0.119001</td>\n",
       "      <td>0.054689</td>\n",
       "      <td>0.031705</td>\n",
       "      <td>-0.007652</td>\n",
       "      <td>0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.023748</td>\n",
       "      <td>-0.015360</td>\n",
       "      <td>-0.096321</td>\n",
       "      <td>-0.118948</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>-0.025857</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>0.003435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>-0.019810</td>\n",
       "      <td>-0.024013</td>\n",
       "      <td>-0.055905</td>\n",
       "      <td>-0.120027</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>-0.026880</td>\n",
       "      <td>-0.045861</td>\n",
       "      <td>0.001295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.010704</td>\n",
       "      <td>-0.030269</td>\n",
       "      <td>-0.119311</td>\n",
       "      <td>-0.119290</td>\n",
       "      <td>-0.005948</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>0.000630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.059410</td>\n",
       "      <td>-0.007423</td>\n",
       "      <td>0.010749</td>\n",
       "      <td>-0.031333</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>0.002035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            겨울_change  도시가스_change  여행_change  인터넷 대표주_change  제습기_change  \\\n",
       "Date                                                                        \n",
       "2000-01-04   0.030136    -0.020502   0.100968       -0.119001    0.054689   \n",
       "2000-01-05   0.023748    -0.015360  -0.096321       -0.118948    0.018182   \n",
       "2000-01-06  -0.019810    -0.024013  -0.055905       -0.120027    0.037346   \n",
       "2000-01-07   0.010704    -0.030269  -0.119311       -0.119290   -0.005948   \n",
       "2000-01-10   0.003991     0.059410  -0.007423        0.010749   -0.031333   \n",
       "\n",
       "            태양광에너지_change  태풍 및 장마_change  kospi_change  \n",
       "Date                                                     \n",
       "2000-01-04       0.031705       -0.007652      0.001505  \n",
       "2000-01-05      -0.025857       -0.020016      0.003435  \n",
       "2000-01-06      -0.026880       -0.045861      0.001295  \n",
       "2000-01-07       0.006642        0.017759      0.000630  \n",
       "2000-01-10       0.002046        0.006444      0.002035  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2['kospi_change'] = kospi_co(y2['kospi_change'])\n",
    "y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f300c014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ab9f468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "      <th>kospi_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.028631</td>\n",
       "      <td>-0.022007</td>\n",
       "      <td>0.099463</td>\n",
       "      <td>-0.120506</td>\n",
       "      <td>0.053184</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>-0.009157</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.020313</td>\n",
       "      <td>-0.018795</td>\n",
       "      <td>-0.099756</td>\n",
       "      <td>-0.122383</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>-0.029292</td>\n",
       "      <td>-0.023451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>-0.021105</td>\n",
       "      <td>-0.025308</td>\n",
       "      <td>-0.057200</td>\n",
       "      <td>-0.121322</td>\n",
       "      <td>0.036051</td>\n",
       "      <td>-0.028175</td>\n",
       "      <td>-0.047156</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.010074</td>\n",
       "      <td>-0.030899</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.119920</td>\n",
       "      <td>-0.006578</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.017129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.057375</td>\n",
       "      <td>-0.009458</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.033368</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            겨울_change  도시가스_change  여행_change  인터넷 대표주_change  제습기_change  \\\n",
       "Date                                                                        \n",
       "2000-01-04   0.028631    -0.022007   0.099463       -0.120506    0.053184   \n",
       "2000-01-05   0.020313    -0.018795  -0.099756       -0.122383    0.014747   \n",
       "2000-01-06  -0.021105    -0.025308  -0.057200       -0.121322    0.036051   \n",
       "2000-01-07   0.010074    -0.030899  -0.119941       -0.119920   -0.006578   \n",
       "2000-01-10   0.001956     0.057375  -0.009458        0.008714   -0.033368   \n",
       "\n",
       "            태양광에너지_change  태풍 및 장마_change  kospi_change  \n",
       "Date                                                     \n",
       "2000-01-04       0.030200       -0.009157           0.0  \n",
       "2000-01-05      -0.029292       -0.023451           0.0  \n",
       "2000-01-06      -0.028175       -0.047156           0.0  \n",
       "2000-01-07       0.006012        0.017129           0.0  \n",
       "2000-01-10       0.000011        0.004409           0.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 테마별 변동률 - 보정된 코스피 변동률\n",
    "\n",
    "i = 0\n",
    "while i < 8:\n",
    "    print(i, end = ' ')\n",
    "    y2.iloc[:,i] = y2.iloc[:,i] - y2['kospi_change']\n",
    "    i +=1\n",
    "\n",
    "y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58dc3337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.028631</td>\n",
       "      <td>-0.022007</td>\n",
       "      <td>0.099463</td>\n",
       "      <td>-0.120506</td>\n",
       "      <td>0.053184</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>-0.009157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.020313</td>\n",
       "      <td>-0.018795</td>\n",
       "      <td>-0.099756</td>\n",
       "      <td>-0.122383</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>-0.029292</td>\n",
       "      <td>-0.023451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>-0.021105</td>\n",
       "      <td>-0.025308</td>\n",
       "      <td>-0.057200</td>\n",
       "      <td>-0.121322</td>\n",
       "      <td>0.036051</td>\n",
       "      <td>-0.028175</td>\n",
       "      <td>-0.047156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.010074</td>\n",
       "      <td>-0.030899</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.119920</td>\n",
       "      <td>-0.006578</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.017129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.057375</td>\n",
       "      <td>-0.009458</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.033368</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.004409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            겨울_change  도시가스_change  여행_change  인터넷 대표주_change  제습기_change  \\\n",
       "Date                                                                        \n",
       "2000-01-04   0.028631    -0.022007   0.099463       -0.120506    0.053184   \n",
       "2000-01-05   0.020313    -0.018795  -0.099756       -0.122383    0.014747   \n",
       "2000-01-06  -0.021105    -0.025308  -0.057200       -0.121322    0.036051   \n",
       "2000-01-07   0.010074    -0.030899  -0.119941       -0.119920   -0.006578   \n",
       "2000-01-10   0.001956     0.057375  -0.009458        0.008714   -0.033368   \n",
       "\n",
       "            태양광에너지_change  태풍 및 장마_change  \n",
       "Date                                       \n",
       "2000-01-04       0.030200       -0.009157  \n",
       "2000-01-05      -0.029292       -0.023451  \n",
       "2000-01-06      -0.028175       -0.047156  \n",
       "2000-01-07       0.006012        0.017129  \n",
       "2000-01-10       0.000011        0.004409  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y2.iloc[:,0:7]\n",
    "y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64e0f459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            겨울_change  도시가스_change  여행_change  인터넷 대표주_change  제습기_change  \\\n",
       "Date                                                                        \n",
       "2000-01-04          1            0          1               0           1   \n",
       "2000-01-05          1            0          0               0           1   \n",
       "2000-01-06          0            0          0               0           1   \n",
       "2000-01-07          1            0          0               0           0   \n",
       "2000-01-10          1            1          0               1           0   \n",
       "\n",
       "            태양광에너지_change  태풍 및 장마_change  \n",
       "Date                                       \n",
       "2000-01-04              1               0  \n",
       "2000-01-05              0               0  \n",
       "2000-01-06              0               0  \n",
       "2000-01-07              1               1  \n",
       "2000-01-10              1               1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이진분류로 만듦\n",
    "for i in range(len(y2.columns)):\n",
    "    y2.iloc[:,i] = plus_minus(y2.iloc[:,i])\n",
    "y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20793980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 모형 평가때 쓰이는 데이터\n",
    "x2_tr = x2.loc[:'2020-01-01',:]\n",
    "y2_tr = y2.loc[:'2020-01-01',:]\n",
    "\n",
    "# 실제 평가를 하는 데이터\n",
    "x2_te = x2.loc['2019-12-31':,:]\n",
    "y2_te = y2.loc['2019-12-31':,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5640aec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            겨울_change  도시가스_change  여행_change  인터넷 대표주_change  제습기_change  \\\n",
       "Date                                                                        \n",
       "2000-01-04          1            0          1               0           1   \n",
       "2000-01-05          1            0          0               0           1   \n",
       "2000-01-06          0            0          0               0           1   \n",
       "2000-01-07          1            0          0               0           0   \n",
       "2000-01-10          1            1          0               1           0   \n",
       "\n",
       "            태양광에너지_change  태풍 및 장마_change  \n",
       "Date                                       \n",
       "2000-01-04              1               0  \n",
       "2000-01-05              0               0  \n",
       "2000-01-06              0               0  \n",
       "2000-01-07              1               1  \n",
       "2000-01-10              1               1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "881b4043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['평균기온', '최저기온', '최고기온', '강수계속시간', '10분최다강수', '1시간최다강수', '일강수', '최대순간풍속',\n",
       "       '최대풍속', '평균풍속', '평균이슬점온도', '최소상대습도', '평균상대습도', '평균현지기압', '최고해면기압',\n",
       "       '최저해면기압', '평균해면기압', '가조시간', '합계일조시간', '1시간최다일사량', '합계일사량', '최심신적설',\n",
       "       '최심적설', '3시간신적설', '평균전운량', '평균중하층운량', '평균지면온도', '평균10cm지중온도',\n",
       "       '평균30cm지중온도', '0.5m지중온도', '1.5m지중온도', '3m지중온도', '대형증발량', '소형증발량',\n",
       "       '안개계속시간', '겨울_change', '도시가스_change', '여행_change', '인터넷 대표주_change',\n",
       "       '제습기_change', '태양광에너지_change', '태풍 및 장마_change', 'kospi_change'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be854384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa97c5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f7b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4cee610",
   "metadata": {},
   "source": [
    "## Case 2 : X를 날씨, y를 각 테마별 변동률로 설정하여 모델을 학습.\n",
    "## 사용모델 : \n",
    "### DecisionTreeClassifier\n",
    "### LogisticRegression\n",
    "### KNeighborsClassifier\n",
    "### naive_bayes\n",
    "### RandomForestClassifier\n",
    "### VotingClassifier\n",
    "   \n",
    "## 2019-12-31 이전 데이터를 학습 및 평가용으로 그 이후 데이터를 \n",
    "## 실제 데이터에 적용을 하기 위해 아래와 같이 나누었다.\n",
    "\n",
    "## x2_tr, y2_tr : 모델 학습 및 평가때 쓰이는 데이터, 2019-12-31 이전\n",
    "## x2_te, y2_te : 학습된 모델을 실제 데이터에 투입하여 확인하는 데이터 2020-01-01 이후\n",
    "\n",
    "## 테스트 결과는 case1과 크게 다르지 않게 ensemble 계열의 모델은 과적합, LogisticRegression은 점수가 낮게 나왔다.\n",
    "\n",
    "## 모델의 설명력을 올리기 위해 Case3에서 코스피의 변동률을 각 테마 변동률의 차를 표준화 시켜서 학습을 실행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0afdce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030238c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a9871d1",
   "metadata": {},
   "source": [
    "# Case2 분석시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "127d1949",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================겨울_change==============================1 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5309017223910841\n",
      "LogisticRegression 정확도(테스트셋) : 0.5121457489878543\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.4943820224719101\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.4959514170040486\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.5191011235955056\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.6821175278622087\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.48279352226720645\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.5191011235955056\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.4959473150962513\n",
      "GaussianNB 정확도(테스트셋) : 0.4433198380566802\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.45393258426966293\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5242914979757085\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5258426966292135\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9457953394123607\n",
      "VotingClassifier 정확도(테스트셋) : 0.4807692307692308\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4966292134831461\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9984802431610942\n",
      "VotingClassifier 정확도(테스트셋) : 0.4757085020242915\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5213483146067416\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.27      0.32       425\n",
      "           1       0.56      0.69      0.62       563\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.48      0.48      0.47       988\n",
      "weighted avg       0.49      0.51      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.25      0.31       201\n",
      "           1       0.53      0.69      0.60       244\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.47      0.47      0.46       445\n",
      "weighted avg       0.47      0.49      0.47       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.47      0.45       425\n",
      "           1       0.56      0.51      0.54       563\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.49      0.48       201\n",
      "           1       0.56      0.54      0.55       244\n",
      "\n",
      "    accuracy                           0.52       445\n",
      "   macro avg       0.52      0.52      0.52       445\n",
      "weighted avg       0.52      0.52      0.52       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.46      0.43       425\n",
      "           1       0.55      0.50      0.52       563\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.48      0.48      0.48       988\n",
      "weighted avg       0.49      0.48      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.47      0.47       201\n",
      "           1       0.56      0.56      0.56       244\n",
      "\n",
      "    accuracy                           0.52       445\n",
      "   macro avg       0.51      0.51      0.51       445\n",
      "weighted avg       0.52      0.52      0.52       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.89      0.58       425\n",
      "           1       0.56      0.11      0.18       563\n",
      "\n",
      "    accuracy                           0.44       988\n",
      "   macro avg       0.49      0.50      0.38       988\n",
      "weighted avg       0.50      0.44      0.35       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.84      0.58       201\n",
      "           1       0.51      0.14      0.21       244\n",
      "\n",
      "    accuracy                           0.45       445\n",
      "   macro avg       0.48      0.49      0.40       445\n",
      "weighted avg       0.48      0.45      0.38       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.49      0.47       425\n",
      "           1       0.59      0.55      0.57       563\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.52      0.52      0.52       988\n",
      "weighted avg       0.53      0.52      0.53       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.50      0.49       201\n",
      "           1       0.57      0.55      0.56       244\n",
      "\n",
      "    accuracy                           0.53       445\n",
      "   macro avg       0.52      0.52      0.52       445\n",
      "weighted avg       0.53      0.53      0.53       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.50      0.45       425\n",
      "           1       0.55      0.47      0.51       563\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.48      0.48      0.48       988\n",
      "weighted avg       0.49      0.48      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.47      0.46       201\n",
      "           1       0.54      0.52      0.53       244\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.49      0.49      0.49       445\n",
      "weighted avg       0.50      0.50      0.50       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.52      0.46       425\n",
      "           1       0.55      0.44      0.49       563\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.48      0.48      0.48       988\n",
      "weighted avg       0.49      0.48      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.50      0.48       201\n",
      "           1       0.57      0.54      0.55       244\n",
      "\n",
      "    accuracy                           0.52       445\n",
      "   macro avg       0.52      0.52      0.52       445\n",
      "weighted avg       0.52      0.52      0.52       445\n",
      "\n",
      "=================================== 1 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================도시가스_change==============================2 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5268490374873354\n",
      "LogisticRegression 정확도(테스트셋) : 0.4949392712550607\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.4314606741573034\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.5192307692307693\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.4898876404494382\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.6876899696048632\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.48279352226720645\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.4786516853932584\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5157041540020263\n",
      "GaussianNB 정확도(테스트셋) : 0.46558704453441296\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.4449438202247191\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5030364372469636\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.4898876404494382\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.8956433637284701\n",
      "VotingClassifier 정확도(테스트셋) : 0.4979757085020243\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.43820224719101125\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9979736575481256\n",
      "VotingClassifier 정확도(테스트셋) : 0.507085020242915\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.48764044943820223\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.72      0.58       471\n",
      "           1       0.53      0.29      0.38       517\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.51      0.50      0.48       988\n",
      "weighted avg       0.51      0.49      0.47       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.89      0.58       196\n",
      "           1       0.45      0.07      0.12       249\n",
      "\n",
      "    accuracy                           0.43       445\n",
      "   macro avg       0.44      0.48      0.35       445\n",
      "weighted avg       0.44      0.43      0.32       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50       471\n",
      "           1       0.54      0.54      0.54       517\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.52      0.52      0.52       988\n",
      "weighted avg       0.52      0.52      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.52      0.47       196\n",
      "           1       0.55      0.47      0.51       249\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.49      0.49      0.49       445\n",
      "weighted avg       0.50      0.49      0.49       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.51      0.48       471\n",
      "           1       0.51      0.46      0.48       517\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.48      0.48      0.48       988\n",
      "weighted avg       0.48      0.48      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.47      0.44       196\n",
      "           1       0.54      0.48      0.51       249\n",
      "\n",
      "    accuracy                           0.48       445\n",
      "   macro avg       0.48      0.48      0.48       445\n",
      "weighted avg       0.49      0.48      0.48       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.72      0.56       471\n",
      "           1       0.48      0.23      0.31       517\n",
      "\n",
      "    accuracy                           0.47       988\n",
      "   macro avg       0.47      0.48      0.44       988\n",
      "weighted avg       0.47      0.47      0.43       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.67      0.51       196\n",
      "           1       0.51      0.27      0.35       249\n",
      "\n",
      "    accuracy                           0.44       445\n",
      "   macro avg       0.46      0.47      0.43       445\n",
      "weighted avg       0.47      0.44      0.42       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.56      0.52       471\n",
      "           1       0.53      0.45      0.49       517\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.51      0.51      0.50       988\n",
      "weighted avg       0.51      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.56      0.49       196\n",
      "           1       0.56      0.43      0.49       249\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.50      0.50      0.49       445\n",
      "weighted avg       0.50      0.49      0.49       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.69      0.57       471\n",
      "           1       0.53      0.32      0.40       517\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.51      0.51      0.48       988\n",
      "weighted avg       0.51      0.50      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.70      0.52       196\n",
      "           1       0.50      0.23      0.32       249\n",
      "\n",
      "    accuracy                           0.44       445\n",
      "   macro avg       0.46      0.47      0.42       445\n",
      "weighted avg       0.46      0.44      0.41       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.54      0.51       471\n",
      "           1       0.53      0.48      0.51       517\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.52      0.47       196\n",
      "           1       0.55      0.47      0.50       249\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.49      0.49      0.49       445\n",
      "weighted avg       0.50      0.49      0.49       445\n",
      "\n",
      "=================================== 2 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================여행_change==============================3 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5309017223910841\n",
      "LogisticRegression 정확도(테스트셋) : 0.5374493927125507\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5078651685393258\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.4979757085020243\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.5056179775280899\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.6904761904761905\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.4868421052631579\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.47191011235955055\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.524822695035461\n",
      "GaussianNB 정확도(테스트셋) : 0.5131578947368421\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.4786516853932584\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.507085020242915\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.48089887640449436\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.8733535967578521\n",
      "VotingClassifier 정확도(테스트셋) : 0.521255060728745\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4696629213483146\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9962006079027356\n",
      "VotingClassifier 정확도(테스트셋) : 0.5121457489878543\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4696629213483146\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.51      0.52       483\n",
      "           1       0.55      0.57      0.56       505\n",
      "\n",
      "    accuracy                           0.54       988\n",
      "   macro avg       0.54      0.54      0.54       988\n",
      "weighted avg       0.54      0.54      0.54       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.62      0.55       213\n",
      "           1       0.54      0.40      0.46       232\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.51      0.51      0.50       445\n",
      "weighted avg       0.51      0.51      0.50       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50       483\n",
      "           1       0.51      0.48      0.50       505\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.54      0.51       213\n",
      "           1       0.53      0.48      0.50       232\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.51      0.51      0.51       445\n",
      "weighted avg       0.51      0.51      0.51       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.47      0.47       483\n",
      "           1       0.50      0.50      0.50       505\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.47      0.46       213\n",
      "           1       0.49      0.47      0.48       232\n",
      "\n",
      "    accuracy                           0.47       445\n",
      "   macro avg       0.47      0.47      0.47       445\n",
      "weighted avg       0.47      0.47      0.47       445\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.64      0.56       483\n",
      "           1       0.53      0.39      0.45       505\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.52      0.52      0.51       988\n",
      "weighted avg       0.52      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.67      0.55       213\n",
      "           1       0.50      0.30      0.38       232\n",
      "\n",
      "    accuracy                           0.48       445\n",
      "   macro avg       0.48      0.49      0.46       445\n",
      "weighted avg       0.49      0.48      0.46       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.48      0.49       483\n",
      "           1       0.52      0.53      0.52       505\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.52      0.49       213\n",
      "           1       0.50      0.44      0.47       232\n",
      "\n",
      "    accuracy                           0.48       445\n",
      "   macro avg       0.48      0.48      0.48       445\n",
      "weighted avg       0.48      0.48      0.48       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.57      0.54       483\n",
      "           1       0.54      0.48      0.51       505\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.52      0.52      0.52       988\n",
      "weighted avg       0.52      0.52      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.61      0.52       213\n",
      "           1       0.49      0.34      0.40       232\n",
      "\n",
      "    accuracy                           0.47       445\n",
      "   macro avg       0.47      0.48      0.46       445\n",
      "weighted avg       0.47      0.47      0.46       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.53      0.52       483\n",
      "           1       0.52      0.49      0.51       505\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.57      0.51       213\n",
      "           1       0.49      0.38      0.43       232\n",
      "\n",
      "    accuracy                           0.47       445\n",
      "   macro avg       0.47      0.47      0.47       445\n",
      "weighted avg       0.47      0.47      0.47       445\n",
      "\n",
      "=================================== 3 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================인터넷 대표주_change==============================4 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.524822695035461\n",
      "LogisticRegression 정확도(테스트셋) : 0.5111336032388664\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5235955056179775\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.5121457489878543\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.503370786516854\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.6937689969604863\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.4939271255060729\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.4786516853932584\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5124113475177305\n",
      "GaussianNB 정확도(테스트셋) : 0.5253036437246964\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.4898876404494382\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.4949392712550607\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.49213483146067416\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.8875379939209727\n",
      "VotingClassifier 정확도(테스트셋) : 0.507085020242915\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.49213483146067416\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9868287740628167\n",
      "VotingClassifier 정확도(테스트셋) : 0.5040485829959515\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4898876404494382\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.68      0.59       511\n",
      "           1       0.49      0.34      0.40       477\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.49       988\n",
      "weighted avg       0.51      0.51      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.77      0.60       210\n",
      "           1       0.60      0.30      0.40       235\n",
      "\n",
      "    accuracy                           0.52       445\n",
      "   macro avg       0.55      0.54      0.50       445\n",
      "weighted avg       0.55      0.52      0.50       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54       511\n",
      "           1       0.49      0.47      0.48       477\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.47      0.47       210\n",
      "           1       0.53      0.53      0.53       235\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.50      0.50      0.50       445\n",
      "weighted avg       0.50      0.50      0.50       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.52      0.52       511\n",
      "           1       0.48      0.46      0.47       477\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.48      0.47       210\n",
      "           1       0.51      0.48      0.49       235\n",
      "\n",
      "    accuracy                           0.48       445\n",
      "   macro avg       0.48      0.48      0.48       445\n",
      "weighted avg       0.48      0.48      0.48       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.94      0.67       511\n",
      "           1       0.56      0.08      0.14       477\n",
      "\n",
      "    accuracy                           0.53       988\n",
      "   macro avg       0.54      0.51      0.40       988\n",
      "weighted avg       0.54      0.53      0.41       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.97      0.64       210\n",
      "           1       0.68      0.06      0.12       235\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.58      0.52      0.38       445\n",
      "weighted avg       0.59      0.49      0.36       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.54      0.53       511\n",
      "           1       0.48      0.44      0.46       477\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.50      0.48       210\n",
      "           1       0.52      0.48      0.50       235\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.49      0.49      0.49       445\n",
      "weighted avg       0.49      0.49      0.49       445\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.70      0.60       511\n",
      "           1       0.48      0.30      0.37       477\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.50      0.50      0.48       988\n",
      "weighted avg       0.50      0.51      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.70      0.57       210\n",
      "           1       0.53      0.30      0.39       235\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.50      0.50      0.48       445\n",
      "weighted avg       0.51      0.49      0.47       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.68      0.58       511\n",
      "           1       0.48      0.32      0.38       477\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.48       988\n",
      "weighted avg       0.50      0.50      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.63      0.54       210\n",
      "           1       0.52      0.36      0.43       235\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.50      0.50      0.48       445\n",
      "weighted avg       0.50      0.49      0.48       445\n",
      "\n",
      "=================================== 4 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================제습기_change==============================5 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5316616008105369\n",
      "LogisticRegression 정확도(테스트셋) : 0.5263157894736842\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5617977528089888\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.4848178137651822\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.5123595505617977\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.7001013171225937\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.5020242914979757\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.4966292134831461\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5053191489361702\n",
      "GaussianNB 정확도(테스트셋) : 0.48380566801619435\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.48764044943820223\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.48785425101214575\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5146067415730337\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9088145896656535\n",
      "VotingClassifier 정확도(테스트셋) : 0.5020242914979757\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5123595505617977\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9911347517730497\n",
      "VotingClassifier 정확도(테스트셋) : 0.4949392712550607\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.47415730337078654\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.39      0.43       450\n",
      "           1       0.56      0.64      0.60       538\n",
      "\n",
      "    accuracy                           0.53       988\n",
      "   macro avg       0.52      0.51      0.51       988\n",
      "weighted avg       0.52      0.53      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.48      0.50       198\n",
      "           1       0.60      0.62      0.61       247\n",
      "\n",
      "    accuracy                           0.56       445\n",
      "   macro avg       0.55      0.55      0.55       445\n",
      "weighted avg       0.56      0.56      0.56       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.48      0.46       450\n",
      "           1       0.53      0.49      0.51       538\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.48      0.48      0.48       988\n",
      "weighted avg       0.49      0.48      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.54      0.50       198\n",
      "           1       0.57      0.49      0.53       247\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.51      0.52      0.51       445\n",
      "weighted avg       0.52      0.51      0.51       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.48      0.47       450\n",
      "           1       0.54      0.52      0.53       538\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.46      0.45       198\n",
      "           1       0.55      0.52      0.54       247\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.49      0.49      0.49       445\n",
      "weighted avg       0.50      0.50      0.50       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.80      0.59       450\n",
      "           1       0.57      0.22      0.31       538\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.52      0.51      0.45       988\n",
      "weighted avg       0.52      0.48      0.44       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.85      0.60       198\n",
      "           1       0.62      0.19      0.30       247\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.54      0.52      0.45       445\n",
      "weighted avg       0.55      0.49      0.43       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.46      0.45       450\n",
      "           1       0.53      0.51      0.52       538\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.54      0.50       198\n",
      "           1       0.57      0.49      0.53       247\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.52      0.52      0.51       445\n",
      "weighted avg       0.52      0.51      0.52       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.52      0.49       450\n",
      "           1       0.55      0.48      0.51       538\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.51      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.59      0.52       198\n",
      "           1       0.58      0.45      0.51       247\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.52      0.52      0.51       445\n",
      "weighted avg       0.53      0.51      0.51       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.60      0.52       450\n",
      "           1       0.55      0.41      0.47       538\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.50      0.50      0.49       988\n",
      "weighted avg       0.51      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.61      0.51       198\n",
      "           1       0.54      0.37      0.44       247\n",
      "\n",
      "    accuracy                           0.47       445\n",
      "   macro avg       0.49      0.49      0.47       445\n",
      "weighted avg       0.49      0.47      0.47       445\n",
      "\n",
      "=================================== 5 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================태양광에너지_change==============================6 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5509118541033434\n",
      "LogisticRegression 정확도(테스트셋) : 0.5516194331983806\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5146067415730337\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.5121457489878543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.5393258426966292\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.7120060790273556\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.5060728744939271\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.5123595505617977\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.47720364741641336\n",
      "GaussianNB 정확도(테스트셋) : 0.45951417004048584\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.43595505617977526\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5232793522267206\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5258426966292135\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9630192502532928\n",
      "VotingClassifier 정확도(테스트셋) : 0.5111336032388664\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5056179775280899\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9949341438703141\n",
      "VotingClassifier 정확도(테스트셋) : 0.5020242914979757\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5078651685393258\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.13      0.20       426\n",
      "           1       0.57      0.87      0.69       562\n",
      "\n",
      "    accuracy                           0.55       988\n",
      "   macro avg       0.50      0.50      0.45       988\n",
      "weighted avg       0.51      0.55      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.19      0.24       183\n",
      "           1       0.57      0.74      0.64       262\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.45      0.47      0.44       445\n",
      "weighted avg       0.47      0.51      0.48       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.47      0.45       426\n",
      "           1       0.57      0.55      0.56       562\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.52      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.51      0.48       183\n",
      "           1       0.62      0.56      0.59       262\n",
      "\n",
      "    accuracy                           0.54       445\n",
      "   macro avg       0.53      0.53      0.53       445\n",
      "weighted avg       0.55      0.54      0.54       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.43      0.43       426\n",
      "           1       0.57      0.57      0.57       562\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.40      0.41       183\n",
      "           1       0.59      0.59      0.59       262\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.50      0.50      0.50       445\n",
      "weighted avg       0.51      0.51      0.51       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.89      0.59       426\n",
      "           1       0.61      0.13      0.22       562\n",
      "\n",
      "    accuracy                           0.46       988\n",
      "   macro avg       0.53      0.51      0.40       988\n",
      "weighted avg       0.54      0.46      0.38       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.93      0.58       183\n",
      "           1       0.66      0.09      0.15       262\n",
      "\n",
      "    accuracy                           0.44       445\n",
      "   macro avg       0.54      0.51      0.37       445\n",
      "weighted avg       0.56      0.44      0.33       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.36      0.40       426\n",
      "           1       0.57      0.64      0.61       562\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.51      0.52      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.31      0.35       183\n",
      "           1       0.58      0.68      0.63       262\n",
      "\n",
      "    accuracy                           0.53       445\n",
      "   macro avg       0.49      0.49      0.49       445\n",
      "weighted avg       0.51      0.53      0.51       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.39      0.41       426\n",
      "           1       0.57      0.60      0.58       562\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.43      0.42       183\n",
      "           1       0.58      0.56      0.57       262\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.49      0.49      0.49       445\n",
      "weighted avg       0.51      0.51      0.51       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.46      0.45       426\n",
      "           1       0.57      0.53      0.55       562\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.51      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.49      0.45       183\n",
      "           1       0.59      0.52      0.55       262\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.51      0.51      0.50       445\n",
      "weighted avg       0.52      0.51      0.51       445\n",
      "\n",
      "=================================== 6 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================태풍 및 장마_change==============================7 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5379939209726444\n",
      "LogisticRegression 정확도(테스트셋) : 0.49898785425101216\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.4943820224719101\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.4848178137651822\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.47415730337078654\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.6975683890577508\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.5020242914979757\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.47191011235955055\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5053191489361702\n",
      "GaussianNB 정확도(테스트셋) : 0.4807692307692308\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.503370786516854\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.49291497975708504\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5370786516853933\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9232522796352584\n",
      "VotingClassifier 정확도(테스트셋) : 0.5040485829959515\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4606741573033708\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 정확도(훈련셋) : 0.9934143870314083\n",
      "VotingClassifier 정확도(테스트셋) : 0.5\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4584269662921348\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.36      0.40       459\n",
      "           1       0.53      0.62      0.57       529\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.49      0.49      0.48       988\n",
      "weighted avg       0.49      0.50      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.42      0.44       208\n",
      "           1       0.52      0.56      0.54       237\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.49      0.49      0.49       445\n",
      "weighted avg       0.49      0.49      0.49       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.49      0.47       459\n",
      "           1       0.52      0.48      0.50       529\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.49      0.49      0.48       988\n",
      "weighted avg       0.49      0.48      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.47      0.46       208\n",
      "           1       0.51      0.48      0.49       237\n",
      "\n",
      "    accuracy                           0.47       445\n",
      "   macro avg       0.47      0.47      0.47       445\n",
      "weighted avg       0.48      0.47      0.47       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.48      0.47       459\n",
      "           1       0.54      0.52      0.53       529\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.43      0.43       208\n",
      "           1       0.50      0.51      0.51       237\n",
      "\n",
      "    accuracy                           0.47       445\n",
      "   macro avg       0.47      0.47      0.47       445\n",
      "weighted avg       0.47      0.47      0.47       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.80      0.59       459\n",
      "           1       0.54      0.20      0.29       529\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.50      0.50      0.44       988\n",
      "weighted avg       0.51      0.48      0.43       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.84      0.61       208\n",
      "           1       0.60      0.21      0.31       237\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.54      0.52      0.46       445\n",
      "weighted avg       0.54      0.50      0.45       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.42      0.44       459\n",
      "           1       0.53      0.55      0.54       529\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.48      0.49       208\n",
      "           1       0.56      0.59      0.57       237\n",
      "\n",
      "    accuracy                           0.54       445\n",
      "   macro avg       0.53      0.53      0.53       445\n",
      "weighted avg       0.54      0.54      0.54       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.52      0.49       459\n",
      "           1       0.54      0.49      0.51       529\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.51      0.51      0.50       988\n",
      "weighted avg       0.51      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46       208\n",
      "           1       0.49      0.43      0.46       237\n",
      "\n",
      "    accuracy                           0.46       445\n",
      "   macro avg       0.46      0.46      0.46       445\n",
      "weighted avg       0.46      0.46      0.46       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.53      0.50       459\n",
      "           1       0.54      0.47      0.50       529\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46       208\n",
      "           1       0.49      0.42      0.45       237\n",
      "\n",
      "    accuracy                           0.46       445\n",
      "   macro avg       0.46      0.46      0.46       445\n",
      "weighted avg       0.46      0.46      0.46       445\n",
      "\n",
      "=================================== 7 page ===================================\n",
      "\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for i in range(len(y2.columns)) : \n",
    "    # 훈련용 데이터(X_tr)을 train_test_split으로 나누기\n",
    "#   from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x2_tr, y2_tr.iloc[:,i], test_size = 0.2, random_state = 1)\n",
    "\n",
    "    # 데이터 표준화\n",
    "#     from sklearn.preprocessing import StandardScaler\n",
    "    stds = StandardScaler()\n",
    "    stds.fit(X_train)\n",
    "    X_train_std = stds.transform(X_train)\n",
    "    X_test_std = stds.transform(X_test)\n",
    "    X_ftest_std = stds.transform(x2_te)\n",
    "\n",
    "    # 분석 시작\n",
    "#     from sklearn.tree import DecisionTreeClassifier\n",
    "#     from sklearn.linear_model import LogisticRegression\n",
    "#     from sklearn.neighbors import KNeighborsClassifier\n",
    "#     from sklearn.naive_bayes import GaussianNB\n",
    "#     from sklearn.ensemble import RandomForestClassifier\n",
    "#     from sklearn.ensemble import VotingClassifier\n",
    "#     from sklearn.metrics import precision_score\n",
    "    \n",
    "    # 모델 생성\n",
    "    log = LogisticRegression()\n",
    "    knn = KNeighborsClassifier()\n",
    "    tree = DecisionTreeClassifier()\n",
    "    gnb = GaussianNB()\n",
    "    rfc = RandomForestClassifier()\n",
    "         \n",
    "    hvot = VotingClassifier(estimators = [('log', log), ('rfc', rfc), ('knn', knn), \\\n",
    "                        ('tree',tree),('gnb', gnb)], voting='hard')\n",
    "\n",
    "    svot = VotingClassifier(estimators = [('log', log), ('rfc', rfc), ('knn', knn), \\\n",
    "                        ('tree',tree),('gnb', gnb)], voting='soft')\n",
    "    \n",
    "    models = [log, tree, knn, gnb, rfc, hvot, svot]\n",
    "    \n",
    "    print('==================================={}=============================={} page'.format(y2.columns[i], i+1))\n",
    "    \n",
    "    y_fin = y2_te.iloc[:,i] # 최종 모형 평가 변수\n",
    "    \n",
    "    for m in models :\n",
    "        m.fit(X_train, y_train)\n",
    "        \n",
    "        # 데이터 예측\n",
    "        preds = m.predict(X_test) \n",
    "        \n",
    "        # 정확도 평가\n",
    "        accuracy0 = m.score(X_train, y_train)\n",
    "        accuracy1 = m.score(X_test, y_test)\n",
    "        accuracy2 = m.score(x2_te, y_fin)\n",
    "        \n",
    "        print(m.__class__.__name__, '정확도(훈련셋) :' , accuracy0)\n",
    "        print(m.__class__.__name__, '정확도(테스트셋) :' , accuracy1)\n",
    "        print(m.__class__.__name__, '정확도(실제 테스트셋) :' , accuracy2)\n",
    "        \n",
    "        print('-'*80)\n",
    "\n",
    "    # 분류 레포트\n",
    "\n",
    "#     from sklearn.metrics import classification_report\n",
    "    \n",
    "    y_fin = y2_te.iloc[:,i]                \n",
    "    \n",
    "    for m in models :\n",
    "        preds0 = m.predict(X_test) # 데이터 예측\n",
    "        preds1 = m.predict(x2_te)\n",
    "        class_report1 = classification_report(y_test, preds0)\n",
    "        class_report2 = classification_report(y_fin, preds1)\n",
    "        \n",
    "        print(m.__class__.__name__ , '훈련 데이터 테스트셋 \\n',class_report1)\n",
    "        print('-'*80)\n",
    "        print(m.__class__.__name__ , '실제 데이터 테스트셋 \\n',class_report2)\n",
    "    \n",
    "    print('=================================== {} page ===================================\\n\\n\\n '.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d034fbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b50011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ae7ed3a",
   "metadata": {},
   "source": [
    "# 3. 테마별 변동률 - 코스피 변동률 연산 후 변동률 표준화( (x-x.mean())/x.std()) \n",
    "- 각 테마별 변동률의 평균이 코스피 변동률에 비해 너무 크기 때문에 표준화를 한 뒤 각 테마를 코스피 변동률에 뺀 후 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bbeb306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = total_df.loc[:,'겨울_change':]\n",
    "x3 = total_df.iloc[:, :-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ddd0bfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "      <th>kospi_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.028631</td>\n",
       "      <td>-0.022007</td>\n",
       "      <td>0.099463</td>\n",
       "      <td>-0.120506</td>\n",
       "      <td>0.053184</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>-0.009157</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.020313</td>\n",
       "      <td>-0.018795</td>\n",
       "      <td>-0.099756</td>\n",
       "      <td>-0.122383</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>-0.029292</td>\n",
       "      <td>-0.023451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>-0.021105</td>\n",
       "      <td>-0.025308</td>\n",
       "      <td>-0.057200</td>\n",
       "      <td>-0.121322</td>\n",
       "      <td>0.036051</td>\n",
       "      <td>-0.028175</td>\n",
       "      <td>-0.047156</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.010074</td>\n",
       "      <td>-0.030899</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.119920</td>\n",
       "      <td>-0.006578</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.017129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.057375</td>\n",
       "      <td>-0.009458</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.033368</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            겨울_change  도시가스_change  여행_change  인터넷 대표주_change  제습기_change  \\\n",
       "Date                                                                        \n",
       "2000-01-04   0.028631    -0.022007   0.099463       -0.120506    0.053184   \n",
       "2000-01-05   0.020313    -0.018795  -0.099756       -0.122383    0.014747   \n",
       "2000-01-06  -0.021105    -0.025308  -0.057200       -0.121322    0.036051   \n",
       "2000-01-07   0.010074    -0.030899  -0.119941       -0.119920   -0.006578   \n",
       "2000-01-10   0.001956     0.057375  -0.009458        0.008714   -0.033368   \n",
       "\n",
       "            태양광에너지_change  태풍 및 장마_change  kospi_change  \n",
       "Date                                                     \n",
       "2000-01-04       0.030200       -0.009157           0.0  \n",
       "2000-01-05      -0.029292       -0.023451           0.0  \n",
       "2000-01-06      -0.028175       -0.047156           0.0  \n",
       "2000-01-07       0.006012        0.017129           0.0  \n",
       "2000-01-10       0.000011        0.004409           0.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163cb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "640ad2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kospi_co(x) :  # x는 코스피 y는 변동값\n",
    "    i=0\n",
    "    L=[]\n",
    "\n",
    "    while i < len(x):\n",
    "        if x[i] > 0:\n",
    "            t = x[i]*0.1\n",
    "        else :\n",
    "            t = abs(x[i])*0.1\n",
    "        i +=1\n",
    "        L.append(t)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0058bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kospi_co_1(x,y) :  # x는 코스피 y는 변동값\n",
    "    i=0\n",
    "    L=[]\n",
    "\n",
    "    while i < len(x):\n",
    "        if x[i] > 0:\n",
    "            t = y[i] - x[i]\n",
    "        else :\n",
    "            t = y[i] - abs(x[i])\n",
    "        i +=1\n",
    "        L.append(t)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da78e872",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "겨울_change\n",
      "도시가스_change\n",
      "여행_change\n",
      "인터넷 대표주_change\n",
      "제습기_change\n",
      "태양광에너지_change\n",
      "태풍 및 장마_change\n",
      "kospi_change\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "      <th>kospi_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.028631</td>\n",
       "      <td>-0.022007</td>\n",
       "      <td>0.099463</td>\n",
       "      <td>-0.120506</td>\n",
       "      <td>0.053184</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>-0.009157</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.020313</td>\n",
       "      <td>-0.018795</td>\n",
       "      <td>-0.099756</td>\n",
       "      <td>-0.122383</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>-0.029292</td>\n",
       "      <td>-0.023451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>-0.021105</td>\n",
       "      <td>-0.025308</td>\n",
       "      <td>-0.057200</td>\n",
       "      <td>-0.121322</td>\n",
       "      <td>0.036051</td>\n",
       "      <td>-0.028175</td>\n",
       "      <td>-0.047156</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.010074</td>\n",
       "      <td>-0.030899</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.119920</td>\n",
       "      <td>-0.006578</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.017129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.057375</td>\n",
       "      <td>-0.009458</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.033368</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            겨울_change  도시가스_change  여행_change  인터넷 대표주_change  제습기_change  \\\n",
       "Date                                                                        \n",
       "2000-01-04   0.028631    -0.022007   0.099463       -0.120506    0.053184   \n",
       "2000-01-05   0.020313    -0.018795  -0.099756       -0.122383    0.014747   \n",
       "2000-01-06  -0.021105    -0.025308  -0.057200       -0.121322    0.036051   \n",
       "2000-01-07   0.010074    -0.030899  -0.119941       -0.119920   -0.006578   \n",
       "2000-01-10   0.001956     0.057375  -0.009458        0.008714   -0.033368   \n",
       "\n",
       "            태양광에너지_change  태풍 및 장마_change  kospi_change  \n",
       "Date                                                     \n",
       "2000-01-04       0.030200       -0.009157           0.0  \n",
       "2000-01-05      -0.029292       -0.023451           0.0  \n",
       "2000-01-06      -0.028175       -0.047156           0.0  \n",
       "2000-01-07       0.006012        0.017129           0.0  \n",
       "2000-01-10       0.000011        0.004409           0.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테마 - 코스피\n",
    "\n",
    "for i in y3.columns:\n",
    "    print(i)\n",
    "    y3['{}'.format(i)] = kospi_co_1(y3['kospi_change'], y3['{}'.format(i)])\n",
    "y3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8621479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테마 - 코스피 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa77292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "겨울_change\n",
      "도시가스_change\n",
      "여행_change\n",
      "인터넷 대표주_change\n",
      "제습기_change\n",
      "태양광에너지_change\n",
      "태풍 및 장마_change\n",
      "kospi_change\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "      <th>kospi_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.019457</td>\n",
       "      <td>-0.018473</td>\n",
       "      <td>0.039749</td>\n",
       "      <td>-0.039460</td>\n",
       "      <td>0.020795</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>-0.004896</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.013743</td>\n",
       "      <td>-0.015775</td>\n",
       "      <td>-0.040178</td>\n",
       "      <td>-0.040072</td>\n",
       "      <td>0.005608</td>\n",
       "      <td>-0.016176</td>\n",
       "      <td>-0.012344</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>-0.014711</td>\n",
       "      <td>-0.021247</td>\n",
       "      <td>-0.023104</td>\n",
       "      <td>-0.039726</td>\n",
       "      <td>0.014026</td>\n",
       "      <td>-0.015564</td>\n",
       "      <td>-0.024695</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.006708</td>\n",
       "      <td>-0.025944</td>\n",
       "      <td>-0.048276</td>\n",
       "      <td>-0.039269</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.048227</td>\n",
       "      <td>-0.003950</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>-0.013402</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            겨울_change  도시가스_change  여행_change  인터넷 대표주_change  제습기_change  \\\n",
       "Date                                                                        \n",
       "2000-01-04   0.019457    -0.018473   0.039749       -0.039460    0.020795   \n",
       "2000-01-05   0.013743    -0.015775  -0.040178       -0.040072    0.005608   \n",
       "2000-01-06  -0.014711    -0.021247  -0.023104       -0.039726    0.014026   \n",
       "2000-01-07   0.006708    -0.025944  -0.048276       -0.039269   -0.002817   \n",
       "2000-01-10   0.001132     0.048227  -0.003950        0.002680   -0.013402   \n",
       "\n",
       "            태양광에너지_change  태풍 및 장마_change  kospi_change  \n",
       "Date                                                     \n",
       "2000-01-04       0.016407       -0.004896           NaN  \n",
       "2000-01-05      -0.016176       -0.012344           NaN  \n",
       "2000-01-06      -0.015564       -0.024695           NaN  \n",
       "2000-01-07       0.003160        0.008800           NaN  \n",
       "2000-01-10      -0.000127        0.002172           NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in y3.columns:\n",
    "    print(i)\n",
    "    y3['{}'.format(i)] = standards(y3['{}'.format(i)])\n",
    "y3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ff6af63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>겨울_change</th>\n",
       "      <th>도시가스_change</th>\n",
       "      <th>여행_change</th>\n",
       "      <th>인터넷 대표주_change</th>\n",
       "      <th>제습기_change</th>\n",
       "      <th>태양광에너지_change</th>\n",
       "      <th>태풍 및 장마_change</th>\n",
       "      <th>kospi_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            겨울_change  도시가스_change  여행_change  인터넷 대표주_change  제습기_change  \\\n",
       "Date                                                                        \n",
       "2000-01-04          1            0          1               0           1   \n",
       "2000-01-05          1            0          0               0           1   \n",
       "2000-01-06          0            0          0               0           1   \n",
       "2000-01-07          1            0          0               0           0   \n",
       "2000-01-10          1            1          0               1           0   \n",
       "\n",
       "            태양광에너지_change  태풍 및 장마_change  kospi_change  \n",
       "Date                                                     \n",
       "2000-01-04              1               0             0  \n",
       "2000-01-05              0               0             0  \n",
       "2000-01-06              0               0             0  \n",
       "2000-01-07              1               1             0  \n",
       "2000-01-10              0               1             0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이진분류로 만듦\n",
    "\n",
    "for i in range(len(y3.columns)):\n",
    "    y3.iloc[:,i] = plus_minus(y3.iloc[:,i])\n",
    "y3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6067739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1cffb061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 모형 평가때 쓰이는 데이터\n",
    "x3_tr = x3.loc[:'2020-01-01',:]\n",
    "y3_tr = y3.loc[:'2020-01-01',:]\n",
    "\n",
    "# 실제 평가를 하는 데이터\n",
    "x3_te = x3.loc['2019-12-31':,:]\n",
    "y3_te = y3.loc['2019-12-31':,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b1a90664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['평균기온', '최저기온', '최고기온', '강수계속시간', '10분최다강수', '1시간최다강수', '일강수', '최대순간풍속',\n",
       "       '최대풍속', '평균풍속', '평균이슬점온도', '최소상대습도', '평균상대습도', '평균현지기압', '최고해면기압',\n",
       "       '최저해면기압', '평균해면기압', '가조시간', '합계일조시간', '1시간최다일사량', '합계일사량', '최심신적설',\n",
       "       '최심적설', '3시간신적설', '평균전운량', '평균중하층운량', '평균지면온도', '평균10cm지중온도',\n",
       "       '평균30cm지중온도', '0.5m지중온도', '1.5m지중온도', '3m지중온도', '대형증발량', '소형증발량',\n",
       "       '안개계속시간'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3_tr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47130525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "694599d3",
   "metadata": {},
   "source": [
    "## case3 테마별 변동률 - 코스피 변동률 연산 후 변동률 표준화( (x-x.mean())/x.std()) \n",
    "\n",
    "## 각 테마별 변동률의 평균이 코스피 변동률에 비해 너무 크기 때문에 표준화를 한 뒤 각 테마를 코스피 변동률에 뺀 후 분석\n",
    "\n",
    "## 사용모델 : \n",
    "### DecisionTreeClassifier\n",
    "### LogisticRegression\n",
    "### KNeighborsClassifier\n",
    "### naive_bayes\n",
    "### RandomForestClassifier\n",
    "### VotingClassifier\n",
    "   \n",
    "## 2019-12-31 이전 데이터를 학습 및 평가용으로 그 이후 데이터를 \n",
    "## 실제 데이터에 적용을 하기 위해 아래와 같이 나누었다.\n",
    "\n",
    "## x3_tr, y3_tr : 모델 학습 및 평가때 쓰이는 데이터, 2019-12-31 이전\n",
    "## x3_te, y3_te : 학습된 모델을 실제 데이터에 투입하여 확인하는 데이터 2020-01-01 이후\n",
    "\n",
    "## 테스트 결과는 case1, case2와 크게 다르지 않게 ensemble 계열의 모델은 과적합, LogisticRegression은 점수가 낮게 나왔다.\n",
    "\n",
    "## 결론 : 날씨에 따라 테마별 주가 변동이 있을것이라고 판단을 하였으나 실제 테마 전체의 변동량(change)는 영향이 거의 없음을 알 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34198101",
   "metadata": {},
   "source": [
    "# Case3 분석시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "019e0985",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================겨울_change==============================1 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5240628166160081\n",
      "LogisticRegression 정확도(테스트셋) : 0.5020242914979757\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.4853932584269663\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.4979757085020243\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.48314606741573035\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.6826241134751773\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.48582995951417\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.5280898876404494\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5058257345491388\n",
      "GaussianNB 정확도(테스트셋) : 0.4534412955465587\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.46741573033707867\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5141700404858299\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5617977528089888\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9194528875379939\n",
      "VotingClassifier 정확도(테스트셋) : 0.4868421052631579\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.501123595505618\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9997467071935157\n",
      "VotingClassifier 정확도(테스트셋) : 0.4777327935222672\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5235955056179775\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.44      0.44       437\n",
      "           1       0.55      0.55      0.55       551\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.39      0.41       210\n",
      "           1       0.51      0.57      0.54       235\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.48      0.48      0.48       445\n",
      "weighted avg       0.48      0.49      0.48       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.46      0.45       437\n",
      "           1       0.55      0.53      0.54       551\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.47      0.46       210\n",
      "           1       0.51      0.49      0.50       235\n",
      "\n",
      "    accuracy                           0.48       445\n",
      "   macro avg       0.48      0.48      0.48       445\n",
      "weighted avg       0.48      0.48      0.48       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.49      0.46       437\n",
      "           1       0.54      0.48      0.51       551\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.48       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.49      0.50       210\n",
      "           1       0.55      0.56      0.56       235\n",
      "\n",
      "    accuracy                           0.53       445\n",
      "   macro avg       0.53      0.53      0.53       445\n",
      "weighted avg       0.53      0.53      0.53       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.88      0.59       437\n",
      "           1       0.55      0.11      0.19       551\n",
      "\n",
      "    accuracy                           0.45       988\n",
      "   macro avg       0.49      0.50      0.39       988\n",
      "weighted avg       0.50      0.45      0.36       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.84      0.60       210\n",
      "           1       0.48      0.13      0.21       235\n",
      "\n",
      "    accuracy                           0.47       445\n",
      "   macro avg       0.47      0.49      0.40       445\n",
      "weighted avg       0.48      0.47      0.39       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.49      0.47       437\n",
      "           1       0.57      0.53      0.55       551\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.52      0.51      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53       210\n",
      "           1       0.58      0.60      0.59       235\n",
      "\n",
      "    accuracy                           0.56       445\n",
      "   macro avg       0.56      0.56      0.56       445\n",
      "weighted avg       0.56      0.56      0.56       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.58      0.50       437\n",
      "           1       0.55      0.42      0.47       551\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.50      0.50      0.49       988\n",
      "weighted avg       0.50      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.57      0.52       210\n",
      "           1       0.53      0.44      0.48       235\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.50      0.50      0.50       445\n",
      "weighted avg       0.51      0.50      0.50       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.53      0.47       437\n",
      "           1       0.54      0.43      0.48       551\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.48      0.48      0.48       988\n",
      "weighted avg       0.49      0.48      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.55      0.52       210\n",
      "           1       0.55      0.50      0.53       235\n",
      "\n",
      "    accuracy                           0.52       445\n",
      "   macro avg       0.52      0.52      0.52       445\n",
      "weighted avg       0.53      0.52      0.52       445\n",
      "\n",
      "=================================== 1 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================도시가스_change==============================2 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5250759878419453\n",
      "LogisticRegression 정확도(테스트셋) : 0.5\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.42696629213483145\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.5030364372469636\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.48764044943820223\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.686676798378926\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.48380566801619435\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.47415730337078654\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5126646403242148\n",
      "GaussianNB 정확도(테스트셋) : 0.46558704453441296\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.43820224719101125\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.4949392712550607\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.4696629213483146\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.898936170212766\n",
      "VotingClassifier 정확도(테스트셋) : 0.4888663967611336\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.42921348314606744\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9977203647416414\n",
      "VotingClassifier 정확도(테스트셋) : 0.5010121457489879\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4696629213483146\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.71      0.57       471\n",
      "           1       0.54      0.31      0.39       517\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.51      0.51      0.48       988\n",
      "weighted avg       0.51      0.50      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.88      0.57       195\n",
      "           1       0.44      0.08      0.13       250\n",
      "\n",
      "    accuracy                           0.43       445\n",
      "   macro avg       0.43      0.48      0.35       445\n",
      "weighted avg       0.43      0.43      0.32       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.51      0.50       471\n",
      "           1       0.53      0.49      0.51       517\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.49      0.45       195\n",
      "           1       0.55      0.49      0.52       250\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.49      0.49      0.49       445\n",
      "weighted avg       0.50      0.49      0.49       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.51      0.48       471\n",
      "           1       0.51      0.46      0.48       517\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.48      0.48      0.48       988\n",
      "weighted avg       0.49      0.48      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.46      0.43       195\n",
      "           1       0.54      0.48      0.51       250\n",
      "\n",
      "    accuracy                           0.47       445\n",
      "   macro avg       0.47      0.47      0.47       445\n",
      "weighted avg       0.48      0.47      0.48       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.69      0.55       471\n",
      "           1       0.48      0.26      0.34       517\n",
      "\n",
      "    accuracy                           0.47       988\n",
      "   macro avg       0.47      0.48      0.45       988\n",
      "weighted avg       0.47      0.47      0.44       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.62      0.49       195\n",
      "           1       0.50      0.30      0.37       250\n",
      "\n",
      "    accuracy                           0.44       445\n",
      "   macro avg       0.45      0.46      0.43       445\n",
      "weighted avg       0.46      0.44      0.42       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.55      0.51       471\n",
      "           1       0.52      0.45      0.48       517\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.50      0.50      0.49       988\n",
      "weighted avg       0.50      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.59      0.50       195\n",
      "           1       0.54      0.37      0.44       250\n",
      "\n",
      "    accuracy                           0.47       445\n",
      "   macro avg       0.48      0.48      0.47       445\n",
      "weighted avg       0.49      0.47      0.46       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.66      0.55       471\n",
      "           1       0.52      0.33      0.40       517\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.50      0.50      0.48       988\n",
      "weighted avg       0.50      0.49      0.47       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.66      0.50       195\n",
      "           1       0.48      0.25      0.33       250\n",
      "\n",
      "    accuracy                           0.43       445\n",
      "   macro avg       0.45      0.45      0.42       445\n",
      "weighted avg       0.45      0.43      0.41       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.54      0.51       471\n",
      "           1       0.53      0.47      0.50       517\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.49      0.45       195\n",
      "           1       0.53      0.46      0.49       250\n",
      "\n",
      "    accuracy                           0.47       445\n",
      "   macro avg       0.47      0.47      0.47       445\n",
      "weighted avg       0.48      0.47      0.47       445\n",
      "\n",
      "=================================== 2 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================여행_change==============================3 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5316616008105369\n",
      "LogisticRegression 정확도(테스트셋) : 0.5323886639676113\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.49887640449438203\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.5020242914979757\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.5213483146067416\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.6887031408308004\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.48785425101214575\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.4786516853932584\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5235562310030395\n",
      "GaussianNB 정확도(테스트셋) : 0.5091093117408907\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.4943820224719101\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5050607287449392\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.4966292134831461\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.8690476190476191\n",
      "VotingClassifier 정확도(테스트셋) : 0.5192307692307693\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.47415730337078654\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9969604863221885\n",
      "VotingClassifier 정확도(테스트셋) : 0.5020242914979757\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.501123595505618\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.61      0.56       488\n",
      "           1       0.55      0.46      0.50       500\n",
      "\n",
      "    accuracy                           0.53       988\n",
      "   macro avg       0.53      0.53      0.53       988\n",
      "weighted avg       0.53      0.53      0.53       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.67      0.57       216\n",
      "           1       0.52      0.34      0.41       229\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.50      0.50      0.49       445\n",
      "weighted avg       0.50      0.50      0.48       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.48      0.49       488\n",
      "           1       0.51      0.53      0.52       500\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.52      0.51       216\n",
      "           1       0.54      0.52      0.53       229\n",
      "\n",
      "    accuracy                           0.52       445\n",
      "   macro avg       0.52      0.52      0.52       445\n",
      "weighted avg       0.52      0.52      0.52       445\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.49      0.49       488\n",
      "           1       0.49      0.48      0.49       500\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.50      0.48       216\n",
      "           1       0.49      0.45      0.47       229\n",
      "\n",
      "    accuracy                           0.48       445\n",
      "   macro avg       0.48      0.48      0.48       445\n",
      "weighted avg       0.48      0.48      0.48       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57       488\n",
      "           1       0.52      0.35      0.42       500\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.50       988\n",
      "weighted avg       0.51      0.51      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.72      0.58       216\n",
      "           1       0.52      0.28      0.36       229\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.50      0.50      0.47       445\n",
      "weighted avg       0.50      0.49      0.47       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.53      0.51       488\n",
      "           1       0.51      0.48      0.50       500\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.50       988\n",
      "weighted avg       0.51      0.51      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.56      0.52       216\n",
      "           1       0.51      0.44      0.47       229\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.50      0.50      0.50       445\n",
      "weighted avg       0.50      0.50      0.50       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.62      0.56       488\n",
      "           1       0.53      0.42      0.47       500\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.52      0.52      0.51       988\n",
      "weighted avg       0.52      0.52      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.63      0.54       216\n",
      "           1       0.48      0.32      0.39       229\n",
      "\n",
      "    accuracy                           0.47       445\n",
      "   macro avg       0.48      0.48      0.46       445\n",
      "weighted avg       0.48      0.47      0.46       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.54      0.52       488\n",
      "           1       0.51      0.46      0.49       500\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.60      0.54       216\n",
      "           1       0.52      0.41      0.46       229\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.50      0.50      0.50       445\n",
      "weighted avg       0.50      0.50      0.50       445\n",
      "\n",
      "=================================== 3 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================인터넷 대표주_change==============================4 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.529128672745694\n",
      "LogisticRegression 정확도(테스트셋) : 0.5323886639676113\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5056179775280899\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.5242914979757085\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.5258426966292135\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.693515704154002\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.4908906882591093\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.4764044943820225\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.522289766970618\n",
      "GaussianNB 정확도(테스트셋) : 0.5384615384615384\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.48764044943820223\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5192307692307693\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.4786516853932584\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.8556231003039514\n",
      "VotingClassifier 정확도(테스트셋) : 0.5263157894736842\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.49887640449438203\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9822695035460993\n",
      "VotingClassifier 정확도(테스트셋) : 0.5010121457489879\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.49887640449438203\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.88      0.67       527\n",
      "           1       0.50      0.14      0.22       461\n",
      "\n",
      "    accuracy                           0.53       988\n",
      "   macro avg       0.52      0.51      0.44       988\n",
      "weighted avg       0.52      0.53      0.46       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.87      0.62       211\n",
      "           1       0.60      0.18      0.28       234\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.54      0.52      0.45       445\n",
      "weighted avg       0.55      0.51      0.44       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55       527\n",
      "           1       0.49      0.49      0.49       461\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.52      0.52      0.52       988\n",
      "weighted avg       0.52      0.52      0.52       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.52      0.51       211\n",
      "           1       0.55      0.53      0.54       234\n",
      "\n",
      "    accuracy                           0.53       445\n",
      "   macro avg       0.53      0.53      0.53       445\n",
      "weighted avg       0.53      0.53      0.53       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.53       527\n",
      "           1       0.45      0.44      0.45       461\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.51      0.48       211\n",
      "           1       0.50      0.45      0.47       234\n",
      "\n",
      "    accuracy                           0.48       445\n",
      "   macro avg       0.48      0.48      0.48       445\n",
      "weighted avg       0.48      0.48      0.48       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.94      0.69       527\n",
      "           1       0.54      0.08      0.13       461\n",
      "\n",
      "    accuracy                           0.54       988\n",
      "   macro avg       0.54      0.51      0.41       988\n",
      "weighted avg       0.54      0.54      0.43       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.96      0.64       211\n",
      "           1       0.62      0.06      0.12       234\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.55      0.51      0.38       445\n",
      "weighted avg       0.56      0.49      0.36       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.61      0.58       527\n",
      "           1       0.48      0.41      0.44       461\n",
      "\n",
      "    accuracy                           0.52       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.51      0.52      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.57      0.51       211\n",
      "           1       0.51      0.40      0.44       234\n",
      "\n",
      "    accuracy                           0.48       445\n",
      "   macro avg       0.48      0.48      0.48       445\n",
      "weighted avg       0.48      0.48      0.48       445\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.80      0.64       527\n",
      "           1       0.48      0.21      0.30       461\n",
      "\n",
      "    accuracy                           0.53       988\n",
      "   macro avg       0.51      0.51      0.47       988\n",
      "weighted avg       0.51      0.53      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.78      0.60       211\n",
      "           1       0.55      0.24      0.34       234\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.52      0.51      0.47       445\n",
      "weighted avg       0.52      0.50      0.46       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.69      0.60       527\n",
      "           1       0.45      0.29      0.35       461\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.49      0.49      0.47       988\n",
      "weighted avg       0.49      0.50      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.68      0.56       211\n",
      "           1       0.54      0.34      0.41       234\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.51      0.51      0.49       445\n",
      "weighted avg       0.51      0.50      0.48       445\n",
      "\n",
      "=================================== 4 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================제습기_change==============================5 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5379939209726444\n",
      "LogisticRegression 정확도(테스트셋) : 0.5020242914979757\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5370786516853933\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.49696356275303644\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.5056179775280899\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.700354609929078\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.5020242914979757\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.4943820224719101\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5215298885511651\n",
      "GaussianNB 정확도(테스트셋) : 0.4777327935222672\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.48089887640449436\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.4665991902834008\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5528089887640449\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.8870314083080041\n",
      "VotingClassifier 정확도(테스트셋) : 0.4706477732793522\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5078651685393258\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9888551165146909\n",
      "VotingClassifier 정확도(테스트셋) : 0.48785425101214575\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.4943820224719101\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.53      0.50       466\n",
      "           1       0.53      0.47      0.50       522\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.51      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.62      0.55       204\n",
      "           1       0.59      0.47      0.52       241\n",
      "\n",
      "    accuracy                           0.54       445\n",
      "   macro avg       0.54      0.54      0.54       445\n",
      "weighted avg       0.55      0.54      0.54       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.49      0.48       466\n",
      "           1       0.53      0.50      0.51       522\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.52      0.49       204\n",
      "           1       0.55      0.49      0.52       241\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.51      0.51      0.51       445\n",
      "weighted avg       0.51      0.51      0.51       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.52      0.50       466\n",
      "           1       0.53      0.49      0.51       522\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.50      0.50      0.50       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.50      0.48       204\n",
      "           1       0.54      0.49      0.51       241\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.50      0.50      0.49       445\n",
      "weighted avg       0.50      0.49      0.50       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.82      0.60       466\n",
      "           1       0.52      0.17      0.26       522\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.49      0.50      0.43       988\n",
      "weighted avg       0.49      0.48      0.42       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.85      0.60       204\n",
      "           1       0.57      0.17      0.26       241\n",
      "\n",
      "    accuracy                           0.48       445\n",
      "   macro avg       0.52      0.51      0.43       445\n",
      "weighted avg       0.52      0.48      0.41       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.50      0.47       466\n",
      "           1       0.49      0.43      0.46       522\n",
      "\n",
      "    accuracy                           0.47       988\n",
      "   macro avg       0.47      0.47      0.47       988\n",
      "weighted avg       0.47      0.47      0.47       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.64      0.57       204\n",
      "           1       0.61      0.48      0.54       241\n",
      "\n",
      "    accuracy                           0.55       445\n",
      "   macro avg       0.56      0.56      0.55       445\n",
      "weighted avg       0.56      0.55      0.55       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.60      0.52       466\n",
      "           1       0.50      0.35      0.41       522\n",
      "\n",
      "    accuracy                           0.47       988\n",
      "   macro avg       0.48      0.48      0.47       988\n",
      "weighted avg       0.48      0.47      0.46       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.72      0.57       204\n",
      "           1       0.58      0.33      0.42       241\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.53      0.52      0.50       445\n",
      "weighted avg       0.53      0.51      0.49       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.63      0.54       466\n",
      "           1       0.52      0.36      0.43       522\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.50      0.50      0.48       988\n",
      "weighted avg       0.50      0.49      0.48       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.67      0.55       204\n",
      "           1       0.55      0.35      0.43       241\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.51      0.51      0.49       445\n",
      "weighted avg       0.51      0.49      0.48       445\n",
      "\n",
      "=================================== 5 page ===================================\n",
      "\n",
      "\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================태양광에너지_change==============================6 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5458459979736575\n",
      "LogisticRegression 정확도(테스트셋) : 0.5425101214574899\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5056179775280899\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.5131578947368421\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.5168539325842697\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.7112462006079028\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.5040485829959515\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.5101123595505618\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.48505572441742656\n",
      "GaussianNB 정확도(테스트셋) : 0.4625506072874494\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.43820224719101125\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5293522267206477\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5235955056179775\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9549138804457954\n",
      "VotingClassifier 정확도(테스트셋) : 0.5394736842105263\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.501123595505618\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9951874366767984\n",
      "VotingClassifier 정확도(테스트셋) : 0.49190283400809715\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.5123595505617977\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.19      0.27       432\n",
      "           1       0.56      0.82      0.67       556\n",
      "\n",
      "    accuracy                           0.54       988\n",
      "   macro avg       0.51      0.50      0.47       988\n",
      "weighted avg       0.51      0.54      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.27      0.31       186\n",
      "           1       0.56      0.68      0.61       259\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.47      0.47      0.46       445\n",
      "weighted avg       0.48      0.51      0.49       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.46      0.45       432\n",
      "           1       0.57      0.55      0.56       556\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.52      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.41      0.41       186\n",
      "           1       0.58      0.59      0.59       259\n",
      "\n",
      "    accuracy                           0.52       445\n",
      "   macro avg       0.50      0.50      0.50       445\n",
      "weighted avg       0.52      0.52      0.52       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.45      0.44       432\n",
      "           1       0.56      0.54      0.55       556\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.50      0.50      0.50       988\n",
      "weighted avg       0.51      0.50      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.42      0.42       186\n",
      "           1       0.58      0.57      0.58       259\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.50      0.50      0.50       445\n",
      "weighted avg       0.51      0.51      0.51       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.89      0.59       432\n",
      "           1       0.61      0.13      0.21       556\n",
      "\n",
      "    accuracy                           0.46       988\n",
      "   macro avg       0.52      0.51      0.40       988\n",
      "weighted avg       0.53      0.46      0.38       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.94      0.58       186\n",
      "           1       0.64      0.08      0.14       259\n",
      "\n",
      "    accuracy                           0.44       445\n",
      "   macro avg       0.53      0.51      0.36       445\n",
      "weighted avg       0.55      0.44      0.33       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.42      0.44       432\n",
      "           1       0.58      0.61      0.59       556\n",
      "\n",
      "    accuracy                           0.53       988\n",
      "   macro avg       0.52      0.52      0.52       988\n",
      "weighted avg       0.53      0.53      0.53       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.38      0.40       186\n",
      "           1       0.58      0.63      0.60       259\n",
      "\n",
      "    accuracy                           0.52       445\n",
      "   macro avg       0.50      0.50      0.50       445\n",
      "weighted avg       0.52      0.52      0.52       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.47      0.47       432\n",
      "           1       0.59      0.59      0.59       556\n",
      "\n",
      "    accuracy                           0.54       988\n",
      "   macro avg       0.53      0.53      0.53       988\n",
      "weighted avg       0.54      0.54      0.54       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.47      0.44       186\n",
      "           1       0.58      0.52      0.55       259\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.50      0.50      0.50       445\n",
      "weighted avg       0.51      0.50      0.50       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.47      0.45       432\n",
      "           1       0.55      0.51      0.53       556\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.50      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.46      0.44       186\n",
      "           1       0.59      0.55      0.57       259\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.50      0.50      0.50       445\n",
      "weighted avg       0.52      0.51      0.51       445\n",
      "\n",
      "=================================== 6 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================태풍 및 장마_change==============================7 page\n",
      "LogisticRegression 정확도(훈련셋) : 0.5422998986828774\n",
      "LogisticRegression 정확도(테스트셋) : 0.49696356275303644\n",
      "LogisticRegression 정확도(실제 테스트셋) : 0.5101123595505618\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 정확도(훈련셋) : 1.0\n",
      "DecisionTreeClassifier 정확도(테스트셋) : 0.4939271255060729\n",
      "DecisionTreeClassifier 정확도(실제 테스트셋) : 0.501123595505618\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 정확도(훈련셋) : 0.6978216818642351\n",
      "KNeighborsClassifier 정확도(테스트셋) : 0.5060728744939271\n",
      "KNeighborsClassifier 정확도(실제 테스트셋) : 0.47191011235955055\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 정확도(훈련셋) : 0.5098784194528876\n",
      "GaussianNB 정확도(테스트셋) : 0.4817813765182186\n",
      "GaussianNB 정확도(실제 테스트셋) : 0.501123595505618\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 정확도(훈련셋) : 1.0\n",
      "RandomForestClassifier 정확도(테스트셋) : 0.5091093117408907\n",
      "RandomForestClassifier 정확도(실제 테스트셋) : 0.5528089887640449\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9176798378926039\n",
      "VotingClassifier 정확도(테스트셋) : 0.4908906882591093\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.48764044943820223\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 정확도(훈련셋) : 0.9941742654508612\n",
      "VotingClassifier 정확도(테스트셋) : 0.4898785425101215\n",
      "VotingClassifier 정확도(실제 테스트셋) : 0.48314606741573035\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.42      0.44       468\n",
      "           1       0.52      0.57      0.54       520\n",
      "\n",
      "    accuracy                           0.50       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.50      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.47      0.48       210\n",
      "           1       0.54      0.54      0.54       235\n",
      "\n",
      "    accuracy                           0.51       445\n",
      "   macro avg       0.51      0.51      0.51       445\n",
      "weighted avg       0.51      0.51      0.51       445\n",
      "\n",
      "DecisionTreeClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.46      0.46       468\n",
      "           1       0.52      0.52      0.52       520\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.50      0.49       210\n",
      "           1       0.53      0.50      0.51       235\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.50      0.50      0.50       445\n",
      "weighted avg       0.50      0.50      0.50       445\n",
      "\n",
      "KNeighborsClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.50      0.49       468\n",
      "           1       0.53      0.51      0.52       520\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.43      0.44       210\n",
      "           1       0.50      0.51      0.50       235\n",
      "\n",
      "    accuracy                           0.47       445\n",
      "   macro avg       0.47      0.47      0.47       445\n",
      "weighted avg       0.47      0.47      0.47       445\n",
      "\n",
      "GaussianNB 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.81      0.60       468\n",
      "           1       0.52      0.19      0.28       520\n",
      "\n",
      "    accuracy                           0.48       988\n",
      "   macro avg       0.50      0.50      0.44       988\n",
      "weighted avg       0.50      0.48      0.43       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GaussianNB 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.85      0.62       210\n",
      "           1       0.58      0.19      0.29       235\n",
      "\n",
      "    accuracy                           0.50       445\n",
      "   macro avg       0.53      0.52      0.45       445\n",
      "weighted avg       0.54      0.50      0.44       445\n",
      "\n",
      "RandomForestClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.45      0.46       468\n",
      "           1       0.53      0.57      0.55       520\n",
      "\n",
      "    accuracy                           0.51       988\n",
      "   macro avg       0.51      0.51      0.51       988\n",
      "weighted avg       0.51      0.51      0.51       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50       210\n",
      "           1       0.57      0.63      0.60       235\n",
      "\n",
      "    accuracy                           0.55       445\n",
      "   macro avg       0.55      0.55      0.55       445\n",
      "weighted avg       0.55      0.55      0.55       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.54      0.50       468\n",
      "           1       0.52      0.45      0.48       520\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.54      0.50       210\n",
      "           1       0.52      0.44      0.47       235\n",
      "\n",
      "    accuracy                           0.49       445\n",
      "   macro avg       0.49      0.49      0.49       445\n",
      "weighted avg       0.49      0.49      0.49       445\n",
      "\n",
      "VotingClassifier 훈련 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.55      0.50       468\n",
      "           1       0.52      0.44      0.47       520\n",
      "\n",
      "    accuracy                           0.49       988\n",
      "   macro avg       0.49      0.49      0.49       988\n",
      "weighted avg       0.49      0.49      0.49       988\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VotingClassifier 실제 데이터 테스트셋 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.55      0.50       210\n",
      "           1       0.51      0.42      0.46       235\n",
      "\n",
      "    accuracy                           0.48       445\n",
      "   macro avg       0.49      0.49      0.48       445\n",
      "weighted avg       0.49      0.48      0.48       445\n",
      "\n",
      "=================================== 7 page ===================================\n",
      "\n",
      "\n",
      " \n",
      "===================================kospi_change==============================8 page\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-83e9d35fdc3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# 데이터 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[0m\u001b[0;32m   1375\u001b[0m                              \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m                              \" class: %r\" % classes_[0])\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for i in range(len(y3.columns)) : \n",
    "    # 훈련용 데이터(X_tr)을 train_test_split으로 나누기\n",
    "#   from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x3_tr, y3_tr.iloc[:,i], test_size = 0.2, random_state = 1)\n",
    "\n",
    "    # 데이터 표준화\n",
    "#     from sklearn.preprocessing import StandardScaler\n",
    "    stds = StandardScaler()\n",
    "    stds.fit(X_train)\n",
    "    X_train_std = stds.transform(X_train)\n",
    "    X_test_std = stds.transform(X_test)\n",
    "    X_ftest_std = stds.transform(x3_te)\n",
    "\n",
    "    # 분석 시작\n",
    "#     from sklearn.tree import DecisionTreeClassifier\n",
    "#     from sklearn.linear_model import LogisticRegression\n",
    "#     from sklearn.neighbors import KNeighborsClassifier\n",
    "#     from sklearn.naive_bayes import GaussianNB\n",
    "#     from sklearn.ensemble import RandomForestClassifier\n",
    "#     from sklearn.ensemble import VotingClassifier\n",
    "#     from sklearn.metrics import precision_score\n",
    "    \n",
    "    # 모델 생성\n",
    "    log = LogisticRegression()\n",
    "    knn = KNeighborsClassifier()\n",
    "    tree = DecisionTreeClassifier()\n",
    "    gnb = GaussianNB()\n",
    "    rfc = RandomForestClassifier()\n",
    "         \n",
    "    hvot = VotingClassifier(estimators = [('log', log), ('rfc', rfc), ('knn', knn), \\\n",
    "                        ('tree',tree),('gnb', gnb)], voting='hard')\n",
    "\n",
    "    svot = VotingClassifier(estimators = [('log', log), ('rfc', rfc), ('knn', knn), \\\n",
    "                        ('tree',tree),('gnb', gnb)], voting='soft')\n",
    "    \n",
    "    models = [log, tree, knn, gnb, rfc, hvot, svot]\n",
    "    \n",
    "    print('==================================={}=============================={} page'.format(y3.columns[i], i+1))\n",
    "    \n",
    "    y_fin = y3_te.iloc[:,i] # 최종 모형 평가 변수\n",
    "    \n",
    "    for m in models :\n",
    "        m.fit(X_train, y_train)\n",
    "        \n",
    "        # 데이터 예측\n",
    "        preds = m.predict(X_test) \n",
    "        \n",
    "        # 정확도 평가\n",
    "        accuracy0 = m.score(X_train, y_train)\n",
    "        accuracy1 = m.score(X_test, y_test)\n",
    "        accuracy2 = m.score(x3_te, y_fin)\n",
    "        \n",
    "        print(m.__class__.__name__, '정확도(훈련셋) :' , accuracy0)\n",
    "        print(m.__class__.__name__, '정확도(테스트셋) :' , accuracy1)\n",
    "        print(m.__class__.__name__, '정확도(실제 테스트셋) :' , accuracy2)\n",
    "        \n",
    "        print('-'*80)\n",
    "\n",
    "    # 분류 레포트\n",
    "\n",
    "#     from sklearn.metrics import classification_report\n",
    "    \n",
    "    y_fin = y3_te.iloc[:,i]                \n",
    "    \n",
    "    for m in models :\n",
    "        preds0 = m.predict(X_test) # 데이터 예측\n",
    "        preds1 = m.predict(x1_te)\n",
    "        class_report1 = classification_report(y_test, preds0)\n",
    "        class_report2 = classification_report(y_fin, preds1)\n",
    "        \n",
    "        print(m.__class__.__name__ , '훈련 데이터 테스트셋 \\n',class_report1)\n",
    "        print('-'*80)\n",
    "        print(m.__class__.__name__ , '실제 데이터 테스트셋 \\n',class_report2)\n",
    "    \n",
    "    print('=================================== {} page ===================================\\n\\n\\n '.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679dd246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167e5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96cdcea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad91b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014d3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611cb64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b6115c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e802715b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12622f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb88b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960af40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba888c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6ec72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800bca7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a89a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8231f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1d6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3657700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0807d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a64865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c236a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e090d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e228f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f677c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a735d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e58e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d92b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddefbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a170e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb70e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee5fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e390096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 훈련용 데이터(X_tr)을 train_test_split으로 나누기\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_tr, y_tr.iloc[:,1], test_size = 0.2, random_state = 1)\n",
    "\n",
    "# # 데이터 표준화\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# stds = StandardScaler()\n",
    "# stds.fit(X_train)\n",
    "# X_train_std = stds.transform(X_train)\n",
    "# X_test_std = stds.transform(X_test)\n",
    "\n",
    "# # 로지스틱 회귀분석 시작\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# log_reg = LogisticRegression()\n",
    "# log_reg.fit(X_train, y_train)\n",
    "\n",
    "# # 로지스틱 회귀분석 추정계수\n",
    "# print('{}, =============== {}'.format(y_new_tr.columns[i], i+1))\n",
    "# print('로지스틱 회귀분석 추정계수 \\n', log_reg.coef_)\n",
    "# print('='*40)\n",
    "\n",
    "# # 데이터 예측\n",
    "# pred_log_reg = log_reg.predict(X_test)\n",
    "# print('데이터 예측값 \\n' ,pred_log_reg)\n",
    "# print('='*40)\n",
    "\n",
    "# # 클래스 확률\n",
    "# pred_proba = log_reg.predict_proba(X_test)\n",
    "# print(pred_proba)\n",
    "# print('='*40)\n",
    "\n",
    "# # 정밀도 평가\n",
    "# from sklearn.metrics import precision_score\n",
    "# prec = precision_score(y_test, pred_log_reg)\n",
    "# # prec_fin = precision_score()\n",
    "# print('테스트 훈련셋 정밀도 :', prec)\n",
    "# # print\n",
    "# print('='*40)\n",
    "\n",
    "# # confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# con_mat = confusion_matrix(y_test, pred_log_reg)\n",
    "# print('로지스틱회귀분석 \\n', con_mat)\n",
    "# print('='*40)\n",
    "\n",
    "\n",
    "# # 분류 레포트\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# class_report = classification_report(y_test, pred_log_reg)\n",
    "# print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693e09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea6faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434287a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6107c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98acd04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d1c4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9142655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 코스피 change를 조정한 테마별 change\n",
    "# y1 = pd.DataFrame()\n",
    "# y_new = pd.DataFrame()\n",
    "# c_n = list(y.columns)\n",
    "\n",
    "# i = 0\n",
    "\n",
    "# while i < len(y.columns)-1:\n",
    "#     print(i, end = ' ')\n",
    "#     y_new['{}'.format(c_n[i+1])] = y.iloc[:,i+1] - y['kospi_change']\n",
    "#     y1['{}'.format(c_n[i+1])] = y.iloc[:,i+1]\n",
    "#     i +=1\n",
    "\n",
    "# y_new.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
