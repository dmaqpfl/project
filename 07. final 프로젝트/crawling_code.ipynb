{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea37f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from konlpy.tag import Kkma, Hannanum, Komoran, Mecab\n",
    "kkma = Kkma()\n",
    "mecab = Mecab()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "import re\n",
    "from gensim.summarization.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b64ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 크롤링 코드\n",
    "article_df = pd.DataFrame(columns=['date','title','contents','press','good','well','sad','mad','want'])\n",
    "scan_day = pd.datetime(2021,1,10) # 시작 일자 설정\n",
    "page_count = True\n",
    "page = 1\n",
    "\n",
    "for a in range(0, 10) : \n",
    "\n",
    "    search_day = str(scan_day.year) + str(scan_day.month).zfill(2) + str(scan_day.day).zfill(2)\n",
    "    print(search_day)\n",
    "    while page_count :\n",
    "        main_url = 'https://news.naver.com/main/list.naver?mode=LS2D&sid2=259&page2=&sid1=101&mid=shm&date={}&page={}'.format(search_day, page)\n",
    "        headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36'}\n",
    "        main_res = requests.get(main_url, headers = headers)\n",
    "        main_soup = BeautifulSoup(main_res.text, 'html.parser')\n",
    "        path = '#main_content > div.list_body.newsflash_body > ul > li'\n",
    "        page_path1 = '#main_content > div.paging > a'\n",
    "        page_path2 = '#main_content > div.paging > strong'\n",
    "        main_select = main_soup.select(path)\n",
    "        page_select = main_soup.select(page_path1)\n",
    "        present = main_soup.select(page_path2)\n",
    "        if page_select[-1].text != '다음' :\n",
    "            if 20 != len(main_select) :\n",
    "                page_count = False\n",
    "            elif int(present[0].text) == int(page_select[-1].text)+1  :\n",
    "                page_count = False\n",
    "\n",
    "        page += 1            \n",
    "        print(main_url)\n",
    "        try : \n",
    "            for i in range(0, len(main_select)) :\n",
    "                news_cont_url = main_select[i].select('a')[0]['href']\n",
    "\n",
    "                cont_res = requests.get(news_cont_url, headers = headers)\n",
    "                cont_soup = BeautifulSoup(cont_res.text, 'html.parser')\n",
    "                cont_select_head = cont_soup.select('#main_content > div.article_header')\n",
    "                cont_select_body = cont_soup.select('#articleBodyContents')\n",
    "\n",
    "                target_text_without_child_tags = [bs_object for bs_object in cont_select_body[0]\n",
    "                    if isinstance(bs_object, NavigableString)]\n",
    "                text = \"\".join(target_text_without_child_tags[8:-3])\n",
    "\n",
    "                date = cont_select_head[0].select('span.t11')[0].text\n",
    "                title = cont_select_head[0].select('div.article_info #articleTitle')[0].text\n",
    "                contents = text\n",
    "                press = cont_select_head[0].select('a')[0]['href']\n",
    "                good = cont_select_head[0].select('span.u_likeit_list_count._count')[0].text\n",
    "                well = cont_select_head[0].select('span.u_likeit_list_count._count')[1].text\n",
    "                sad = cont_select_head[0].select('span.u_likeit_list_count._count')[2].text\n",
    "                mad = cont_select_head[0].select('span.u_likeit_list_count._count')[3].text\n",
    "                want = cont_select_head[0].select('span.u_likeit_list_count._count')[4].text\n",
    "\n",
    "                data = {'date':date, 'title':title, 'contents':contents, 'press':press, 'good':good,\n",
    "                       'well':well, 'sad':sad, 'mad':mad, 'want':want}\n",
    "                article_df = article_df.append(data, ignore_index=True)\n",
    "        except :\n",
    "            continue\n",
    "\n",
    "    scan_day = scan_day - pd.Timedelta(\"1day\")\n",
    "    page_count = True\n",
    "    page = 1\n",
    "\n",
    "# article_df.to_csv('article_info.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dc3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contents 요약\n",
    "summa = []\n",
    "for contents in df['contents'] :\n",
    "    try : \n",
    "        sentence = kkma.sentences(contents)        \n",
    "        if len(sentence) > 10 :\n",
    "            summary = ''\n",
    "            for row in summarize(contents).split('\\n') :\n",
    "                summary += row\n",
    "            if summary.strip() == '' :\n",
    "                summa.append(np.nan)\n",
    "            else : \n",
    "                summa.append(summary)\n",
    "        else :\n",
    "            summa.append(np.nan)\n",
    "    except :\n",
    "        summa.append(np.nan)\n",
    "\n",
    "df['summary'] = summa\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6033cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd40df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
